{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8417cd56-18e6-4cfe-bc14-f6f854987801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_stats(doremi, reference):\n",
    "#     total = 0\n",
    "#     succeed = 0\n",
    "#     same = 0\n",
    "#     amount_succeed = 0\n",
    "#     amount_fail = 0\n",
    "    \n",
    "#     for name in doremi:\n",
    "#         tuned_acc = doremi[name]['acc']\n",
    "#         ref_acc = reference[name]['acc']\n",
    "    \n",
    "#         if tuned_acc > ref_acc:\n",
    "#             succeed += 1\n",
    "#             amount_succeed += tuned_acc - ref_acc\n",
    "#         elif tuned_acc == ref_acc:\n",
    "#             # if doremi[name][\"acc_stderr\"] < reference[name][\"acc_stderr\"]:\n",
    "#             #     succeed += 1\n",
    "#             # else:\n",
    "#             #     same += 1\n",
    "#             same += 1\n",
    "#         else:\n",
    "#             amount_fail += ref_acc - tuned_acc\n",
    "    \n",
    "#         total += 1\n",
    "\n",
    "#     failed = total - succeed - same\n",
    "\n",
    "#     print(f\"total={total}, succeed={succeed}, failed={failed}, same={same}, amount_succeed={amount_succeed}, amount_fail={amount_fail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772c4738-cac8-41c7-88b0-af6a68277bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot(doremi, reference):\n",
    "#     import pandas as pd\n",
    "    \n",
    "#     pd.set_option('display.max_rows', None)\n",
    "    \n",
    "#     tasks = list(doremi.keys())\n",
    "#     columns = ['Task', 'DoReMi ACC', 'Reference ACC', 'DoReMi AccNorm', 'Reference AccNorm']\n",
    "#     data = []\n",
    "    \n",
    "#     for task in tasks:\n",
    "#         row = [\n",
    "#             task,\n",
    "#             doremi[task]['acc'],\n",
    "#             reference[task]['acc'],\n",
    "#             doremi[task].get('acc_norm', 'N/A'),  # Using 'N/A' for missing 'acc_norm' values\n",
    "#             reference[task].get('acc_norm', 'N/A')\n",
    "#         ]\n",
    "#         data.append(row)\n",
    "    \n",
    "#     # Create DataFrame\n",
    "#     comparison_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "#     pd.set_option('display.max_rows', None)\n",
    "\n",
    "#     def highlight_greater_doremi_acc(row):\n",
    "#         if row['DoReMi ACC'] > row['Reference ACC']:\n",
    "#             return ['background-color: #59cc0c'] * len(row)  # Apply yellow background to entire row\n",
    "#         elif row['DoReMi ACC'] == row['Reference ACC']:\n",
    "#             return ['background-color: #cc9c0c'] * len(row)  # Apply yellow background to entire row\n",
    "#         else:\n",
    "#             return [''] * len(row)  # No styling for rows that don't meet the condition\n",
    "    \n",
    "#     # Apply the styling function to the DataFrame\n",
    "#     styled_df = comparison_df.style.apply(highlight_greater_doremi_acc, axis=1)\n",
    "#     return styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3e34c2-7341-47bc-a5e8-811c392a7f0c",
   "metadata": {},
   "source": [
    "### 40k proxy, 25k reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae33c792-83d0-48bc-80d5-f3c3acf10ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_data_25k = {\n",
    "#     \"arc:challenge\": {\n",
    "#     \"acc\": 0.181,\n",
    "#     \"acc_stderr\": 0.012181436179177893,\n",
    "#     \"acc_norm\": 0.24,\n",
    "#     \"acc_norm_stderr\": 0.013512312258920843\n",
    "#     },\n",
    "#     \"arc:easy\": {\n",
    "#     \"acc\": 0.372,\n",
    "#     \"acc_stderr\": 0.015292149942040577,\n",
    "#     \"acc_norm\": 0.371,\n",
    "#     \"acc_norm_stderr\": 0.015283736211823187\n",
    "#     },\n",
    "#     \"commonsense_qa\": {\n",
    "#     \"acc\": 0.233,\n",
    "#     \"acc_stderr\": 0.013374972519220039,\n",
    "#     \"acc_norm\": 0.259,\n",
    "#     \"acc_norm_stderr\": 0.013860415257527911\n",
    "#     },\n",
    "#     \"hellaswag\": {\n",
    "#     \"acc\": 0.289,\n",
    "#     \"acc_stderr\": 0.014341711358296172,\n",
    "#     \"acc_norm\": 0.291,\n",
    "#     \"acc_norm_stderr\": 0.014370995982377944\n",
    "#     },\n",
    "#     \"mmlu:abstract_algebra\": {\n",
    "#     \"acc\": 0.22,\n",
    "#     \"acc_stderr\": 0.0416333199893227,\n",
    "#     \"acc_norm\": 0.26,\n",
    "#     \"acc_norm_stderr\": 0.04408440022768078\n",
    "#     },\n",
    "#     \"mmlu:anatomy\": {\n",
    "#     \"acc\": 0.28888888888888886,\n",
    "#     \"acc_stderr\": 0.03915450630414251,\n",
    "#     \"acc_norm\": 0.2740740740740741,\n",
    "#     \"acc_norm_stderr\": 0.03853254836552003\n",
    "#     },\n",
    "#     \"mmlu:astronomy\": {\n",
    "#     \"acc\": 0.23684210526315788,\n",
    "#     \"acc_stderr\": 0.034597776068105365,\n",
    "#     \"acc_norm\": 0.27631578947368424,\n",
    "#     \"acc_norm_stderr\": 0.03639057569952924\n",
    "#     },\n",
    "#     \"mmlu:business_ethics\": {\n",
    "#     \"acc\": 0.36,\n",
    "#     \"acc_stderr\": 0.048241815132442176,\n",
    "#     \"acc_norm\": 0.26,\n",
    "#     \"acc_norm_stderr\": 0.04408440022768079\n",
    "#     },\n",
    "#     \"mmlu:clinical_knowledge\": {\n",
    "#     \"acc\": 0.2,\n",
    "#     \"acc_stderr\": 0.02461829819586651,\n",
    "#     \"acc_norm\": 0.33584905660377357,\n",
    "#     \"acc_norm_stderr\": 0.02906722014664483\n",
    "#     },\n",
    "#     \"mmlu:college_biology\": {\n",
    "#     \"acc\": 0.25,\n",
    "#     \"acc_stderr\": 0.03621034121889507,\n",
    "#     \"acc_norm\": 0.2361111111111111,\n",
    "#     \"acc_norm_stderr\": 0.03551446610810826\n",
    "#     },\n",
    "#     \"mmlu:college_chemistry\": {\n",
    "#     \"acc\": 0.29,\n",
    "#     \"acc_stderr\": 0.045604802157206845,\n",
    "#     \"acc_norm\": 0.26,\n",
    "#     \"acc_norm_stderr\": 0.0440844002276808\n",
    "#     },\n",
    "#     \"mmlu:college_computer_science\": {\n",
    "#     \"acc\": 0.24,\n",
    "#     \"acc_stderr\": 0.042923469599092816,\n",
    "#     \"acc_norm\": 0.23,\n",
    "#     \"acc_norm_stderr\": 0.042295258468165044\n",
    "#     },\n",
    "#     \"mmlu:college_mathematics\": {\n",
    "#     \"acc\": 0.15,\n",
    "#     \"acc_stderr\": 0.03588702812826371,\n",
    "#     \"acc_norm\": 0.24,\n",
    "#     \"acc_norm_stderr\": 0.04292346959909282\n",
    "#     },\n",
    "#     \"mmlu:college_medicine\": {\n",
    "#     \"acc\": 0.2138728323699422,\n",
    "#     \"acc_stderr\": 0.03126511206173043,\n",
    "#     \"acc_norm\": 0.24277456647398843,\n",
    "#     \"acc_norm_stderr\": 0.0326926380614177\n",
    "#     },\n",
    "#     \"mmlu:college_physics\": {\n",
    "#     \"acc\": 0.22549019607843138,\n",
    "#     \"acc_stderr\": 0.041583075330832865,\n",
    "#     \"acc_norm\": 0.24509803921568626,\n",
    "#     \"acc_norm_stderr\": 0.04280105837364396\n",
    "#     },\n",
    "#     \"mmlu:computer_security\": {\n",
    "#     \"acc\": 0.22,\n",
    "#     \"acc_stderr\": 0.04163331998932269,\n",
    "#     \"acc_norm\": 0.23,\n",
    "#     \"acc_norm_stderr\": 0.042295258468165044\n",
    "#     },\n",
    "#     \"mmlu:conceptual_physics\": {\n",
    "#     \"acc\": 0.3276595744680851,\n",
    "#     \"acc_stderr\": 0.030683020843231,\n",
    "#     \"acc_norm\": 0.2297872340425532,\n",
    "#     \"acc_norm_stderr\": 0.027501752944412417\n",
    "#     },\n",
    "#     \"mmlu:econometrics\": {\n",
    "#     \"acc\": 0.16666666666666666,\n",
    "#     \"acc_stderr\": 0.03505859682597264,\n",
    "#     \"acc_norm\": 0.21929824561403508,\n",
    "#     \"acc_norm_stderr\": 0.038924311065187546\n",
    "#     },\n",
    "#     \"mmlu:electrical_engineering\": {\n",
    "#     \"acc\": 0.2413793103448276,\n",
    "#     \"acc_stderr\": 0.03565998174135302,\n",
    "#     \"acc_norm\": 0.2827586206896552,\n",
    "#     \"acc_norm_stderr\": 0.03752833958003337\n",
    "#     },\n",
    "#     \"mmlu:elementary_mathematics\": {\n",
    "#     \"acc\": 0.2037037037037037,\n",
    "#     \"acc_stderr\": 0.020742740560122663,\n",
    "#     \"acc_norm\": 0.21164021164021163,\n",
    "#     \"acc_norm_stderr\": 0.021037331505262886\n",
    "#     },\n",
    "#     \"mmlu:formal_logic\": {\n",
    "#     \"acc\": 0.2857142857142857,\n",
    "#     \"acc_stderr\": 0.0404061017820884,\n",
    "#     \"acc_norm\": 0.23015873015873015,\n",
    "#     \"acc_norm_stderr\": 0.03764950879790605\n",
    "#     },\n",
    "#     \"mmlu:global_facts\": {\n",
    "#     \"acc\": 0.25,\n",
    "#     \"acc_stderr\": 0.04351941398892446,\n",
    "#     \"acc_norm\": 0.24,\n",
    "#     \"acc_norm_stderr\": 0.042923469599092816\n",
    "#     },\n",
    "#     \"mmlu:high_school_biology\": {\n",
    "#     \"acc\": 0.22903225806451613,\n",
    "#     \"acc_stderr\": 0.023904914311782648,\n",
    "#     \"acc_norm\": 0.29354838709677417,\n",
    "#     \"acc_norm_stderr\": 0.02590608702131929\n",
    "#     },\n",
    "#     \"mmlu:high_school_chemistry\": {\n",
    "#     \"acc\": 0.1625615763546798,\n",
    "#     \"acc_stderr\": 0.0259603000646056,\n",
    "#     \"acc_norm\": 0.19704433497536947,\n",
    "#     \"acc_norm_stderr\": 0.027986724666736223\n",
    "#     },\n",
    "#     \"mmlu:high_school_computer_science\": {\n",
    "#     \"acc\": 0.22,\n",
    "#     \"acc_stderr\": 0.041633319989322695,\n",
    "#     \"acc_norm\": 0.28,\n",
    "#     \"acc_norm_stderr\": 0.045126085985421296\n",
    "#     },\n",
    "#     \"mmlu:high_school_european_history\": {\n",
    "#     \"acc\": 0.18181818181818182,\n",
    "#     \"acc_stderr\": 0.030117688929503582,\n",
    "#     \"acc_norm\": 0.28484848484848485,\n",
    "#     \"acc_norm_stderr\": 0.03524390844511782\n",
    "#     },\n",
    "#     \"mmlu:high_school_geography\": {\n",
    "#     \"acc\": 0.25252525252525254,\n",
    "#     \"acc_stderr\": 0.030954055470365907,\n",
    "#     \"acc_norm\": 0.2777777777777778,\n",
    "#     \"acc_norm_stderr\": 0.03191178226713546\n",
    "#     },\n",
    "#     \"mmlu:high_school_government_and_politics\": {\n",
    "#     \"acc\": 0.23316062176165803,\n",
    "#     \"acc_stderr\": 0.030516111371476008,\n",
    "#     \"acc_norm\": 0.26424870466321243,\n",
    "#     \"acc_norm_stderr\": 0.03182155050916646\n",
    "#     },\n",
    "#     \"mmlu:high_school_macroeconomics\": {\n",
    "#     \"acc\": 0.26153846153846155,\n",
    "#     \"acc_stderr\": 0.022282141204204426,\n",
    "#     \"acc_norm\": 0.28205128205128205,\n",
    "#     \"acc_norm_stderr\": 0.022815813098896603\n",
    "#     },\n",
    "#     \"mmlu:high_school_mathematics\": {\n",
    "#     \"acc\": 0.12962962962962962,\n",
    "#     \"acc_stderr\": 0.020479910253320705,\n",
    "#     \"acc_norm\": 0.15185185185185185,\n",
    "#     \"acc_norm_stderr\": 0.021881130957380476\n",
    "#     },\n",
    "#     \"mmlu:high_school_microeconomics\": {\n",
    "#     \"acc\": 0.23949579831932774,\n",
    "#     \"acc_stderr\": 0.02772206549336128,\n",
    "#     \"acc_norm\": 0.31932773109243695,\n",
    "#     \"acc_norm_stderr\": 0.030283995525884396\n",
    "#     },\n",
    "#     \"mmlu:high_school_physics\": {\n",
    "#     \"acc\": 0.23841059602649006,\n",
    "#     \"acc_stderr\": 0.034791855725996586,\n",
    "#     \"acc_norm\": 0.26490066225165565,\n",
    "#     \"acc_norm_stderr\": 0.03603038545360384\n",
    "#     },\n",
    "#     \"mmlu:high_school_psychology\": {\n",
    "#     \"acc\": 0.29908256880733947,\n",
    "#     \"acc_stderr\": 0.019630417285415175,\n",
    "#     \"acc_norm\": 0.28073394495412846,\n",
    "#     \"acc_norm_stderr\": 0.019266055045871616\n",
    "#     },\n",
    "#     \"mmlu:high_school_statistics\": {\n",
    "#     \"acc\": 0.25925925925925924,\n",
    "#     \"acc_stderr\": 0.02988691054762696,\n",
    "#     \"acc_norm\": 0.28703703703703703,\n",
    "#     \"acc_norm_stderr\": 0.03085199299325701\n",
    "#     },\n",
    "#     \"mmlu:high_school_us_history\": {\n",
    "#     \"acc\": 0.23529411764705882,\n",
    "#     \"acc_stderr\": 0.029771775228145652,\n",
    "#     \"acc_norm\": 0.30392156862745096,\n",
    "#     \"acc_norm_stderr\": 0.03228210387037894\n",
    "#     },\n",
    "#     \"mmlu:high_school_world_history\": {\n",
    "#     \"acc\": 0.21940928270042195,\n",
    "#     \"acc_stderr\": 0.026939106581553945,\n",
    "#     \"acc_norm\": 0.2616033755274262,\n",
    "#     \"acc_norm_stderr\": 0.028609516716994934\n",
    "#     },\n",
    "#     \"mmlu:human_aging\": {\n",
    "#     \"acc\": 0.3094170403587444,\n",
    "#     \"acc_stderr\": 0.03102441174057222,\n",
    "#     \"acc_norm\": 0.2825112107623318,\n",
    "#     \"acc_norm_stderr\": 0.030216831011508766\n",
    "#     },\n",
    "#     \"mmlu:human_sexuality\": {\n",
    "#     \"acc\": 0.33587786259541985,\n",
    "#     \"acc_stderr\": 0.041423137719966634,\n",
    "#     \"acc_norm\": 0.31297709923664124,\n",
    "#     \"acc_norm_stderr\": 0.04066962905677697\n",
    "#     },\n",
    "#     \"mmlu:international_law\": {\n",
    "#     \"acc\": 0.11570247933884298,\n",
    "#     \"acc_stderr\": 0.029199802455622783,\n",
    "#     \"acc_norm\": 0.256198347107438,\n",
    "#     \"acc_norm_stderr\": 0.03984979653302871\n",
    "#     },\n",
    "#     \"mmlu:jurisprudence\": {\n",
    "#     \"acc\": 0.1574074074074074,\n",
    "#     \"acc_stderr\": 0.03520703990517963,\n",
    "#     \"acc_norm\": 0.23148148148148148,\n",
    "#     \"acc_norm_stderr\": 0.04077494709252627\n",
    "#     },\n",
    "#     \"mmlu:logical_fallacies\": {\n",
    "#     \"acc\": 0.27607361963190186,\n",
    "#     \"acc_stderr\": 0.0351238528370505,\n",
    "#     \"acc_norm\": 0.3558282208588957,\n",
    "#     \"acc_norm_stderr\": 0.03761521380046734\n",
    "#     },\n",
    "#     \"mmlu:machine_learning\": {\n",
    "#     \"acc\": 0.21428571428571427,\n",
    "#     \"acc_stderr\": 0.03894641120044792,\n",
    "#     \"acc_norm\": 0.21428571428571427,\n",
    "#     \"acc_norm_stderr\": 0.038946411200447915\n",
    "#     },\n",
    "#     \"mmlu:management\": {\n",
    "#     \"acc\": 0.22330097087378642,\n",
    "#     \"acc_stderr\": 0.04123553189891431,\n",
    "#     \"acc_norm\": 0.22330097087378642,\n",
    "#     \"acc_norm_stderr\": 0.04123553189891431\n",
    "#     },\n",
    "#     \"mmlu:marketing\": {\n",
    "#     \"acc\": 0.2948717948717949,\n",
    "#     \"acc_stderr\": 0.029872577708891165,\n",
    "#     \"acc_norm\": 0.32905982905982906,\n",
    "#     \"acc_norm_stderr\": 0.030782321577688156\n",
    "#     },\n",
    "#     \"mmlu:medical_genetics\": {\n",
    "#     \"acc\": 0.23,\n",
    "#     \"acc_stderr\": 0.04229525846816506,\n",
    "#     \"acc_norm\": 0.25,\n",
    "#     \"acc_norm_stderr\": 0.04351941398892446\n",
    "#     },\n",
    "#     \"mmlu:miscellaneous\": {\n",
    "#     \"acc\": 0.2720306513409962,\n",
    "#     \"acc_stderr\": 0.015913367447500517,\n",
    "#     \"acc_norm\": 0.26181353767560667,\n",
    "#     \"acc_norm_stderr\": 0.015720838678445266\n",
    "#     },\n",
    "#     \"mmlu:moral_disputes\": {\n",
    "#     \"acc\": 0.20520231213872833,\n",
    "#     \"acc_stderr\": 0.021742519835276305,\n",
    "#     \"acc_norm\": 0.1676300578034682,\n",
    "#     \"acc_norm_stderr\": 0.020110579919734833\n",
    "#     },\n",
    "#     \"mmlu:moral_scenarios\": {\n",
    "#     \"acc\": 0.23798882681564246,\n",
    "#     \"acc_stderr\": 0.014242630070574915,\n",
    "#     \"acc_norm\": 0.27262569832402234,\n",
    "#     \"acc_norm_stderr\": 0.014893391735249588\n",
    "#     },\n",
    "#     \"mmlu:nutrition\": {\n",
    "#     \"acc\": 0.20588235294117646,\n",
    "#     \"acc_stderr\": 0.023152722439402307,\n",
    "#     \"acc_norm\": 0.29411764705882354,\n",
    "#     \"acc_norm_stderr\": 0.026090162504279056\n",
    "#     },\n",
    "#     \"mmlu:philosophy\": {\n",
    "#     \"acc\": 0.21543408360128619,\n",
    "#     \"acc_stderr\": 0.023350225475471414,\n",
    "#     \"acc_norm\": 0.2829581993569132,\n",
    "#     \"acc_norm_stderr\": 0.025583062489984834\n",
    "#     },\n",
    "#     \"mmlu:prehistory\": {\n",
    "#     \"acc\": 0.27469135802469136,\n",
    "#     \"acc_stderr\": 0.024836057868294688,\n",
    "#     \"acc_norm\": 0.19753086419753085,\n",
    "#     \"acc_norm_stderr\": 0.022152889927898975\n",
    "#     },\n",
    "#     \"mmlu:professional_accounting\": {\n",
    "#     \"acc\": 0.25886524822695034,\n",
    "#     \"acc_stderr\": 0.026129572527180848,\n",
    "#     \"acc_norm\": 0.22695035460992907,\n",
    "#     \"acc_norm_stderr\": 0.02498710636564296\n",
    "#     },\n",
    "#     \"mmlu:professional_law\": {\n",
    "#     \"acc\": 0.232,\n",
    "#     \"acc_stderr\": 0.013354937452281558,\n",
    "#     \"acc_norm\": 0.254,\n",
    "#     \"acc_norm_stderr\": 0.013772206565168544\n",
    "#     },\n",
    "#     \"mmlu:professional_medicine\": {\n",
    "#     \"acc\": 0.23529411764705882,\n",
    "#     \"acc_stderr\": 0.02576725201085596,\n",
    "#     \"acc_norm\": 0.2536764705882353,\n",
    "#     \"acc_norm_stderr\": 0.02643132987078954\n",
    "#     },\n",
    "#     \"mmlu:professional_psychology\": {\n",
    "#     \"acc\": 0.26143790849673204,\n",
    "#     \"acc_stderr\": 0.017776947157528037,\n",
    "#     \"acc_norm\": 0.2679738562091503,\n",
    "#     \"acc_norm_stderr\": 0.017917974069594726\n",
    "#     },\n",
    "#     \"mmlu:public_relations\": {\n",
    "#     \"acc\": 0.33636363636363636,\n",
    "#     \"acc_stderr\": 0.04525393596302506,\n",
    "#     \"acc_norm\": 0.24545454545454545,\n",
    "#     \"acc_norm_stderr\": 0.041220665028782834\n",
    "#     },\n",
    "#     \"mmlu:security_studies\": {\n",
    "# \"acc\": 0.30612244897959184,\n",
    "# \"acc_stderr\": 0.029504896454595968,\n",
    "# \"acc_norm\": 0.20816326530612245,\n",
    "# \"acc_norm_stderr\": 0.025991117672813296\n",
    "# },\n",
    "# \"mmlu:sociology\": {\n",
    "# \"acc\": 0.21890547263681592,\n",
    "# \"acc_stderr\": 0.029239174636647,\n",
    "# \"acc_norm\": 0.23383084577114427,\n",
    "# \"acc_norm_stderr\": 0.02992941540834839\n",
    "# },\n",
    "# \"mmlu:us_foreign_policy\": {\n",
    "# \"acc\": 0.22,\n",
    "# \"acc_stderr\": 0.04163331998932269,\n",
    "# \"acc_norm\": 0.19,\n",
    "# \"acc_norm_stderr\": 0.03942772444036623\n",
    "# },\n",
    "# \"mmlu:virology\": {\n",
    "# \"acc\": 0.2469879518072289,\n",
    "# \"acc_stderr\": 0.03357351982064536,\n",
    "# \"acc_norm\": 0.3253012048192771,\n",
    "# \"acc_norm_stderr\": 0.03647168523683228\n",
    "# },\n",
    "# \"mmlu:world_religions\": {\n",
    "# \"acc\": 0.18128654970760233,\n",
    "# \"acc_stderr\": 0.029547741687640027,\n",
    "# \"acc_norm\": 0.24561403508771928,\n",
    "# \"acc_norm_stderr\": 0.03301405946987251\n",
    "# },\n",
    "# \"openbookqa\": {\n",
    "# \"acc\": 0.132,\n",
    "# \"acc_stderr\": 0.015152927850580155,\n",
    "# \"acc_norm\": 0.268,\n",
    "# \"acc_norm_stderr\": 0.019827714859587578\n",
    "# },\n",
    "# \"piqa\": {\n",
    "# \"acc\": 0.571,\n",
    "# \"acc_stderr\": 0.015658997547870236,\n",
    "# \"acc_norm\": 0.58,\n",
    "# \"acc_norm_stderr\": 0.015615500115072959\n",
    "# },\n",
    "# \"siqa\": {\n",
    "# \"acc\": 0.358,\n",
    "# \"acc_stderr\": 0.015167928865407559,\n",
    "# \"acc_norm\": 0.379,\n",
    "# \"acc_norm_stderr\": 0.015349091002225352\n",
    "# },\n",
    "# \"winogrande\": {\n",
    "# \"acc\": 0.512,\n",
    "# \"acc_stderr\": 0.015814743314581818,\n",
    "# \"acc_norm\": 0.509,\n",
    "# \"acc_norm_stderr\": 0.015816736995005392\n",
    "# },\n",
    "# \"arc:_average\": {\n",
    "# \"acc\": 0.27649999999999997,\n",
    "# \"acc_stderr\": 0.013736793060609235,\n",
    "# \"acc_norm\": 0.3055,\n",
    "# \"acc_norm_stderr\": 0.014398024235372016\n",
    "# },\n",
    "# \"mmlu:_average\": {\n",
    "# \"acc\": 0.23854149080775466,\n",
    "# \"acc_stderr\": 0.03163789714288859,\n",
    "# \"acc_norm\": 0.2567727066277369,\n",
    "# \"acc_norm_stderr\": 0.03259073413274518\n",
    "# },\n",
    "#     \"mmlu:professional_medicine\": {\n",
    "#     \"acc\": 0.23529411764705882,\n",
    "#     \"acc_stderr\": 0.02576725201085597,\n",
    "#     \"acc_norm\": 0.23529411764705882,\n",
    "#     \"acc_norm_stderr\": 0.02576725201085598\n",
    "#   },\n",
    "#   \"mmlu:professional_psychology\": {\n",
    "#     \"acc\": 0.2549019607843137,\n",
    "#     \"acc_stderr\": 0.017630827375148383,\n",
    "#     \"acc_norm\": 0.25,\n",
    "#     \"acc_norm_stderr\": 0.01751781884501444\n",
    "#   },\n",
    "#   \"mmlu:public_relations\": {\n",
    "#     \"acc\": 0.35454545454545455,\n",
    "#     \"acc_stderr\": 0.04582004841505417,\n",
    "#     \"acc_norm\": 0.20909090909090908,\n",
    "#     \"acc_norm_stderr\": 0.038950910157241385\n",
    "#   },\n",
    "#   \"mmlu:security_studies\": {\n",
    "#     \"acc\": 0.3142857142857143,\n",
    "#     \"acc_stderr\": 0.02971932942241746,\n",
    "#     \"acc_norm\": 0.19591836734693877,\n",
    "#     \"acc_norm_stderr\": 0.025409301953225678\n",
    "#   },\n",
    "#   \"mmlu:sociology\": {\n",
    "#     \"acc\": 0.21393034825870647,\n",
    "#     \"acc_stderr\": 0.02899690969332891,\n",
    "#     \"acc_norm\": 0.22388059701492538,\n",
    "#     \"acc_norm_stderr\": 0.029475250236017173\n",
    "#   },\n",
    "#   \"mmlu:us_foreign_policy\": {\n",
    "#     \"acc\": 0.24,\n",
    "#     \"acc_stderr\": 0.04292346959909283,\n",
    "#     \"acc_norm\": 0.23,\n",
    "#     \"acc_norm_stderr\": 0.04229525846816505\n",
    "#   },\n",
    "#   \"mmlu:virology\": {\n",
    "#     \"acc\": 0.22289156626506024,\n",
    "#     \"acc_stderr\": 0.03240004825594687,\n",
    "#     \"acc_norm\": 0.3253012048192771,\n",
    "#     \"acc_norm_stderr\": 0.03647168523683227\n",
    "#   },\n",
    "#   \"mmlu:world_religions\": {\n",
    "#     \"acc\": 0.15789473684210525,\n",
    "#     \"acc_stderr\": 0.027966785859160907,\n",
    "#     \"acc_norm\": 0.23391812865497075,\n",
    "#     \"acc_norm_stderr\": 0.032467217651178264\n",
    "#   },\n",
    "#   \"openbookqa\": {\n",
    "#     \"acc\": 0.14,\n",
    "#     \"acc_stderr\": 0.015533272840269622,\n",
    "#     \"acc_norm\": 0.27,\n",
    "#     \"acc_norm_stderr\": 0.01987435483128749\n",
    "#   },\n",
    "#   \"piqa\": {\n",
    "#     \"acc\": 0.568,\n",
    "#     \"acc_stderr\": 0.0156723202373362,\n",
    "#     \"acc_norm\": 0.588,\n",
    "#     \"acc_norm_stderr\": 0.015572363292015091\n",
    "#   },\n",
    "#   \"siqa\": {\n",
    "#     \"acc\": 0.342,\n",
    "#     \"acc_stderr\": 0.015008706182121726,\n",
    "#     \"acc_norm\": 0.375,\n",
    "#     \"acc_norm_stderr\": 0.015316971293620996\n",
    "#   },\n",
    "#   \"winogrande\": {\n",
    "#     \"acc\": 0.511,\n",
    "#     \"acc_stderr\": 0.015815471195292693,\n",
    "#     \"acc_norm\": 0.498,\n",
    "#     \"acc_norm_stderr\": 0.015819173374302706\n",
    "#   },\n",
    "#   \"arc:_average\": {\n",
    "#     \"acc\": 0.277,\n",
    "#     \"acc_stderr\": 0.013694891076312077,\n",
    "#     \"acc_norm\": 0.298,\n",
    "#     \"acc_norm_stderr\": 0.014299871901289755\n",
    "#   },\n",
    "#   \"mmlu:_average\": {\n",
    "#     \"acc\": 0.24486225766415484,\n",
    "#     \"acc_stderr\": 0.03198621725172759,\n",
    "#     \"acc_norm\": 0.26125950385266233,\n",
    "#     \"acc_norm_stderr\": 0.032822076137567394\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e6edf7-256f-4485-b02e-ffd62def05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_25k = {\n",
    "    \"arc:challenge\": {\n",
    "\"acc\": 0.181,\n",
    "\"acc_stderr\": 0.012181436179177893,\n",
    "\"acc_norm\": 0.24,\n",
    "\"acc_norm_stderr\": 0.013512312258920843\n",
    "},\n",
    "\"arc:easy\": {\n",
    "\"acc\": 0.372,\n",
    "\"acc_stderr\": 0.015292149942040577,\n",
    "\"acc_norm\": 0.371,\n",
    "\"acc_norm_stderr\": 0.015283736211823187\n",
    "},\n",
    "\"commonsense_qa\": {\n",
    "\"acc\": 0.233,\n",
    "\"acc_stderr\": 0.013374972519220039,\n",
    "\"acc_norm\": 0.259,\n",
    "\"acc_norm_stderr\": 0.013860415257527911\n",
    "},\n",
    "\"hellaswag\": {\n",
    "\"acc\": 0.289,\n",
    "\"acc_stderr\": 0.014341711358296172,\n",
    "\"acc_norm\": 0.291,\n",
    "\"acc_norm_stderr\": 0.014370995982377944\n",
    "},\n",
    "\"mmlu:abstract_algebra\": {\n",
    "\"acc\": 0.22,\n",
    "\"acc_stderr\": 0.0416333199893227,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.04408440022768078\n",
    "},\n",
    "\"mmlu:anatomy\": {\n",
    "\"acc\": 0.28888888888888886,\n",
    "\"acc_stderr\": 0.03915450630414251,\n",
    "\"acc_norm\": 0.2740740740740741,\n",
    "\"acc_norm_stderr\": 0.03853254836552003\n",
    "},\n",
    "\"mmlu:astronomy\": {\n",
    "\"acc\": 0.23684210526315788,\n",
    "\"acc_stderr\": 0.034597776068105365,\n",
    "\"acc_norm\": 0.27631578947368424,\n",
    "\"acc_norm_stderr\": 0.03639057569952924\n",
    "},\n",
    "\"mmlu:business_ethics\": {\n",
    "\"acc\": 0.36,\n",
    "\"acc_stderr\": 0.048241815132442176,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.04408440022768079\n",
    "},\n",
    "\"mmlu:clinical_knowledge\": {\n",
    "\"acc\": 0.2,\n",
    "\"acc_stderr\": 0.02461829819586651,\n",
    "\"acc_norm\": 0.33584905660377357,\n",
    "\"acc_norm_stderr\": 0.02906722014664483\n",
    "},\n",
    "\"mmlu:college_biology\": {\n",
    "\"acc\": 0.25,\n",
    "\"acc_stderr\": 0.03621034121889507,\n",
    "\"acc_norm\": 0.2361111111111111,\n",
    "\"acc_norm_stderr\": 0.03551446610810826\n",
    "},\n",
    "\"mmlu:college_chemistry\": {\n",
    "\"acc\": 0.29,\n",
    "\"acc_stderr\": 0.045604802157206845,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.0440844002276808\n",
    "},\n",
    "\"mmlu:college_computer_science\": {\n",
    "\"acc\": 0.24,\n",
    "\"acc_stderr\": 0.042923469599092816,\n",
    "\"acc_norm\": 0.23,\n",
    "\"acc_norm_stderr\": 0.042295258468165044\n",
    "},\n",
    "\"mmlu:college_mathematics\": {\n",
    "\"acc\": 0.15,\n",
    "\"acc_stderr\": 0.03588702812826371,\n",
    "\"acc_norm\": 0.24,\n",
    "\"acc_norm_stderr\": 0.04292346959909282\n",
    "},\n",
    "\"mmlu:college_medicine\": {\n",
    "\"acc\": 0.2138728323699422,\n",
    "\"acc_stderr\": 0.03126511206173043,\n",
    "\"acc_norm\": 0.24277456647398843,\n",
    "\"acc_norm_stderr\": 0.0326926380614177\n",
    "},\n",
    "\"mmlu:college_physics\": {\n",
    "\"acc\": 0.22549019607843138,\n",
    "\"acc_stderr\": 0.041583075330832865,\n",
    "\"acc_norm\": 0.24509803921568626,\n",
    "\"acc_norm_stderr\": 0.04280105837364396\n",
    "},\n",
    "\"mmlu:computer_security\": {\n",
    "\"acc\": 0.22,\n",
    "\"acc_stderr\": 0.04163331998932269,\n",
    "\"acc_norm\": 0.23,\n",
    "\"acc_norm_stderr\": 0.042295258468165044\n",
    "},\n",
    "\"mmlu:conceptual_physics\": {\n",
    "\"acc\": 0.3276595744680851,\n",
    "\"acc_stderr\": 0.030683020843231,\n",
    "\"acc_norm\": 0.2297872340425532,\n",
    "\"acc_norm_stderr\": 0.027501752944412417\n",
    "},\n",
    "\"mmlu:econometrics\": {\n",
    "\"acc\": 0.16666666666666666,\n",
    "\"acc_stderr\": 0.03505859682597264,\n",
    "\"acc_norm\": 0.21929824561403508,\n",
    "\"acc_norm_stderr\": 0.038924311065187546\n",
    "},\n",
    "\"mmlu:electrical_engineering\": {\n",
    "\"acc\": 0.2413793103448276,\n",
    "\"acc_stderr\": 0.03565998174135302,\n",
    "\"acc_norm\": 0.2827586206896552,\n",
    "\"acc_norm_stderr\": 0.03752833958003337\n",
    "},\n",
    "\"mmlu:elementary_mathematics\": {\n",
    "\"acc\": 0.2037037037037037,\n",
    "\"acc_stderr\": 0.020742740560122663,\n",
    "\"acc_norm\": 0.21164021164021163,\n",
    "\"acc_norm_stderr\": 0.021037331505262886\n",
    "},\n",
    "\"mmlu:formal_logic\": {\n",
    "\"acc\": 0.2857142857142857,\n",
    "\"acc_stderr\": 0.0404061017820884,\n",
    "\"acc_norm\": 0.23015873015873015,\n",
    "\"acc_norm_stderr\": 0.03764950879790605\n",
    "},\n",
    "\"mmlu:global_facts\": {\n",
    "\"acc\": 0.25,\n",
    "\"acc_stderr\": 0.04351941398892446,\n",
    "\"acc_norm\": 0.24,\n",
    "\"acc_norm_stderr\": 0.042923469599092816\n",
    "},\n",
    "\"mmlu:high_school_biology\": {\n",
    "\"acc\": 0.22903225806451613,\n",
    "\"acc_stderr\": 0.023904914311782648,\n",
    "\"acc_norm\": 0.29354838709677417,\n",
    "\"acc_norm_stderr\": 0.02590608702131929\n",
    "},\n",
    "\"mmlu:high_school_chemistry\": {\n",
    "\"acc\": 0.1625615763546798,\n",
    "\"acc_stderr\": 0.0259603000646056,\n",
    "\"acc_norm\": 0.19704433497536947,\n",
    "\"acc_norm_stderr\": 0.027986724666736223\n",
    "},\n",
    "\"mmlu:high_school_computer_science\": {\n",
    "\"acc\": 0.22,\n",
    "\"acc_stderr\": 0.041633319989322695,\n",
    "\"acc_norm\": 0.28,\n",
    "\"acc_norm_stderr\": 0.045126085985421296\n",
    "},\n",
    "\"mmlu:high_school_european_history\": {\n",
    "\"acc\": 0.18181818181818182,\n",
    "\"acc_stderr\": 0.030117688929503582,\n",
    "\"acc_norm\": 0.28484848484848485,\n",
    "\"acc_norm_stderr\": 0.03524390844511782\n",
    "},\n",
    "\"mmlu:high_school_geography\": {\n",
    "\"acc\": 0.25252525252525254,\n",
    "\"acc_stderr\": 0.030954055470365907,\n",
    "\"acc_norm\": 0.2777777777777778,\n",
    "\"acc_norm_stderr\": 0.03191178226713546\n",
    "},\n",
    "\"mmlu:high_school_government_and_politics\": {\n",
    "\"acc\": 0.23316062176165803,\n",
    "\"acc_stderr\": 0.030516111371476008,\n",
    "\"acc_norm\": 0.26424870466321243,\n",
    "\"acc_norm_stderr\": 0.03182155050916646\n",
    "},\n",
    "\"mmlu:high_school_macroeconomics\": {\n",
    "\"acc\": 0.26153846153846155,\n",
    "\"acc_stderr\": 0.022282141204204426,\n",
    "\"acc_norm\": 0.28205128205128205,\n",
    "\"acc_norm_stderr\": 0.022815813098896603\n",
    "},\n",
    "\"mmlu:high_school_mathematics\": {\n",
    "\"acc\": 0.12962962962962962,\n",
    "\"acc_stderr\": 0.020479910253320705,\n",
    "\"acc_norm\": 0.15185185185185185,\n",
    "\"acc_norm_stderr\": 0.021881130957380476\n",
    "},\n",
    "\"mmlu:high_school_microeconomics\": {\n",
    "\"acc\": 0.23949579831932774,\n",
    "\"acc_stderr\": 0.02772206549336128,\n",
    "\"acc_norm\": 0.31932773109243695,\n",
    "\"acc_norm_stderr\": 0.030283995525884396\n",
    "},\n",
    "\"mmlu:high_school_physics\": {\n",
    "\"acc\": 0.23841059602649006,\n",
    "\"acc_stderr\": 0.034791855725996586,\n",
    "\"acc_norm\": 0.26490066225165565,\n",
    "\"acc_norm_stderr\": 0.03603038545360384\n",
    "},\n",
    "\"mmlu:high_school_psychology\": {\n",
    "\"acc\": 0.29908256880733947,\n",
    "\"acc_stderr\": 0.019630417285415175,\n",
    "\"acc_norm\": 0.28073394495412846,\n",
    "\"acc_norm_stderr\": 0.019266055045871616\n",
    "},\n",
    "\"mmlu:high_school_statistics\": {\n",
    "\"acc\": 0.25925925925925924,\n",
    "\"acc_stderr\": 0.02988691054762696,\n",
    "\"acc_norm\": 0.28703703703703703,\n",
    "\"acc_norm_stderr\": 0.03085199299325701\n",
    "},\n",
    "\"mmlu:high_school_us_history\": {\n",
    "\"acc\": 0.23529411764705882,\n",
    "\"acc_stderr\": 0.029771775228145652,\n",
    "\"acc_norm\": 0.30392156862745096,\n",
    "\"acc_norm_stderr\": 0.03228210387037894\n",
    "},\n",
    "\"mmlu:high_school_world_history\": {\n",
    "\"acc\": 0.21940928270042195,\n",
    "\"acc_stderr\": 0.026939106581553945,\n",
    "\"acc_norm\": 0.2616033755274262,\n",
    "\"acc_norm_stderr\": 0.028609516716994934\n",
    "},\n",
    "\"mmlu:human_aging\": {\n",
    "\"acc\": 0.3094170403587444,\n",
    "\"acc_stderr\": 0.03102441174057222,\n",
    "\"acc_norm\": 0.2825112107623318,\n",
    "\"acc_norm_stderr\": 0.030216831011508766\n",
    "},\n",
    "\"mmlu:human_sexuality\": {\n",
    "\"acc\": 0.33587786259541985,\n",
    "\"acc_stderr\": 0.041423137719966634,\n",
    "\"acc_norm\": 0.31297709923664124,\n",
    "\"acc_norm_stderr\": 0.04066962905677697\n",
    "},\n",
    "\"mmlu:international_law\": {\n",
    "\"acc\": 0.11570247933884298,\n",
    "\"acc_stderr\": 0.029199802455622783,\n",
    "\"acc_norm\": 0.256198347107438,\n",
    "\"acc_norm_stderr\": 0.03984979653302871\n",
    "},\n",
    "\"mmlu:jurisprudence\": {\n",
    "\"acc\": 0.1574074074074074,\n",
    "\"acc_stderr\": 0.03520703990517963,\n",
    "\"acc_norm\": 0.23148148148148148,\n",
    "\"acc_norm_stderr\": 0.04077494709252627\n",
    "},\n",
    "\"mmlu:logical_fallacies\": {\n",
    "\"acc\": 0.27607361963190186,\n",
    "\"acc_stderr\": 0.0351238528370505,\n",
    "\"acc_norm\": 0.3558282208588957,\n",
    "\"acc_norm_stderr\": 0.03761521380046734\n",
    "},\n",
    "\"mmlu:machine_learning\": {\n",
    "\"acc\": 0.21428571428571427,\n",
    "\"acc_stderr\": 0.03894641120044792,\n",
    "\"acc_norm\": 0.21428571428571427,\n",
    "\"acc_norm_stderr\": 0.038946411200447915\n",
    "},\n",
    "\"mmlu:management\": {\n",
    "\"acc\": 0.22330097087378642,\n",
    "\"acc_stderr\": 0.04123553189891431,\n",
    "\"acc_norm\": 0.22330097087378642,\n",
    "\"acc_norm_stderr\": 0.04123553189891431\n",
    "},\n",
    "\"mmlu:marketing\": {\n",
    "\"acc\": 0.2948717948717949,\n",
    "\"acc_stderr\": 0.029872577708891165,\n",
    "\"acc_norm\": 0.32905982905982906,\n",
    "\"acc_norm_stderr\": 0.030782321577688156\n",
    "},\n",
    "\"mmlu:medical_genetics\": {\n",
    "\"acc\": 0.23,\n",
    "\"acc_stderr\": 0.04229525846816506,\n",
    "\"acc_norm\": 0.25,\n",
    "\"acc_norm_stderr\": 0.04351941398892446\n",
    "},\n",
    "\"mmlu:miscellaneous\": {\n",
    "\"acc\": 0.2720306513409962,\n",
    "\"acc_stderr\": 0.015913367447500517,\n",
    "\"acc_norm\": 0.26181353767560667,\n",
    "\"acc_norm_stderr\": 0.015720838678445266\n",
    "},\n",
    "\"mmlu:moral_disputes\": {\n",
    "\"acc\": 0.20520231213872833,\n",
    "\"acc_stderr\": 0.021742519835276305,\n",
    "\"acc_norm\": 0.1676300578034682,\n",
    "\"acc_norm_stderr\": 0.020110579919734833\n",
    "},\n",
    "\"mmlu:moral_scenarios\": {\n",
    "\"acc\": 0.23798882681564246,\n",
    "\"acc_stderr\": 0.014242630070574915,\n",
    "\"acc_norm\": 0.27262569832402234,\n",
    "\"acc_norm_stderr\": 0.014893391735249588\n",
    "},\n",
    "\"mmlu:nutrition\": {\n",
    "\"acc\": 0.20588235294117646,\n",
    "\"acc_stderr\": 0.023152722439402307,\n",
    "\"acc_norm\": 0.29411764705882354,\n",
    "\"acc_norm_stderr\": 0.026090162504279056\n",
    "},\n",
    "\"mmlu:philosophy\": {\n",
    "\"acc\": 0.21543408360128619,\n",
    "\"acc_stderr\": 0.023350225475471414,\n",
    "\"acc_norm\": 0.2829581993569132,\n",
    "\"acc_norm_stderr\": 0.025583062489984834\n",
    "},\n",
    "\"mmlu:prehistory\": {\n",
    "\"acc\": 0.27469135802469136,\n",
    "\"acc_stderr\": 0.024836057868294688,\n",
    "\"acc_norm\": 0.19753086419753085,\n",
    "\"acc_norm_stderr\": 0.022152889927898975\n",
    "},\n",
    "\"mmlu:professional_accounting\": {\n",
    "\"acc\": 0.25886524822695034,\n",
    "\"acc_stderr\": 0.026129572527180848,\n",
    "\"acc_norm\": 0.22695035460992907,\n",
    "\"acc_norm_stderr\": 0.02498710636564296\n",
    "},\n",
    "\"mmlu:professional_law\": {\n",
    "\"acc\": 0.232,\n",
    "\"acc_stderr\": 0.013354937452281558,\n",
    "\"acc_norm\": 0.254,\n",
    "\"acc_norm_stderr\": 0.013772206565168544\n",
    "},\n",
    "\"mmlu:professional_medicine\": {\n",
    "\"acc\": 0.23529411764705882,\n",
    "\"acc_stderr\": 0.02576725201085596,\n",
    "\"acc_norm\": 0.2536764705882353,\n",
    "\"acc_norm_stderr\": 0.02643132987078954\n",
    "},\n",
    "\"mmlu:professional_psychology\": {\n",
    "\"acc\": 0.26143790849673204,\n",
    "\"acc_stderr\": 0.017776947157528037,\n",
    "\"acc_norm\": 0.2679738562091503,\n",
    "\"acc_norm_stderr\": 0.017917974069594726\n",
    "},\n",
    "\"mmlu:public_relations\": {\n",
    "\"acc\": 0.33636363636363636,\n",
    "\"acc_stderr\": 0.04525393596302506,\n",
    "\"acc_norm\": 0.24545454545454545,\n",
    "\"acc_norm_stderr\": 0.041220665028782834\n",
    "},\n",
    "    \"mmlu:security_studies\": {\n",
    "\"acc\": 0.30612244897959184,\n",
    "\"acc_stderr\": 0.029504896454595968,\n",
    "\"acc_norm\": 0.20816326530612245,\n",
    "\"acc_norm_stderr\": 0.025991117672813296\n",
    "},\n",
    "\"mmlu:sociology\": {\n",
    "\"acc\": 0.21890547263681592,\n",
    "\"acc_stderr\": 0.029239174636647,\n",
    "\"acc_norm\": 0.23383084577114427,\n",
    "\"acc_norm_stderr\": 0.02992941540834839\n",
    "},\n",
    "\"mmlu:us_foreign_policy\": {\n",
    "\"acc\": 0.22,\n",
    "\"acc_stderr\": 0.04163331998932269,\n",
    "\"acc_norm\": 0.19,\n",
    "\"acc_norm_stderr\": 0.03942772444036623\n",
    "},\n",
    "\"mmlu:virology\": {\n",
    "\"acc\": 0.2469879518072289,\n",
    "\"acc_stderr\": 0.03357351982064536,\n",
    "\"acc_norm\": 0.3253012048192771,\n",
    "\"acc_norm_stderr\": 0.03647168523683228\n",
    "},\n",
    "\"mmlu:world_religions\": {\n",
    "\"acc\": 0.18128654970760233,\n",
    "\"acc_stderr\": 0.029547741687640027,\n",
    "\"acc_norm\": 0.24561403508771928,\n",
    "\"acc_norm_stderr\": 0.03301405946987251\n",
    "},\n",
    "\"openbookqa\": {\n",
    "\"acc\": 0.132,\n",
    "\"acc_stderr\": 0.015152927850580155,\n",
    "\"acc_norm\": 0.268,\n",
    "\"acc_norm_stderr\": 0.019827714859587578\n",
    "},\n",
    "\"piqa\": {\n",
    "\"acc\": 0.571,\n",
    "\"acc_stderr\": 0.015658997547870236,\n",
    "\"acc_norm\": 0.58,\n",
    "\"acc_norm_stderr\": 0.015615500115072959\n",
    "},\n",
    "\"siqa\": {\n",
    "\"acc\": 0.358,\n",
    "\"acc_stderr\": 0.015167928865407559,\n",
    "\"acc_norm\": 0.379,\n",
    "\"acc_norm_stderr\": 0.015349091002225352\n",
    "},\n",
    "\"winogrande\": {\n",
    "\"acc\": 0.512,\n",
    "\"acc_stderr\": 0.015814743314581818,\n",
    "\"acc_norm\": 0.509,\n",
    "\"acc_norm_stderr\": 0.015816736995005392\n",
    "},\n",
    "\"arc:_average\": {\n",
    "\"acc\": 0.27649999999999997,\n",
    "\"acc_stderr\": 0.013736793060609235,\n",
    "\"acc_norm\": 0.3055,\n",
    "\"acc_norm_stderr\": 0.014398024235372016\n",
    "},\n",
    "\"mmlu:_average\": {\n",
    "\"acc\": 0.23854149080775466,\n",
    "\"acc_stderr\": 0.03163789714288859,\n",
    "\"acc_norm\": 0.2567727066277369,\n",
    "\"acc_norm_stderr\": 0.03259073413274518\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac8b77e-343f-413b-a3ea-d12e73ebbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doremi_data_25k = {\n",
    "    \"arc:_average\": {\n",
    "    \"acc\": 0.277,\n",
    "    \"acc_stderr\": 0.013694891076312077,\n",
    "    \"acc_norm\": 0.298,\n",
    "    \"acc_norm_stderr\": 0.014299871901289755\n",
    "    },\n",
    "    \"arc:challenge\": {\n",
    "    \"acc\": 0.176,\n",
    "    \"acc_stderr\": 0.01204861689859751,\n",
    "    \"acc_norm\": 0.234,\n",
    "    \"acc_norm_stderr\": 0.013394902889660009\n",
    "    },\n",
    "    \"arc:easy\": {\n",
    "    \"acc\": 0.378,\n",
    "    \"acc_stderr\": 0.015341165254026644,\n",
    "    \"acc_norm\": 0.362,\n",
    "    \"acc_norm_stderr\": 0.015204840912919501\n",
    "    },\n",
    "    \"commonsense_qa\": {\n",
    "    \"acc\": 0.209,\n",
    "    \"acc_stderr\": 0.012864077288499344,\n",
    "    \"acc_norm\": 0.256,\n",
    "    \"acc_norm_stderr\": 0.013807775152234202\n",
    "    },\n",
    "    \"hellaswag\": {\n",
    "    \"acc\": 0.281,\n",
    "    \"acc_stderr\": 0.014221154708434925,\n",
    "    \"acc_norm\": 0.287,\n",
    "    \"acc_norm_stderr\": 0.014312087053809965\n",
    "    },\n",
    "    \"mmlu:_average\": {\n",
    "    \"acc\": 0.24486225766415484,\n",
    "    \"acc_stderr\": 0.03198621725172759,\n",
    "    \"acc_norm\": 0.26125950385266233,\n",
    "    \"acc_norm_stderr\": 0.032822076137567394\n",
    "    },\n",
    "    \"mmlu:abstract_algebra\": {\n",
    "    \"acc\": 0.23,\n",
    "    \"acc_stderr\": 0.04229525846816508,\n",
    "    \"acc_norm\": 0.21,\n",
    "    \"acc_norm_stderr\": 0.040936018074033256\n",
    "    },\n",
    "    \"mmlu:anatomy\": {\n",
    "    \"acc\": 0.2814814814814815,\n",
    "    \"acc_stderr\": 0.03885004245800253,\n",
    "    \"acc_norm\": 0.2518518518518518,\n",
    "    \"acc_norm_stderr\": 0.03749850709174022\n",
    "    },\n",
    "    \"mmlu:astronomy\": {\n",
    "    \"acc\": 0.21052631578947367,\n",
    "    \"acc_stderr\": 0.03317672787533156,\n",
    "    \"acc_norm\": 0.28289473684210525,\n",
    "    \"acc_norm_stderr\": 0.03665349695640767\n",
    "    },\n",
    "    \"mmlu:business_ethics\": {\n",
    "    \"acc\": 0.38,\n",
    "    \"acc_stderr\": 0.04878317312145633,\n",
    "    \"acc_norm\": 0.28,\n",
    "    \"acc_norm_stderr\": 0.04512608598542127\n",
    "    },\n",
    "    \"mmlu:clinical_knowledge\": {\n",
    "    \"acc\": 0.21132075471698114,\n",
    "    \"acc_stderr\": 0.025125766484827835,\n",
    "    \"acc_norm\": 0.30943396226415093,\n",
    "    \"acc_norm_stderr\": 0.028450154794118627\n",
    "    },\n",
    "    \"mmlu:college_biology\": {\n",
    "    \"acc\": 0.2638888888888889,\n",
    "    \"acc_stderr\": 0.03685651095897532,\n",
    "    \"acc_norm\": 0.2777777777777778,\n",
    "    \"acc_norm_stderr\": 0.03745554791462457\n",
    "    },\n",
    "    \"mmlu:college_chemistry\": {\n",
    "    \"acc\": 0.3,\n",
    "    \"acc_stderr\": 0.046056618647183814,\n",
    "    \"acc_norm\": 0.3,\n",
    "    \"acc_norm_stderr\": 0.046056618647183814\n",
    "    },\n",
    "    \"mmlu:college_computer_science\": {\n",
    "    \"acc\": 0.22,\n",
    "    \"acc_stderr\": 0.04163331998932269,\n",
    "    \"acc_norm\": 0.21,\n",
    "    \"acc_norm_stderr\": 0.040936018074033256\n",
    "    },\n",
    "    \"mmlu:college_mathematics\": {\n",
    "    \"acc\": 0.15,\n",
    "    \"acc_stderr\": 0.03588702812826371,\n",
    "    \"acc_norm\": 0.23,\n",
    "    \"acc_norm_stderr\": 0.04229525846816505\n",
    "    },\n",
    "    \"mmlu:college_medicine\": {\n",
    "    \"acc\": 0.26011560693641617,\n",
    "    \"acc_stderr\": 0.033450369167889925,\n",
    "    \"acc_norm\": 0.2543352601156069,\n",
    "    \"acc_norm_stderr\": 0.0332055644308557\n",
    "    },\n",
    "    \"mmlu:college_physics\": {\n",
    "    \"acc\": 0.20588235294117646,\n",
    "    \"acc_stderr\": 0.040233822736177476,\n",
    "    \"acc_norm\": 0.20588235294117646,\n",
    "    \"acc_norm_stderr\": 0.04023382273617747\n",
    "    },\n",
    "    \"mmlu:computer_security\": {\n",
    "    \"acc\": 0.18,\n",
    "    \"acc_stderr\": 0.03861229196653694,\n",
    "    \"acc_norm\": 0.25,\n",
    "    \"acc_norm_stderr\": 0.04351941398892446\n",
    "    },\n",
    "    \"mmlu:conceptual_physics\": {\n",
    "    \"acc\": 0.3191489361702128,\n",
    "    \"acc_stderr\": 0.030472973363380042,\n",
    "    \"acc_norm\": 0.22127659574468084,\n",
    "    \"acc_norm_stderr\": 0.027136349602424063\n",
    "    },\n",
    "    \"mmlu:econometrics\": {\n",
    "    \"acc\": 0.20175438596491227,\n",
    "    \"acc_stderr\": 0.037752050135836386,\n",
    "    \"acc_norm\": 0.20175438596491227,\n",
    "    \"acc_norm_stderr\": 0.03775205013583639\n",
    "    },\n",
    "    \"mmlu:electrical_engineering\": {\n",
    "    \"acc\": 0.23448275862068965,\n",
    "    \"acc_stderr\": 0.035306258743465914,\n",
    "    \"acc_norm\": 0.2620689655172414,\n",
    "    \"acc_norm_stderr\": 0.036646663372252565\n",
    "    },\n",
    "    \"mmlu:elementary_mathematics\": {\n",
    "    \"acc\": 0.22486772486772486,\n",
    "    \"acc_stderr\": 0.02150209607822914,\n",
    "    \"acc_norm\": 0.22486772486772486,\n",
    "    \"acc_norm_stderr\": 0.02150209607822914\n",
    "    },\n",
    "    \"mmlu:formal_logic\": {\n",
    "    \"acc\": 0.2698412698412698,\n",
    "    \"acc_stderr\": 0.03970158273235171,\n",
    "    \"acc_norm\": 0.25396825396825395,\n",
    "    \"acc_norm_stderr\": 0.03893259610604674\n",
    "    },\n",
    "    \"mmlu:global_facts\": {\n",
    "    \"acc\": 0.29,\n",
    "    \"acc_stderr\": 0.045604802157206845,\n",
    "    \"acc_norm\": 0.32,\n",
    "    \"acc_norm_stderr\": 0.04688261722621504\n",
    "    },\n",
    "    \"mmlu:high_school_biology\": {\n",
    "    \"acc\": 0.24838709677419354,\n",
    "    \"acc_stderr\": 0.024580028921480996,\n",
    "    \"acc_norm\": 0.27419354838709675,\n",
    "    \"acc_norm_stderr\": 0.025378139970885193\n",
    "    },\n",
    "    \"mmlu:high_school_chemistry\": {\n",
    "    \"acc\": 0.2019704433497537,\n",
    "    \"acc_stderr\": 0.028247350122180284,\n",
    "    \"acc_norm\": 0.22167487684729065,\n",
    "    \"acc_norm_stderr\": 0.029225575892489614\n",
    "    },\n",
    "    \"mmlu:high_school_computer_science\": {\n",
    "    \"acc\": 0.25,\n",
    "    \"acc_stderr\": 0.04351941398892446,\n",
    "    \"acc_norm\": 0.3,\n",
    "    \"acc_norm_stderr\": 0.046056618647183814\n",
    "    },\n",
    "    \"mmlu:high_school_european_history\": {\n",
    "    \"acc\": 0.21818181818181817,\n",
    "    \"acc_stderr\": 0.03225078108306289,\n",
    "    \"acc_norm\": 0.3090909090909091,\n",
    "    \"acc_norm_stderr\": 0.036085410115739666\n",
    "    },\n",
    "    \"mmlu:high_school_geography\": {\n",
    "    \"acc\": 0.25757575757575757,\n",
    "    \"acc_stderr\": 0.031156269519646836,\n",
    "    \"acc_norm\": 0.29292929292929293,\n",
    "    \"acc_norm_stderr\": 0.03242497958178818\n",
    "    },\n",
    "    \"mmlu:high_school_government_and_politics\": {\n",
    "    \"acc\": 0.23316062176165803,\n",
    "    \"acc_stderr\": 0.030516111371476008,\n",
    "    \"acc_norm\": 0.2694300518134715,\n",
    "    \"acc_norm_stderr\": 0.03201867122877793\n",
    "    },\n",
    "    \"mmlu:high_school_macroeconomics\": {\n",
    "    \"acc\": 0.23333333333333334,\n",
    "    \"acc_stderr\": 0.021444547301560476,\n",
    "    \"acc_norm\": 0.26666666666666666,\n",
    "    \"acc_norm_stderr\": 0.022421273612923714\n",
    "    },\n",
    "    \"mmlu:high_school_mathematics\": {\n",
    "    \"acc\": 0.13333333333333333,\n",
    "    \"acc_stderr\": 0.020726180448133867,\n",
    "    \"acc_norm\": 0.16666666666666666,\n",
    "    \"acc_norm_stderr\": 0.02272257846455052\n",
    "    },\n",
    "    \"mmlu:high_school_microeconomics\": {\n",
    "    \"acc\": 0.23949579831932774,\n",
    "    \"acc_stderr\": 0.02772206549336127,\n",
    "    \"acc_norm\": 0.33613445378151263,\n",
    "    \"acc_norm_stderr\": 0.030684737115135363\n",
    "    },\n",
    "    \"mmlu:high_school_physics\": {\n",
    "    \"acc\": 0.23178807947019867,\n",
    "    \"acc_stderr\": 0.03445406271987054,\n",
    "    \"acc_norm\": 0.2847682119205298,\n",
    "    \"acc_norm_stderr\": 0.03684881521389023\n",
    "    },\n",
    "    \"mmlu:high_school_psychology\": {\n",
    "    \"acc\": 0.28256880733944956,\n",
    "    \"acc_stderr\": 0.01930424349770715,\n",
    "    \"acc_norm\": 0.26605504587155965,\n",
    "    \"acc_norm_stderr\": 0.01894602232222559\n",
    "    },\n",
    "    \"mmlu:high_school_statistics\": {\n",
    "    \"acc\": 0.2638888888888889,\n",
    "    \"acc_stderr\": 0.030058202704309846,\n",
    "    \"acc_norm\": 0.2962962962962963,\n",
    "    \"acc_norm_stderr\": 0.031141447823536037\n",
    "    },\n",
    "    \"mmlu:high_school_us_history\": {\n",
    "    \"acc\": 0.24509803921568626,\n",
    "    \"acc_stderr\": 0.03019028245350194,\n",
    "    \"acc_norm\": 0.28921568627450983,\n",
    "    \"acc_norm_stderr\": 0.031822318676475524\n",
    "    },\n",
    "    \"mmlu:high_school_world_history\": {\n",
    "    \"acc\": 0.24050632911392406,\n",
    "    \"acc_stderr\": 0.027820781981149675,\n",
    "    \"acc_norm\": 0.25738396624472576,\n",
    "    \"acc_norm_stderr\": 0.02845882099146029\n",
    "    },\n",
    "    \"mmlu:human_aging\": {\n",
    "    \"acc\": 0.3542600896860987,\n",
    "    \"acc_stderr\": 0.032100621541349864,\n",
    "    \"acc_norm\": 0.3004484304932735,\n",
    "    \"acc_norm_stderr\": 0.030769352008229143\n",
    "    },\n",
    "    \"mmlu:human_sexuality\": {\n",
    "    \"acc\": 0.32061068702290074,\n",
    "    \"acc_stderr\": 0.04093329229834278,\n",
    "    \"acc_norm\": 0.33587786259541985,\n",
    "    \"acc_norm_stderr\": 0.04142313771996665\n",
    "    },\n",
    "    \"mmlu:international_law\": {\n",
    "    \"acc\": 0.1487603305785124,\n",
    "    \"acc_stderr\": 0.03248470083807194,\n",
    "    \"acc_norm\": 0.21487603305785125,\n",
    "    \"acc_norm_stderr\": 0.037494924487096994\n",
    "    },\n",
    "    \"mmlu:jurisprudence\": {\n",
    "    \"acc\": 0.2037037037037037,\n",
    "    \"acc_stderr\": 0.03893542518824847,\n",
    "    \"acc_norm\": 0.25,\n",
    "    \"acc_norm_stderr\": 0.04186091791394607\n",
    "    },\n",
    "    \"mmlu:logical_fallacies\": {\n",
    "    \"acc\": 0.3006134969325153,\n",
    "    \"acc_stderr\": 0.0360251131880677,\n",
    "    \"acc_norm\": 0.3312883435582822,\n",
    "    \"acc_norm_stderr\": 0.03697983910025588\n",
    "    },\n",
    "    \"mmlu:machine_learning\": {\n",
    "    \"acc\": 0.2767857142857143,\n",
    "    \"acc_stderr\": 0.04246624336697625,\n",
    "    \"acc_norm\": 0.2767857142857143,\n",
    "    \"acc_norm_stderr\": 0.042466243366976256\n",
    "    },\n",
    "    \"mmlu:management\": {\n",
    "    \"acc\": 0.24271844660194175,\n",
    "    \"acc_stderr\": 0.04245022486384495,\n",
    "    \"acc_norm\": 0.30097087378640774,\n",
    "    \"acc_norm_stderr\": 0.04541609446503947\n",
    "    },\n",
    "    \"mmlu:marketing\": {\n",
    "    \"acc\": 0.3076923076923077,\n",
    "    \"acc_stderr\": 0.03023638994217309,\n",
    "    \"acc_norm\": 0.3162393162393162,\n",
    "    \"acc_norm_stderr\": 0.030463656747340265\n",
    "    },\n",
    "    \"mmlu:medical_genetics\": {\n",
    "    \"acc\": 0.21,\n",
    "    \"acc_stderr\": 0.040936018074033256,\n",
    "    \"acc_norm\": 0.27,\n",
    "    \"acc_norm_stderr\": 0.044619604333847394\n",
    "    },\n",
    "    \"mmlu:miscellaneous\": {\n",
    "    \"acc\": 0.2720306513409962,\n",
    "    \"acc_stderr\": 0.015913367447500514,\n",
    "    \"acc_norm\": 0.2707535121328225,\n",
    "    \"acc_norm_stderr\": 0.015889888362560486\n",
    "    },\n",
    "    \"mmlu:moral_disputes\": {\n",
    "    \"acc\": 0.1907514450867052,\n",
    "    \"acc_stderr\": 0.021152676966575294,\n",
    "    \"acc_norm\": 0.1936416184971098,\n",
    "    \"acc_norm_stderr\": 0.021274230317515543\n",
    "    },\n",
    "    \"mmlu:moral_scenarios\": {\n",
    "    \"acc\": 0.23798882681564246,\n",
    "    \"acc_stderr\": 0.014242630070574915,\n",
    "    \"acc_norm\": 0.27262569832402234,\n",
    "    \"acc_norm_stderr\": 0.014893391735249588\n",
    "    },\n",
    "    \"mmlu:nutrition\": {\n",
    "    \"acc\": 0.2222222222222222,\n",
    "    \"acc_stderr\": 0.02380518652488813,\n",
    "    \"acc_norm\": 0.29411764705882354,\n",
    "    \"acc_norm_stderr\": 0.02609016250427905\n",
    "    },\n",
    "    \"mmlu:philosophy\": {\n",
    "    \"acc\": 0.2090032154340836,\n",
    "    \"acc_stderr\": 0.023093140398374224,\n",
    "    \"acc_norm\": 0.26688102893890675,\n",
    "    \"acc_norm_stderr\": 0.025122637608816636\n",
    "    },\n",
    "    \"mmlu:prehistory\": {\n",
    "    \"acc\": 0.2623456790123457,\n",
    "    \"acc_stderr\": 0.02447722285613512,\n",
    "    \"acc_norm\": 0.2222222222222222,\n",
    "    \"acc_norm_stderr\": 0.023132376234543353\n",
    "    },\n",
    "    \"mmlu:professional_accounting\": {\n",
    "    \"acc\": 0.2553191489361702,\n",
    "    \"acc_stderr\": 0.02601199293090202,\n",
    "    \"acc_norm\": 0.23404255319148937,\n",
    "    \"acc_norm_stderr\": 0.025257861359432414\n",
    "    },\n",
    "    \"mmlu:professional_law\": {\n",
    "    \"acc\": 0.236,\n",
    "    \"acc_stderr\": 0.013434451402438697,\n",
    "    \"acc_norm\": 0.261,\n",
    "    \"acc_norm_stderr\": 0.013895037677965126\n",
    "    },\n",
    "    \"mmlu:professional_medicine\": {\n",
    "    \"acc\": 0.23529411764705882,\n",
    "    \"acc_stderr\": 0.02576725201085597,\n",
    "    \"acc_norm\": 0.23529411764705882,\n",
    "    \"acc_norm_stderr\": 0.02576725201085598\n",
    "    },\n",
    "    \"mmlu:professional_medicine\": {\n",
    "    \"acc\": 0.23529411764705882,\n",
    "    \"acc_stderr\": 0.02576725201085597,\n",
    "    \"acc_norm\": 0.23529411764705882,\n",
    "    \"acc_norm_stderr\": 0.02576725201085598\n",
    "  },\n",
    "  \"mmlu:professional_psychology\": {\n",
    "    \"acc\": 0.2549019607843137,\n",
    "    \"acc_stderr\": 0.017630827375148383,\n",
    "    \"acc_norm\": 0.25,\n",
    "    \"acc_norm_stderr\": 0.01751781884501444\n",
    "  },\n",
    "  \"mmlu:public_relations\": {\n",
    "    \"acc\": 0.35454545454545455,\n",
    "    \"acc_stderr\": 0.04582004841505417,\n",
    "    \"acc_norm\": 0.20909090909090908,\n",
    "    \"acc_norm_stderr\": 0.038950910157241385\n",
    "  },\n",
    "  \"mmlu:security_studies\": {\n",
    "    \"acc\": 0.3142857142857143,\n",
    "    \"acc_stderr\": 0.02971932942241746,\n",
    "    \"acc_norm\": 0.19591836734693877,\n",
    "    \"acc_norm_stderr\": 0.025409301953225678\n",
    "  },\n",
    "  \"mmlu:sociology\": {\n",
    "    \"acc\": 0.21393034825870647,\n",
    "    \"acc_stderr\": 0.02899690969332891,\n",
    "    \"acc_norm\": 0.22388059701492538,\n",
    "    \"acc_norm_stderr\": 0.029475250236017173\n",
    "  },\n",
    "  \"mmlu:us_foreign_policy\": {\n",
    "    \"acc\": 0.24,\n",
    "    \"acc_stderr\": 0.04292346959909283,\n",
    "    \"acc_norm\": 0.23,\n",
    "    \"acc_norm_stderr\": 0.04229525846816505\n",
    "  },\n",
    "  \"mmlu:virology\": {\n",
    "    \"acc\": 0.22289156626506024,\n",
    "    \"acc_stderr\": 0.03240004825594687,\n",
    "    \"acc_norm\": 0.3253012048192771,\n",
    "    \"acc_norm_stderr\": 0.03647168523683227\n",
    "  },\n",
    "  \"mmlu:world_religions\": {\n",
    "    \"acc\": 0.15789473684210525,\n",
    "    \"acc_stderr\": 0.027966785859160907,\n",
    "    \"acc_norm\": 0.23391812865497075,\n",
    "    \"acc_norm_stderr\": 0.032467217651178264\n",
    "  },\n",
    "  \"openbookqa\": {\n",
    "    \"acc\": 0.14,\n",
    "    \"acc_stderr\": 0.015533272840269622,\n",
    "    \"acc_norm\": 0.27,\n",
    "    \"acc_norm_stderr\": 0.01987435483128749\n",
    "  },\n",
    "  \"piqa\": {\n",
    "    \"acc\": 0.568,\n",
    "    \"acc_stderr\": 0.0156723202373362,\n",
    "    \"acc_norm\": 0.588,\n",
    "    \"acc_norm_stderr\": 0.015572363292015091\n",
    "  },\n",
    "  \"siqa\": {\n",
    "    \"acc\": 0.342,\n",
    "    \"acc_stderr\": 0.015008706182121726,\n",
    "    \"acc_norm\": 0.375,\n",
    "    \"acc_norm_stderr\": 0.015316971293620996\n",
    "  },\n",
    "  \"winogrande\": {\n",
    "    \"acc\": 0.511,\n",
    "    \"acc_stderr\": 0.015815471195292693,\n",
    "    \"acc_norm\": 0.498,\n",
    "    \"acc_norm_stderr\": 0.015819173374302706\n",
    "  },\n",
    "  \"arc:_average\": {\n",
    "    \"acc\": 0.277,\n",
    "    \"acc_stderr\": 0.013694891076312077,\n",
    "    \"acc_norm\": 0.298,\n",
    "    \"acc_norm_stderr\": 0.014299871901289755\n",
    "  },\n",
    "  \"mmlu:_average\": {\n",
    "    \"acc\": 0.24486225766415484,\n",
    "    \"acc_stderr\": 0.03198621725172759,\n",
    "    \"acc_norm\": 0.26125950385266233,\n",
    "    \"acc_norm_stderr\": 0.032822076137567394\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dfa9ed-e153-40f3-be0b-3ba0d10f1ca5",
   "metadata": {},
   "source": [
    "### 40k proxy, 30k reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62f6130-8af8-4190-95f4-89ff7b8bee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference_data_30k = {\n",
    "#     \"arc:challenge\": {\n",
    "#     \"acc\": 0.177,\n",
    "#     \"acc_stderr\": 0.012075463420375061,\n",
    "#     \"acc_norm\": 0.242,\n",
    "#     \"acc_norm_stderr\": 0.013550631705555954\n",
    "#     },\n",
    "#     \"arc:easy\": {\n",
    "#     \"acc\": 0.309,\n",
    "#     \"acc_stderr\": 0.014619600977206484,\n",
    "#     \"acc_norm\": 0.319,\n",
    "#     \"acc_norm_stderr\": 0.014746404865473479\n",
    "#     },\n",
    "#     \"commonsense_qa\": {\n",
    "#     \"acc\": 0.197,\n",
    "#     \"acc_stderr\": 0.012583693787968144,\n",
    "#     \"acc_norm\": 0.227,\n",
    "#     \"acc_norm_stderr\": 0.013253174964763923\n",
    "#     },\n",
    "#     \"hellaswag\": {\n",
    "#     \"acc\": 0.265,\n",
    "#     \"acc_stderr\": 0.013963164754809954,\n",
    "#     \"acc_norm\": 0.259,\n",
    "#     \"acc_norm_stderr\": 0.013860415257527911\n",
    "#     },\n",
    "#     \"mmlu:abstract_algebra\": {\n",
    "#     \"acc\": 0.19,\n",
    "#     \"acc_stderr\": 0.03942772444036625,\n",
    "#     \"acc_norm\": 0.24,\n",
    "#     \"acc_norm_stderr\": 0.04292346959909284\n",
    "#     },\n",
    "#     \"mmlu:anatomy\": {\n",
    "#     \"acc\": 0.2074074074074074,\n",
    "#     \"acc_stderr\": 0.035025531706783186,\n",
    "#     \"acc_norm\": 0.24444444444444444,\n",
    "#     \"acc_norm_stderr\": 0.037125378336148665\n",
    "#     },\n",
    "#     \"mmlu:astronomy\": {\n",
    "#     \"acc\": 0.20394736842105263,\n",
    "#     \"acc_stderr\": 0.032790004063100515,\n",
    "#     \"acc_norm\": 0.28289473684210525,\n",
    "#     \"acc_norm_stderr\": 0.03665349695640767\n",
    "#     },\n",
    "#     \"mmlu:business_ethics\": {\n",
    "#     \"acc\": 0.38,\n",
    "#     \"acc_stderr\": 0.04878317312145634,\n",
    "#     \"acc_norm\": 0.25,\n",
    "#     \"acc_norm_stderr\": 0.04351941398892446\n",
    "#     },\n",
    "#     \"mmlu:clinical_knowledge\": {\n",
    "#     \"acc\": 0.18490566037735848,\n",
    "#     \"acc_stderr\": 0.02389335183446432,\n",
    "#     \"acc_norm\": 0.30566037735849055,\n",
    "#     \"acc_norm_stderr\": 0.028353298073322666\n",
    "#     },\n",
    "#     \"mmlu:college_biology\": {\n",
    "#     \"acc\": 0.2013888888888889,\n",
    "#     \"acc_stderr\": 0.033536474697138406,\n",
    "#     \"acc_norm\": 0.20833333333333334,\n",
    "#     \"acc_norm_stderr\": 0.03396116205845335\n",
    "#     },\n",
    "#     \"mmlu:college_chemistry\": {\n",
    "#     \"acc\": 0.22,\n",
    "#     \"acc_stderr\": 0.041633319989322695,\n",
    "#     \"acc_norm\": 0.26,\n",
    "#     \"acc_norm_stderr\": 0.0440844002276808\n",
    "#     },\n",
    "#     \"mmlu:college_computer_science\": {\n",
    "#     \"acc\": 0.26,\n",
    "#     \"acc_stderr\": 0.0440844002276808,\n",
    "#     \"acc_norm\": 0.18,\n",
    "#     \"acc_norm_stderr\": 0.038612291966536955\n",
    "#     },\n",
    "#     \"mmlu:college_mathematics\": {\n",
    "#     \"acc\": 0.18,\n",
    "#     \"acc_stderr\": 0.03861229196653695,\n",
    "#     \"acc_norm\": 0.23,\n",
    "#     \"acc_norm_stderr\": 0.042295258468165044\n",
    "#     },\n",
    "#     \"mmlu:college_medicine\": {\n",
    "#     \"acc\": 0.24277456647398843,\n",
    "#     \"acc_stderr\": 0.0326926380614177,\n",
    "#     \"acc_norm\": 0.27167630057803466,\n",
    "#     \"acc_norm_stderr\": 0.0339175032232166\n",
    "#     },\n",
    "#     \"mmlu:college_physics\": {\n",
    "#     \"acc\": 0.21568627450980393,\n",
    "#     \"acc_stderr\": 0.04092563958237656,\n",
    "#     \"acc_norm\": 0.23529411764705882,\n",
    "#     \"acc_norm_stderr\": 0.04220773659171453\n",
    "#     },\n",
    "#     \"mmlu:computer_security\": {\n",
    "#     \"acc\": 0.26,\n",
    "#     \"acc_stderr\": 0.04408440022768078,\n",
    "#     \"acc_norm\": 0.24,\n",
    "#     \"acc_norm_stderr\": 0.042923469599092816\n",
    "#     },\n",
    "#     \"mmlu:conceptual_physics\": {\n",
    "#     \"acc\": 0.2978723404255319,\n",
    "#     \"acc_stderr\": 0.029896145682095462,\n",
    "#     \"acc_norm\": 0.22127659574468084,\n",
    "#     \"acc_norm_stderr\": 0.027136349602424063\n",
    "#     },\n",
    "#     \"mmlu:econometrics\": {\n",
    "#     \"acc\": 0.23684210526315788,\n",
    "#     \"acc_stderr\": 0.039994238792813344,\n",
    "#     \"acc_norm\": 0.2719298245614035,\n",
    "#     \"acc_norm_stderr\": 0.04185774424022056\n",
    "#     },\n",
    "#     \"mmlu:electrical_engineering\": {\n",
    "#     \"acc\": 0.22758620689655173,\n",
    "#     \"acc_stderr\": 0.03493950380131184,\n",
    "#     \"acc_norm\": 0.2689655172413793,\n",
    "#     \"acc_norm_stderr\": 0.036951833116502325\n",
    "#     },\n",
    "#     \"mmlu:elementary_mathematics\": {\n",
    "#     \"acc\": 0.21693121693121692,\n",
    "#     \"acc_stderr\": 0.02122708244944505,\n",
    "#     \"acc_norm\": 0.22486772486772486,\n",
    "#     \"acc_norm_stderr\": 0.02150209607822914\n",
    "#     },\n",
    "#     \"mmlu:formal_logic\": {\n",
    "#     \"acc\": 0.2698412698412698,\n",
    "#     \"acc_stderr\": 0.03970158273235172,\n",
    "#     \"acc_norm\": 0.21428571428571427,\n",
    "#     \"acc_norm_stderr\": 0.03670066451047182\n",
    "#     },\n",
    "#     \"mmlu:global_facts\": {\n",
    "#     \"acc\": 0.23,\n",
    "#     \"acc_stderr\": 0.04229525846816508,\n",
    "#     \"acc_norm\": 0.2,\n",
    "#     \"acc_norm_stderr\": 0.04020151261036846\n",
    "#     },\n",
    "#     \"mmlu:high_school_biology\": {\n",
    "#     \"acc\": 0.22258064516129034,\n",
    "#     \"acc_stderr\": 0.023664216671642525,\n",
    "#     \"acc_norm\": 0.27419354838709675,\n",
    "#     \"acc_norm_stderr\": 0.025378139970885196\n",
    "#     },\n",
    "#     \"mmlu:high_school_chemistry\": {\n",
    "#     \"acc\": 0.18719211822660098,\n",
    "#     \"acc_stderr\": 0.027444924966882618,\n",
    "#     \"acc_norm\": 0.22167487684729065,\n",
    "#     \"acc_norm_stderr\": 0.029225575892489614\n",
    "#     },\n",
    "#     \"mmlu:high_school_computer_science\": {\n",
    "#     \"acc\": 0.18,\n",
    "#     \"acc_stderr\": 0.038612291966536955,\n",
    "#     \"acc_norm\": 0.21,\n",
    "#     \"acc_norm_stderr\": 0.040936018074033256\n",
    "#     },\n",
    "#     \"mmlu:high_school_european_history\": {\n",
    "#     \"acc\": 0.17575757575757575,\n",
    "#     \"acc_stderr\": 0.02972094300622445,\n",
    "#     \"acc_norm\": 0.23636363636363636,\n",
    "#     \"acc_norm_stderr\": 0.03317505930009182\n",
    "#     },\n",
    "#     \"mmlu:high_school_geography\": {\n",
    "#     \"acc\": 0.23737373737373738,\n",
    "#     \"acc_stderr\": 0.0303137105381989,\n",
    "#     \"acc_norm\": 0.31313131313131315,\n",
    "#     \"acc_norm_stderr\": 0.03304205087813652\n",
    "#     },\n",
    "#     \"mmlu:high_school_government_and_politics\": {\n",
    "#     \"acc\": 0.20725388601036268,\n",
    "#     \"acc_stderr\": 0.02925282329180363,\n",
    "#     \"acc_norm\": 0.24870466321243523,\n",
    "#     \"acc_norm_stderr\": 0.031195840877700286\n",
    "#     },\n",
    "#     \"mmlu:high_school_macroeconomics\": {\n",
    "#     \"acc\": 0.24102564102564103,\n",
    "#     \"acc_stderr\": 0.021685546665333195,\n",
    "#     \"acc_norm\": 0.25384615384615383,\n",
    "#     \"acc_norm_stderr\": 0.022066054378726257\n",
    "#     },\n",
    "#     \"mmlu:high_school_mathematics\": {\n",
    "#     \"acc\": 0.14444444444444443,\n",
    "#     \"acc_stderr\": 0.0214337612741049,\n",
    "#     \"acc_norm\": 0.2,\n",
    "#     \"acc_norm_stderr\": 0.024388430433987664\n",
    "#     },\n",
    "#     \"mmlu:high_school_microeconomics\": {\n",
    "#     \"acc\": 0.23949579831932774,\n",
    "#     \"acc_stderr\": 0.02772206549336127,\n",
    "#     \"acc_norm\": 0.31092436974789917,\n",
    "#     \"acc_norm_stderr\": 0.030066761582977927\n",
    "#     },\n",
    "#     \"mmlu:high_school_physics\": {\n",
    "#     \"acc\": 0.25165562913907286,\n",
    "#     \"acc_stderr\": 0.035433042343899844,\n",
    "#     \"acc_norm\": 0.23178807947019867,\n",
    "#     \"acc_norm_stderr\": 0.03445406271987053\n",
    "#     },\n",
    "#     \"mmlu:high_school_psychology\": {\n",
    "#     \"acc\": 0.27155963302752295,\n",
    "#     \"acc_stderr\": 0.019069098363191442,\n",
    "#     \"acc_norm\": 0.25137614678899084,\n",
    "#     \"acc_norm_stderr\": 0.018599206360287415\n",
    "#     },\n",
    "#     \"mmlu:high_school_statistics\": {\n",
    "#     \"acc\": 0.25925925925925924,\n",
    "#     \"acc_stderr\": 0.02988691054762696,\n",
    "#     \"acc_norm\": 0.30092592592592593,\n",
    "#     \"acc_norm_stderr\": 0.031280390843298825\n",
    "#     },\n",
    "#     \"mmlu:high_school_us_history\": {\n",
    "#     \"acc\": 0.24019607843137256,\n",
    "#     \"acc_stderr\": 0.02998373305591362,\n",
    "#     \"acc_norm\": 0.2647058823529412,\n",
    "#     \"acc_norm_stderr\": 0.030964517926923413\n",
    "#     },\n",
    "#     \"mmlu:high_school_world_history\": {\n",
    "#     \"acc\": 0.20675105485232068,\n",
    "#     \"acc_stderr\": 0.026361651668389087,\n",
    "#     \"acc_norm\": 0.28270042194092826,\n",
    "#     \"acc_norm_stderr\": 0.02931281415395592\n",
    "#     },\n",
    "#     \"mmlu:human_aging\": {\n",
    "#     \"acc\": 0.336322869955157,\n",
    "#     \"acc_stderr\": 0.031708824268455,\n",
    "#     \"acc_norm\": 0.2600896860986547,\n",
    "#     \"acc_norm_stderr\": 0.029442495585857487\n",
    "#     },\n",
    "#     \"mmlu:human_sexuality\": {\n",
    "#     \"acc\": 0.29770992366412213,\n",
    "#     \"acc_stderr\": 0.04010358942462203,\n",
    "#     \"acc_norm\": 0.35877862595419846,\n",
    "#     \"acc_norm_stderr\": 0.04206739313864908\n",
    "#     },\n",
    "#     \"mmlu:international_law\": {\n",
    "#     \"acc\": 0.11570247933884298,\n",
    "#     \"acc_stderr\": 0.029199802455622783,\n",
    "#     \"acc_norm\": 0.2066115702479339,\n",
    "#     \"acc_norm_stderr\": 0.036959801280988254\n",
    "#     },\n",
    "#     \"mmlu:jurisprudence\": {\n",
    "#     \"acc\": 0.1574074074074074,\n",
    "#     \"acc_stderr\": 0.035207039905179635,\n",
    "#     \"acc_norm\": 0.23148148148148148,\n",
    "#     \"acc_norm_stderr\": 0.04077494709252628\n",
    "#     },\n",
    "#     \"mmlu:logical_fallacies\": {\n",
    "#     \"acc\": 0.2822085889570552,\n",
    "#     \"acc_stderr\": 0.03536117886664742,\n",
    "#     \"acc_norm\": 0.31901840490797545,\n",
    "#     \"acc_norm_stderr\": 0.03661997551073836\n",
    "#     },\n",
    "#     \"mmlu:machine_learning\": {\n",
    "#     \"acc\": 0.26785714285714285,\n",
    "#     \"acc_stderr\": 0.04203277291467763,\n",
    "#     \"acc_norm\": 0.20535714285714285,\n",
    "#     \"acc_norm_stderr\": 0.03834241021419072\n",
    "#     },\n",
    "#     \"mmlu:management\": {\n",
    "#     \"acc\": 0.20388349514563106,\n",
    "#     \"acc_stderr\": 0.03989139859531769,\n",
    "#     \"acc_norm\": 0.24271844660194175,\n",
    "#     \"acc_norm_stderr\": 0.04245022486384495\n",
    "#     },\n",
    "#     \"mmlu:marketing\": {\n",
    "#     \"acc\": 0.2777777777777778,\n",
    "#     \"acc_stderr\": 0.029343114798094476,\n",
    "#     \"acc_norm\": 0.3076923076923077,\n",
    "#     \"acc_norm_stderr\": 0.0302363899421731\n",
    "#     },\n",
    "#     \"mmlu:medical_genetics\": {\n",
    "#     \"acc\": 0.25,\n",
    "#     \"acc_stderr\": 0.04351941398892446,\n",
    "#     \"acc_norm\": 0.26,\n",
    "#     \"acc_norm_stderr\": 0.044084400227680794\n",
    "#     },\n",
    "#     \"mmlu:miscellaneous\": {\n",
    "#     \"acc\": 0.24010217113665389,\n",
    "#     \"acc_stderr\": 0.015274685213734191,\n",
    "#     \"acc_norm\": 0.2656449553001277,\n",
    "#     \"acc_norm_stderr\": 0.01579430248788872\n",
    "#     },\n",
    "#     \"mmlu:moral_disputes\": {\n",
    "#     \"acc\": 0.22254335260115607,\n",
    "#     \"acc_stderr\": 0.02239421566194282,\n",
    "#     \"acc_norm\": 0.2138728323699422,\n",
    "#     \"acc_norm_stderr\": 0.02207570925175718\n",
    "#     },\n",
    "#     \"mmlu:moral_scenarios\": {\n",
    "#     \"acc\": 0.23798882681564246,\n",
    "#     \"acc_stderr\": 0.014242630070574915,\n",
    "#     \"acc_norm\": 0.27262569832402234,\n",
    "#     \"acc_norm_stderr\": 0.014893391735249588\n",
    "#     },\n",
    "#     \"mmlu:nutrition\": {\n",
    "#     \"acc\": 0.20261437908496732,\n",
    "#     \"acc_stderr\": 0.02301544687798569,\n",
    "#     \"acc_norm\": 0.2875816993464052,\n",
    "#     \"acc_norm_stderr\": 0.02591780611714716\n",
    "#     },\n",
    "#     \"mmlu:philosophy\": {\n",
    "#     \"acc\": 0.2379421221864952,\n",
    "#     \"acc_stderr\": 0.024185150647818707,\n",
    "#     \"acc_norm\": 0.2733118971061093,\n",
    "#     \"acc_norm_stderr\": 0.02531176597542612\n",
    "#     },\n",
    "#     \"mmlu:prehistory\": {\n",
    "#     \"acc\": 0.2654320987654321,\n",
    "#     \"acc_stderr\": 0.024569223600460852,\n",
    "#     \"acc_norm\": 0.22839506172839505,\n",
    "#     \"acc_norm_stderr\": 0.023358211840626267\n",
    "#     },\n",
    "#     \"mmlu:prehistory\": {\n",
    "#     \"acc\": 0.2654320987654321,\n",
    "#     \"acc_stderr\": 0.024569223600460852,\n",
    "#     \"acc_norm\": 0.22839506172839505,\n",
    "#     \"acc_norm_stderr\": 0.023358211840626267\n",
    "#     },\n",
    "#     \"mmlu:professional_accounting\": {\n",
    "#     \"acc\": 0.23049645390070922,\n",
    "#     \"acc_stderr\": 0.025123739226872402,\n",
    "#     \"acc_norm\": 0.22340425531914893,\n",
    "#     \"acc_norm_stderr\": 0.02484792135806396\n",
    "#     },\n",
    "#     \"mmlu:professional_law\": {\n",
    "#     \"acc\": 0.255,\n",
    "#     \"acc_stderr\": 0.013790038620872828,\n",
    "#     \"acc_norm\": 0.27,\n",
    "#     \"acc_norm_stderr\": 0.014046255632633915\n",
    "#     },\n",
    "#     \"mmlu:professional_medicine\": {\n",
    "#     \"acc\": 0.20955882352941177,\n",
    "#     \"acc_stderr\": 0.024723110407677062,\n",
    "#     \"acc_norm\": 0.24632352941176472,\n",
    "#     \"acc_norm_stderr\": 0.02617343857052\n",
    "#     },\n",
    "#     \"mmlu:professional_psychology\": {\n",
    "#     \"acc\": 0.24836601307189543,\n",
    "#     \"acc_stderr\": 0.017479487001364764,\n",
    "#     \"acc_norm\": 0.26633986928104575,\n",
    "#     \"acc_norm_stderr\": 0.017883188134667178\n",
    "#     },\n",
    "#     \"mmlu:public_relations\": {\n",
    "#     \"acc\": 0.3181818181818182,\n",
    "#     \"acc_stderr\": 0.04461272175910508,\n",
    "#     \"acc_norm\": 0.23636363636363636,\n",
    "#     \"acc_norm_stderr\": 0.040693063197213775\n",
    "#     },\n",
    "#     \"mmlu:security_studies\": {\n",
    "#     \"acc\": 0.30612244897959184,\n",
    "#     \"acc_stderr\": 0.029504896454595968,\n",
    "#     \"acc_norm\": 0.17142857142857143,\n",
    "#     \"acc_norm_stderr\": 0.02412746346265013\n",
    "#     },\n",
    "#     \"mmlu:sociology\": {\n",
    "#     \"acc\": 0.19900497512437812,\n",
    "#     \"acc_stderr\": 0.028231365092758406,\n",
    "#     \"acc_norm\": 0.24875621890547264,\n",
    "#     \"acc_norm_stderr\": 0.03056767593891672\n",
    "#     },\n",
    "#     \"mmlu:us_foreign_policy\": {\n",
    "#     \"acc\": 0.22,\n",
    "#     \"acc_stderr\": 0.04163331998932269,\n",
    "#     \"acc_norm\": 0.24,\n",
    "#     \"acc_norm_stderr\": 0.042923469599092816\n",
    "#     },\n",
    "#     \"mmlu:virology\": {\n",
    "#     \"acc\": 0.26506024096385544,\n",
    "#     \"acc_stderr\": 0.03436024037944966,\n",
    "#     \"acc_norm\": 0.3072289156626506,\n",
    "#     \"acc_norm_stderr\": 0.03591566797824665\n",
    "#     },\n",
    "#     \"mmlu:world_religions\": {\n",
    "#     \"acc\": 0.12280701754385964,\n",
    "#     \"acc_stderr\": 0.025172984350155764,\n",
    "#     \"acc_norm\": 0.2046783625730994,\n",
    "#     \"acc_norm_stderr\": 0.03094445977853321\n",
    "#     },\n",
    "#     \"openbookqa\": {\n",
    "#     \"acc\": 0.124,\n",
    "#     \"acc_stderr\": 0.014754096608517583,\n",
    "#     \"acc_norm\": 0.278,\n",
    "#     \"acc_norm_stderr\": 0.020055833888070914\n",
    "#     },\n",
    "#     \"piqa\": {\n",
    "#     \"acc\": 0.545,\n",
    "#     \"acc_stderr\": 0.01575510149834709,\n",
    "#     \"acc_norm\": 0.537,\n",
    "#     \"acc_norm_stderr\": 0.015775927227262412\n",
    "#     },\n",
    "#     \"siqa\": {\n",
    "#     \"acc\": 0.358,\n",
    "#     \"acc_stderr\": 0.015167928865407559,\n",
    "#     \"acc_norm\": 0.385,\n",
    "#     \"acc_norm_stderr\": 0.01539519444541081\n",
    "#     },\n",
    "#     \"winogrande\": {\n",
    "#     \"acc\": 0.489,\n",
    "#     \"acc_stderr\": 0.015815471195292682,\n",
    "#     \"acc_norm\": 0.502,\n",
    "#     \"acc_norm_stderr\": 0.015819173374302706\n",
    "#     },\n",
    "#     \"arc:_average\": {\n",
    "#     \"acc\": 0.243,\n",
    "#     \"acc_stderr\": 0.013347532198790773,\n",
    "#     \"acc_norm\": 0.28049999999999997,\n",
    "#     \"acc_norm_stderr\": 0.014148518285514717\n",
    "#     },\n",
    "#     \"mmlu:_average\": {\n",
    "#     \"acc\": 0.23262840760445191,\n",
    "#     \"acc_stderr\": 0.031382594250348235,\n",
    "#     \"acc_norm\": 0.2508362609452844,\n",
    "#     \"acc_norm_stderr\": 0.03230638300974771\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0733d-955f-43fe-9b43-d733bbd5f3de",
   "metadata": {},
   "source": [
    "### 100k proxy, 120k reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fe7e85-63ff-4025-a78a-670adeff0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doremi_data_100k_proxy_120k_ckp = {\n",
    "\"arc:challenge\": {\n",
    "\"acc\": 0.183,\n",
    "\"acc_stderr\": 0.012233587399477825,\n",
    "\"acc_norm\": 0.235,\n",
    "\"acc_norm_stderr\": 0.013414729030247124\n",
    "},\n",
    "\"arc:easy\": {\n",
    "\"acc\": 0.418,\n",
    "\"acc_stderr\": 0.015605111967541946,\n",
    "\"acc_norm\": 0.419,\n",
    "\"acc_norm_stderr\": 0.015610338967577794\n",
    "},\n",
    "\"commonsense_qa\": {\n",
    "\"acc\": 0.252,\n",
    "\"acc_stderr\": 0.013736254390651145,\n",
    "\"acc_norm\": 0.263,\n",
    "\"acc_norm_stderr\": 0.013929286594259719\n",
    "},\n",
    "\"hellaswag\": {\n",
    "\"acc\": 0.301,\n",
    "\"acc_stderr\": 0.014512395033543143,\n",
    "\"acc_norm\": 0.33,\n",
    "\"acc_norm_stderr\": 0.014876872027456732\n",
    "},\n",
    "\"mmlu:abstract_algebra\": {\n",
    "\"acc\": 0.23,\n",
    "\"acc_stderr\": 0.04229525846816508,\n",
    "\"acc_norm\": 0.24,\n",
    "\"acc_norm_stderr\": 0.04292346959909283\n",
    "},\n",
    "\"mmlu:anatomy\": {\n",
    "\"acc\": 0.24444444444444444,\n",
    "\"acc_stderr\": 0.037125378336148665,\n",
    "\"acc_norm\": 0.2518518518518518,\n",
    "\"acc_norm_stderr\": 0.03749850709174022\n",
    "},\n",
    "\"mmlu:astronomy\": {\n",
    "\"acc\": 0.24342105263157895,\n",
    "\"acc_stderr\": 0.034923496688842384,\n",
    "\"acc_norm\": 0.3026315789473684,\n",
    "\"acc_norm_stderr\": 0.037385206761196686\n",
    "},\n",
    "\"mmlu:business_ethics\": {\n",
    "\"acc\": 0.41,\n",
    "\"acc_stderr\": 0.04943110704237102,\n",
    "\"acc_norm\": 0.35,\n",
    "\"acc_norm_stderr\": 0.047937248544110196\n",
    "},\n",
    "\"mmlu:clinical_knowledge\": {\n",
    "\"acc\": 0.26037735849056604,\n",
    "\"acc_stderr\": 0.027008766090708094,\n",
    "\"acc_norm\": 0.30943396226415093,\n",
    "\"acc_norm_stderr\": 0.028450154794118627\n",
    "},\n",
    "\"mmlu:college_biology\": {\n",
    "\"acc\": 0.2708333333333333,\n",
    "\"acc_stderr\": 0.03716177437566016,\n",
    "\"acc_norm\": 0.25,\n",
    "\"acc_norm_stderr\": 0.03621034121889507\n",
    "},\n",
    "\"mmlu:college_chemistry\": {\n",
    "\"acc\": 0.29,\n",
    "\"acc_stderr\": 0.04560480215720684,\n",
    "\"acc_norm\": 0.27,\n",
    "\"acc_norm_stderr\": 0.0446196043338474\n",
    "},\n",
    "\"mmlu:college_computer_science\": {\n",
    "\"acc\": 0.27,\n",
    "\"acc_stderr\": 0.044619604333847394,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.04408440022768079\n",
    "},\n",
    "\"mmlu:college_mathematics\": {\n",
    "\"acc\": 0.16,\n",
    "\"acc_stderr\": 0.03684529491774709,\n",
    "\"acc_norm\": 0.25,\n",
    "\"acc_norm_stderr\": 0.04351941398892446\n",
    "},\n",
    "\"mmlu:college_medicine\": {\n",
    "\"acc\": 0.2774566473988439,\n",
    "\"acc_stderr\": 0.034140140070440354,\n",
    "\"acc_norm\": 0.24277456647398843,\n",
    "\"acc_norm_stderr\": 0.0326926380614177\n",
    "},\n",
    "\"mmlu:college_physics\": {\n",
    "\"acc\": 0.1568627450980392,\n",
    "\"acc_stderr\": 0.03618664819936246,\n",
    "\"acc_norm\": 0.1568627450980392,\n",
    "\"acc_norm_stderr\": 0.03618664819936244\n",
    "},\n",
    "\"mmlu:computer_security\": {\n",
    "\"acc\": 0.26,\n",
    "\"acc_stderr\": 0.04408440022768078,\n",
    "\"acc_norm\": 0.31,\n",
    "\"acc_norm_stderr\": 0.04648231987117316\n",
    "},\n",
    "\"mmlu:conceptual_physics\": {\n",
    "\"acc\": 0.35319148936170214,\n",
    "\"acc_stderr\": 0.031245325202761926,\n",
    "\"acc_norm\": 0.23829787234042554,\n",
    "\"acc_norm_stderr\": 0.027851252973889767\n",
    "},\n",
    "\"mmlu:econometrics\": {\n",
    "\"acc\": 0.18421052631578946,\n",
    "\"acc_stderr\": 0.03646758875075566,\n",
    "\"acc_norm\": 0.22807017543859648,\n",
    "\"acc_norm_stderr\": 0.03947152782669415\n",
    "},\n",
    "\"mmlu:electrical_engineering\": {\n",
    "\"acc\": 0.2827586206896552,\n",
    "\"acc_stderr\": 0.03752833958003336,\n",
    "\"acc_norm\": 0.2827586206896552,\n",
    "\"acc_norm_stderr\": 0.03752833958003336\n",
    "},\n",
    "\"mmlu:elementary_mathematics\": {\n",
    "\"acc\": 0.23544973544973544,\n",
    "\"acc_stderr\": 0.02185150982203172,\n",
    "\"acc_norm\": 0.24867724867724866,\n",
    "\"acc_norm_stderr\": 0.022261817692400168\n",
    "},\n",
    "\"mmlu:formal_logic\": {\n",
    "\"acc\": 0.2777777777777778,\n",
    "\"acc_stderr\": 0.04006168083848877,\n",
    "\"acc_norm\": 0.2698412698412698,\n",
    "\"acc_norm_stderr\": 0.03970158273235172\n",
    "},\n",
    "\"mmlu:global_facts\": {\n",
    "\"acc\": 0.27,\n",
    "\"acc_stderr\": 0.04461960433384741,\n",
    "\"acc_norm\": 0.29,\n",
    "\"acc_norm_stderr\": 0.04560480215720684\n",
    "},\n",
    "\"mmlu:high_school_biology\": {\n",
    "\"acc\": 0.24516129032258063,\n",
    "\"acc_stderr\": 0.024472243840895535,\n",
    "\"acc_norm\": 0.3032258064516129,\n",
    "\"acc_norm_stderr\": 0.02614868593067175\n",
    "},\n",
    "\"mmlu:high_school_chemistry\": {\n",
    "\"acc\": 0.15763546798029557,\n",
    "\"acc_stderr\": 0.025639014131172404,\n",
    "\"acc_norm\": 0.2315270935960591,\n",
    "\"acc_norm_stderr\": 0.029678333141444437\n",
    "},\n",
    "\"mmlu:high_school_computer_science\": {\n",
    "\"acc\": 0.26,\n",
    "\"acc_stderr\": 0.044084400227680794,\n",
    "\"acc_norm\": 0.32,\n",
    "\"acc_norm_stderr\": 0.046882617226215034\n",
    "},\n",
    "\"mmlu:high_school_european_history\": {\n",
    "\"acc\": 0.20606060606060606,\n",
    "\"acc_stderr\": 0.03158415324047711,\n",
    "\"acc_norm\": 0.3090909090909091,\n",
    "\"acc_norm_stderr\": 0.036085410115739666\n",
    "},\n",
    "\"mmlu:high_school_geography\": {\n",
    "\"acc\": 0.2727272727272727,\n",
    "\"acc_stderr\": 0.03173071239071724,\n",
    "\"acc_norm\": 0.31313131313131315,\n",
    "\"acc_norm_stderr\": 0.033042050878136525\n",
    "},\n",
    "\"mmlu:high_school_government_and_politics\": {\n",
    "\"acc\": 0.22797927461139897,\n",
    "\"acc_stderr\": 0.030276909945178256,\n",
    "\"acc_norm\": 0.2538860103626943,\n",
    "\"acc_norm_stderr\": 0.03141024780565319\n",
    "},\n",
    "\"mmlu:high_school_macroeconomics\": {\n",
    "\"acc\": 0.2282051282051282,\n",
    "\"acc_stderr\": 0.02127839386358628,\n",
    "\"acc_norm\": 0.258974358974359,\n",
    "\"acc_norm_stderr\": 0.02221110681006166\n",
    "},\n",
    "\"mmlu:high_school_mathematics\": {\n",
    "\"acc\": 0.14814814814814814,\n",
    "\"acc_stderr\": 0.021659778422118036,\n",
    "\"acc_norm\": 0.1925925925925926,\n",
    "\"acc_norm_stderr\": 0.0240430751819452\n",
    "},\n",
    "\"mmlu:high_school_microeconomics\": {\n",
    "\"acc\": 0.24369747899159663,\n",
    "\"acc_stderr\": 0.027886828078380582,\n",
    "\"acc_norm\": 0.3403361344537815,\n",
    "\"acc_norm_stderr\": 0.03077805742293167\n",
    "},\n",
    "\"mmlu:high_school_physics\": {\n",
    "\"acc\": 0.2781456953642384,\n",
    "\"acc_stderr\": 0.03658603262763743,\n",
    "\"acc_norm\": 0.271523178807947,\n",
    "\"acc_norm_stderr\": 0.03631329803969654\n",
    "},\n",
    "\"mmlu:high_school_psychology\": {\n",
    "\"acc\": 0.3155963302752294,\n",
    "\"acc_stderr\": 0.01992611751386967,\n",
    "\"acc_norm\": 0.29908256880733947,\n",
    "\"acc_norm_stderr\": 0.019630417285415175\n",
    "},\n",
    "\"mmlu:high_school_statistics\": {\n",
    "\"acc\": 0.25,\n",
    "\"acc_stderr\": 0.029531221160930918,\n",
    "\"acc_norm\": 0.2638888888888889,\n",
    "\"acc_norm_stderr\": 0.030058202704309846\n",
    "},\n",
    "\"mmlu:high_school_us_history\": {\n",
    "\"acc\": 0.24509803921568626,\n",
    "\"acc_stderr\": 0.030190282453501936,\n",
    "\"acc_norm\": 0.3088235294117647,\n",
    "\"acc_norm_stderr\": 0.03242661719827218\n",
    "},\n",
    "\"mmlu:high_school_world_history\": {\n",
    "\"acc\": 0.24050632911392406,\n",
    "\"acc_stderr\": 0.027820781981149678,\n",
    "\"acc_norm\": 0.2489451476793249,\n",
    "\"acc_norm_stderr\": 0.028146970599422644\n",
    "},\n",
    "\"mmlu:human_aging\": {\n",
    "\"acc\": 0.34080717488789236,\n",
    "\"acc_stderr\": 0.03181149747055359,\n",
    "\"acc_norm\": 0.27802690582959644,\n",
    "\"acc_norm_stderr\": 0.03006958487449403\n",
    "},\n",
    "\"mmlu:human_sexuality\": {\n",
    "\"acc\": 0.35877862595419846,\n",
    "\"acc_stderr\": 0.04206739313864908,\n",
    "\"acc_norm\": 0.31297709923664124,\n",
    "\"acc_norm_stderr\": 0.04066962905677697\n",
    "},\n",
    "\"mmlu:international_law\": {\n",
    "\"acc\": 0.11570247933884298,\n",
    "\"acc_stderr\": 0.029199802455622793,\n",
    "\"acc_norm\": 0.21487603305785125,\n",
    "\"acc_norm_stderr\": 0.03749492448709698\n",
    "},\n",
    "\"mmlu:jurisprudence\": {\n",
    "\"acc\": 0.17592592592592593,\n",
    "\"acc_stderr\": 0.03680918141673881,\n",
    "\"acc_norm\": 0.26851851851851855,\n",
    "\"acc_norm_stderr\": 0.04284467968052191\n",
    "},\n",
    "\"mmlu:logical_fallacies\": {\n",
    "\"acc\": 0.26380368098159507,\n",
    "\"acc_stderr\": 0.03462419931615624,\n",
    "\"acc_norm\": 0.3803680981595092,\n",
    "\"acc_norm_stderr\": 0.03814269893261835\n",
    "},\n",
    "\"mmlu:machine_learning\": {\n",
    "\"acc\": 0.22321428571428573,\n",
    "\"acc_stderr\": 0.039523019677025116,\n",
    "\"acc_norm\": 0.23214285714285715,\n",
    "\"acc_norm_stderr\": 0.04007341809755805\n",
    "},\n",
    "\"mmlu:management\": {\n",
    "\"acc\": 0.24271844660194175,\n",
    "\"acc_stderr\": 0.042450224863844956,\n",
    "\"acc_norm\": 0.33980582524271846,\n",
    "\"acc_norm_stderr\": 0.04689765937278134\n",
    "},\n",
    "\"mmlu:marketing\": {\n",
    "\"acc\": 0.37606837606837606,\n",
    "\"acc_stderr\": 0.03173393632969481,\n",
    "\"acc_norm\": 0.3803418803418803,\n",
    "\"acc_norm_stderr\": 0.03180425204384099\n",
    "},\n",
    "\"mmlu:medical_genetics\": {\n",
    "\"acc\": 0.22,\n",
    "\"acc_stderr\": 0.04163331998932269,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.0440844002276808\n",
    "},\n",
    "\"mmlu:miscellaneous\": {\n",
    "\"acc\": 0.3065134099616858,\n",
    "\"acc_stderr\": 0.01648695289304151,\n",
    "\"acc_norm\": 0.30268199233716475,\n",
    "\"acc_norm_stderr\": 0.016428781581749367\n",
    "},\n",
    "\"mmlu:moral_disputes\": {\n",
    "\"acc\": 0.2023121387283237,\n",
    "\"acc_stderr\": 0.021628077380196134,\n",
    "\"acc_norm\": 0.1936416184971098,\n",
    "\"acc_norm_stderr\": 0.02127423031751555\n",
    "},\n",
    "\"mmlu:moral_scenarios\": {\n",
    "\"acc\": 0.23798882681564246,\n",
    "\"acc_stderr\": 0.014242630070574915,\n",
    "\"acc_norm\": 0.27262569832402234,\n",
    "\"acc_norm_stderr\": 0.014893391735249588\n",
    "},\n",
    "\"mmlu:nutrition\": {\n",
    "\"acc\": 0.22875816993464052,\n",
    "\"acc_stderr\": 0.02405102973991226,\n",
    "\"acc_norm\": 0.2875816993464052,\n",
    "\"acc_norm_stderr\": 0.02591780611714716\n",
    "},\n",
    "\"mmlu:philosophy\": {\n",
    "\"acc\": 0.2379421221864952,\n",
    "\"acc_stderr\": 0.024185150647818707,\n",
    "\"acc_norm\": 0.26688102893890675,\n",
    "\"acc_norm_stderr\": 0.02512263760881664\n",
    "},\n",
    "\"mmlu:prehistory\": {\n",
    "\"acc\": 0.2777777777777778,\n",
    "\"acc_stderr\": 0.02492200116888634,\n",
    "\"acc_norm\": 0.21604938271604937,\n",
    "\"acc_norm_stderr\": 0.022899162918445803\n",
    "},\n",
    "\"mmlu:professional_accounting\": {\n",
    "\"acc\": 0.24468085106382978,\n",
    "\"acc_stderr\": 0.025645553622266726,\n",
    "\"acc_norm\": 0.24822695035460993,\n",
    "\"acc_norm_stderr\": 0.025770015644290385\n",
    "},\n",
    "\"mmlu:professional_law\": {\n",
    "\"acc\": 0.238,\n",
    "\"acc_stderr\": 0.013473586661967222,\n",
    "\"acc_norm\": 0.252,\n",
    "\"acc_norm_stderr\": 0.013736254390651145\n",
    "},\n",
    "\"mmlu:professional_medicine\": {\n",
    "\"acc\": 0.24632352941176472,\n",
    "\"acc_stderr\": 0.02617343857052,\n",
    "\"acc_norm\": 0.28308823529411764,\n",
    "\"acc_norm_stderr\": 0.027365861131513805\n",
    "},\n",
    "\"mmlu:professional_psychology\": {\n",
    "\"acc\": 0.24509803921568626,\n",
    "\"acc_stderr\": 0.01740181671142765,\n",
    "\"acc_norm\": 0.25980392156862747,\n",
    "\"acc_norm_stderr\": 0.017740899509177788\n",
    "},\n",
    "\"mmlu:public_relations\": {\n",
    "\"acc\": 0.4,\n",
    "\"acc_stderr\": 0.0469237132203465,\n",
    "\"acc_norm\": 0.19090909090909092,\n",
    "\"acc_norm_stderr\": 0.03764425585984924\n",
    "},\"mmlu:security_studies\": {\n",
    "\"acc\": 0.31020408163265306,\n",
    "\"acc_stderr\": 0.029613459872484378,\n",
    "\"acc_norm\": 0.20408163265306123,\n",
    "\"acc_norm_stderr\": 0.025801283475090506\n",
    "},\n",
    "\"mmlu:sociology\": {\n",
    "\"acc\": 0.23880597014925373,\n",
    "\"acc_stderr\": 0.03014777593540922,\n",
    "\"acc_norm\": 0.23383084577114427,\n",
    "\"acc_norm_stderr\": 0.02992941540834839\n",
    "},\n",
    "\"mmlu:us_foreign_policy\": {\n",
    "\"acc\": 0.27,\n",
    "\"acc_stderr\": 0.04461960433384741,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.04408440022768079\n",
    "},\n",
    "\"mmlu:virology\": {\n",
    "\"acc\": 0.2469879518072289,\n",
    "\"acc_stderr\": 0.03357351982064537,\n",
    "\"acc_norm\": 0.27710843373493976,\n",
    "\"acc_norm_stderr\": 0.034843315926805875\n",
    "},\n",
    "\"mmlu:world_religions\": {\n",
    "\"acc\": 0.18128654970760233,\n",
    "\"acc_stderr\": 0.029547741687640024,\n",
    "\"acc_norm\": 0.24561403508771928,\n",
    "\"acc_norm_stderr\": 0.03301405946987251\n",
    "},\n",
    "\"openbookqa\": {\n",
    "\"acc\": 0.16,\n",
    "\"acc_stderr\": 0.01641154098050231,\n",
    "\"acc_norm\": 0.266,\n",
    "\"acc_norm_stderr\": 0.019780559675655493\n",
    "},\n",
    "\"piqa\": {\n",
    "\"acc\": 0.606,\n",
    "\"acc_stderr\": 0.015459721957493379,\n",
    "\"acc_norm\": 0.633,\n",
    "\"acc_norm_stderr\": 0.015249378464171742\n",
    "},\n",
    "\"siqa\": {\n",
    "\"acc\": 0.376,\n",
    "\"acc_stderr\": 0.015325105508898129,\n",
    "\"acc_norm\": 0.397,\n",
    "\"acc_norm_stderr\": 0.015480007449307994\n",
    "},\n",
    "\"winogrande\": {\n",
    "\"acc\": 0.522,\n",
    "\"acc_stderr\": 0.01580397942816196,\n",
    "\"acc_norm\": 0.505,\n",
    "\"acc_norm_stderr\": 0.015818508944436656\n",
    "},\n",
    "\"arc:_average\": {\n",
    "\"acc\": 0.3005,\n",
    "\"acc_stderr\": 0.013919349683509885,\n",
    "\"acc_norm\": 0.32699999999999996,\n",
    "\"acc_norm_stderr\": 0.014512533998912459\n",
    "},\n",
    "\"mmlu:_average\": {\n",
    "\"acc\": 0.25307795098023184,\n",
    "\"acc_stderr\": 0.032216775724701545,\n",
    "\"acc_norm\": 0.26890191591111795,\n",
    "\"acc_norm_stderr\": 0.03308441024718641\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f08b0cd-321a-4bc4-8f43-18fc3857c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_120k = {\"commonsense_qa\": {\n",
    "\"acc\": 0.275,\n",
    "\"acc_stderr\": 0.014127086556490528,\n",
    "\"acc_norm\": 0.258,\n",
    "\"acc_norm_stderr\": 0.013842963108656603\n",
    "},\n",
    "\"hellaswag\": {\n",
    "\"acc\": 0.297,\n",
    "\"acc_stderr\": 0.014456832294801098,\n",
    "\"acc_norm\": 0.326,\n",
    "\"acc_norm_stderr\": 0.014830507204541033\n",
    "},\n",
    "\"openbookqa\": {\n",
    "\"acc\": 0.128,\n",
    "\"acc_stderr\": 0.014955913837590672,\n",
    "\"acc_norm\": 0.27,\n",
    "\"acc_norm_stderr\": 0.019874354831287487\n",
    "},\n",
    "\"piqa\": {\n",
    "\"acc\": 0.594,\n",
    "\"acc_stderr\": 0.015537226438634592,\n",
    "\"acc_norm\": 0.611,\n",
    "\"acc_norm_stderr\": 0.015424555647308496\n",
    "},\n",
    "\"siqa\": {\n",
    "\"acc\": 0.365,\n",
    "\"acc_stderr\": 0.015231776226264909,\n",
    "\"acc_norm\": 0.381,\n",
    "\"acc_norm_stderr\": 0.015364734787007436\n",
    "},\n",
    "\"winogrande\": {\n",
    "\"acc\": 0.51,\n",
    "\"acc_stderr\": 0.01581613575277321,\n",
    "\"acc_norm\": 0.497,\n",
    "\"acc_norm_stderr\": 0.015819015179246724\n",
    "},\n",
    "\"arc:challenge\": {\n",
    "\"acc\": 0.196,\n",
    "\"acc_stderr\": 0.01255952792670737,\n",
    "\"acc_norm\": 0.238,\n",
    "\"acc_norm_stderr\": 0.013473586661967225\n",
    "},\n",
    "\"arc:easy\": {\n",
    "\"acc\": 0.422,\n",
    "\"acc_stderr\": 0.01562562511262066,\n",
    "\"acc_norm\": 0.408,\n",
    "\"acc_norm_stderr\": 0.015549205052920675\n",
    "},\n",
    "# \"arc:average\": {\n",
    "# \"acc\": 0.309,\n",
    "# \"acc_stderr\": 0.014092576519664016,\n",
    "# \"acc_norm\": 0.32299999999999995,\n",
    "# \"acc_norm_stderr\": 0.014511395857443949\n",
    "# },\n",
    "\"mmlu:abstract_algebra\": {\n",
    "\"acc\": 0.21,\n",
    "\"acc_stderr\": 0.04093601807403326,\n",
    "\"acc_norm\": 0.24,\n",
    "\"acc_norm_stderr\": 0.04292346959909284\n",
    "},\n",
    "\"mmlu:anatomy\": {\n",
    "\"acc\": 0.21481481481481482,\n",
    "\"acc_stderr\": 0.035478541985608236,\n",
    "\"acc_norm\": 0.26666666666666666,\n",
    "\"acc_norm_stderr\": 0.038201699145179055\n",
    "},\n",
    "\"mmlu:astronomy\": {\n",
    "\"acc\": 0.23026315789473684,\n",
    "\"acc_stderr\": 0.03426059424403165,\n",
    "\"acc_norm\": 0.27631578947368424,\n",
    "\"acc_norm_stderr\": 0.03639057569952925\n",
    "},\n",
    "\"mmlu:business_ethics\": {\n",
    "\"acc\": 0.43,\n",
    "\"acc_stderr\": 0.04975698519562428,\n",
    "\"acc_norm\": 0.3,\n",
    "\"acc_norm_stderr\": 0.046056618647183814\n",
    "},\n",
    "\"mmlu:clinical_knowledge\": {\n",
    "\"acc\": 0.21509433962264152,\n",
    "\"acc_stderr\": 0.025288394502891363,\n",
    "\"acc_norm\": 0.3169811320754717,\n",
    "\"acc_norm_stderr\": 0.028637235639800925\n",
    "},\n",
    "\"mmlu:college_biology\": {\n",
    "\"acc\": 0.25,\n",
    "\"acc_stderr\": 0.03621034121889507,\n",
    "\"acc_norm\": 0.2152777777777778,\n",
    "\"acc_norm_stderr\": 0.03437079344106133\n",
    "},\n",
    "\"mmlu:college_chemistry\": {\n",
    "\"acc\": 0.27,\n",
    "\"acc_stderr\": 0.044619604333847394,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.0440844002276808\n",
    "},\n",
    "\"mmlu:college_computer_science\": {\n",
    "\"acc\": 0.26,\n",
    "\"acc_stderr\": 0.0440844002276808,\n",
    "\"acc_norm\": 0.25,\n",
    "\"acc_norm_stderr\": 0.04351941398892446\n",
    "},\n",
    "\"mmlu:college_mathematics\": {\n",
    "\"acc\": 0.14,\n",
    "\"acc_stderr\": 0.03487350880197771,\n",
    "\"acc_norm\": 0.24,\n",
    "\"acc_norm_stderr\": 0.04292346959909282\n",
    "},\n",
    "\"mmlu:college_medicine\": {\n",
    "\"acc\": 0.24277456647398843,\n",
    "\"acc_stderr\": 0.0326926380614177,\n",
    "\"acc_norm\": 0.23699421965317918,\n",
    "\"acc_norm_stderr\": 0.03242414757483098\n",
    "},\n",
    "\"mmlu:college_physics\": {\n",
    "\"acc\": 0.20588235294117646,\n",
    "\"acc_stderr\": 0.04023382273617747,\n",
    "\"acc_norm\": 0.21568627450980393,\n",
    "\"acc_norm_stderr\": 0.04092563958237654\n",
    "},\n",
    "\"mmlu:computer_security\": {\n",
    "\"acc\": 0.26,\n",
    "\"acc_stderr\": 0.04408440022768078,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.04408440022768077\n",
    "},\n",
    "\"mmlu:conceptual_physics\": {\n",
    "\"acc\": 0.3191489361702128,\n",
    "\"acc_stderr\": 0.03047297336338004,\n",
    "\"acc_norm\": 0.225531914893617,\n",
    "\"acc_norm_stderr\": 0.02732107841738753\n",
    "},\n",
    "\"mmlu:econometrics\": {\n",
    "\"acc\": 0.22807017543859648,\n",
    "\"acc_stderr\": 0.03947152782669416,\n",
    "\"acc_norm\": 0.19298245614035087,\n",
    "\"acc_norm_stderr\": 0.037124548537213684\n",
    "},\n",
    "\"mmlu:electrical_engineering\": {\n",
    "\"acc\": 0.23448275862068965,\n",
    "\"acc_stderr\": 0.035306258743465914,\n",
    "\"acc_norm\": 0.25517241379310346,\n",
    "\"acc_norm_stderr\": 0.03632984052707842\n",
    "},\n",
    "\"mmlu:elementary_mathematics\": {\n",
    "\"acc\": 0.23015873015873015,\n",
    "\"acc_stderr\": 0.021679219663693152,\n",
    "\"acc_norm\": 0.2222222222222222,\n",
    "\"acc_norm_stderr\": 0.02141168439369419\n",
    "},\n",
    "\"mmlu:formal_logic\": {\n",
    "\"acc\": 0.29365079365079366,\n",
    "\"acc_stderr\": 0.04073524322147127,\n",
    "\"acc_norm\": 0.25396825396825395,\n",
    "\"acc_norm_stderr\": 0.038932596106046734\n",
    "},\n",
    "\"mmlu:global_facts\": {\n",
    "\"acc\": 0.2,\n",
    "\"acc_stderr\": 0.04020151261036846,\n",
    "\"acc_norm\": 0.22,\n",
    "\"acc_norm_stderr\": 0.041633319989322695\n",
    "},\n",
    "\"mmlu:high_school_biology\": {\n",
    "\"acc\": 0.22580645161290322,\n",
    "\"acc_stderr\": 0.023785577884181012,\n",
    "\"acc_norm\": 0.27419354838709675,\n",
    "\"acc_norm_stderr\": 0.025378139970885193\n",
    "},\n",
    "\"mmlu:high_school_chemistry\": {\n",
    "\"acc\": 0.18719211822660098,\n",
    "\"acc_stderr\": 0.027444924966882618,\n",
    "\"acc_norm\": 0.2561576354679803,\n",
    "\"acc_norm_stderr\": 0.030712730070982592\n",
    "},\n",
    "\"mmlu:high_school_computer_science\": {\n",
    "\"acc\": 0.22,\n",
    "\"acc_stderr\": 0.04163331998932269,\n",
    "\"acc_norm\": 0.26,\n",
    "\"acc_norm_stderr\": 0.0440844002276808\n",
    "},\n",
    "\"mmlu:high_school_european_history\": {\n",
    "\"acc\": 0.18787878787878787,\n",
    "\"acc_stderr\": 0.03050193405942914,\n",
    "\"acc_norm\": 0.296969696969697,\n",
    "\"acc_norm_stderr\": 0.03567969772268049\n",
    "},\n",
    "\"mmlu:high_school_geography\": {\n",
    "\"acc\": 0.25252525252525254,\n",
    "\"acc_stderr\": 0.030954055470365914,\n",
    "\"acc_norm\": 0.31313131313131315,\n",
    "\"acc_norm_stderr\": 0.03304205087813652\n",
    "},\n",
    "\"mmlu:high_school_government_and_politics\": {\n",
    "\"acc\": 0.21761658031088082,\n",
    "\"acc_stderr\": 0.02977866303775296,\n",
    "\"acc_norm\": 0.25906735751295334,\n",
    "\"acc_norm_stderr\": 0.0316187791793541\n",
    "},\n",
    "\"mmlu:high_school_macroeconomics\": {\n",
    "\"acc\": 0.23076923076923078,\n",
    "\"acc_stderr\": 0.02136202772522273,\n",
    "\"acc_norm\": 0.24871794871794872,\n",
    "\"acc_norm_stderr\": 0.021916957709213803\n",
    "},\n",
    "\"mmlu:high_school_mathematics\": {\n",
    "\"acc\": 0.14074074074074075,\n",
    "\"acc_stderr\": 0.0212029303435688,\n",
    "\"acc_norm\": 0.1814814814814815,\n",
    "\"acc_norm_stderr\": 0.023499264669407282\n",
    "},\n",
    "\"mmlu:high_school_microeconomics\": {\n",
    "\"acc\": 0.25210084033613445,\n",
    "\"acc_stderr\": 0.028205545033277726,\n",
    "\"acc_norm\": 0.3403361344537815,\n",
    "\"acc_norm_stderr\": 0.030778057422931673\n",
    "},\n",
    "\"mmlu:high_school_physics\": {\n",
    "\"acc\": 0.2781456953642384,\n",
    "\"acc_stderr\": 0.03658603262763743,\n",
    "\"acc_norm\": 0.26490066225165565,\n",
    "\"acc_norm_stderr\": 0.036030385453603826\n",
    "},\n",
    "\"mmlu:high_school_psychology\": {\n",
    "\"acc\": 0.28623853211009176,\n",
    "\"acc_stderr\": 0.019379436628919965,\n",
    "\"acc_norm\": 0.27889908256880735,\n",
    "\"acc_norm_stderr\": 0.01922746887646352\n",
    "},\n",
    "\"mmlu:high_school_statistics\": {\n",
    "\"acc\": 0.2361111111111111,\n",
    "\"acc_stderr\": 0.028963702570791037,\n",
    "\"acc_norm\": 0.2777777777777778,\n",
    "\"acc_norm_stderr\": 0.030546745264953195\n",
    "},\n",
    "\"mmlu:high_school_us_history\": {\n",
    "\"acc\": 0.23529411764705882,\n",
    "\"acc_stderr\": 0.02977177522814565,\n",
    "\"acc_norm\": 0.28431372549019607,\n",
    "\"acc_norm_stderr\": 0.031660096793998116\n",
    "},\n",
    "\"mmlu:high_school_world_history\": {\n",
    "\"acc\": 0.24050632911392406,\n",
    "\"acc_stderr\": 0.027820781981149675,\n",
    "\"acc_norm\": 0.26582278481012656,\n",
    "\"acc_norm_stderr\": 0.02875679962965834\n",
    "},\n",
    "\"mmlu:human_aging\": {\n",
    "\"acc\": 0.32286995515695066,\n",
    "\"acc_stderr\": 0.031381476375754995,\n",
    "\"acc_norm\": 0.2645739910313901,\n",
    "\"acc_norm_stderr\": 0.02960510321703832\n",
    "},\n",
    "\"mmlu:human_sexuality\": {\n",
    "\"acc\": 0.366412213740458,\n",
    "\"acc_stderr\": 0.04225875451969637,\n",
    "\"acc_norm\": 0.3282442748091603,\n",
    "\"acc_norm_stderr\": 0.04118438565806298\n",
    "},\n",
    "\"mmlu:international_law\": {\n",
    "\"acc\": 0.14049586776859505,\n",
    "\"acc_stderr\": 0.03172233426002159,\n",
    "\"acc_norm\": 0.256198347107438,\n",
    "\"acc_norm_stderr\": 0.03984979653302871\n",
    "},\n",
    "\"mmlu:jurisprudence\": {\n",
    "\"acc\": 0.16666666666666666,\n",
    "\"acc_stderr\": 0.036028141763926456,\n",
    "\"acc_norm\": 0.19444444444444445,\n",
    "\"acc_norm_stderr\": 0.03826076324884864\n",
    "},\n",
    "\"mmlu:logical_fallacies\": {\n",
    "\"acc\": 0.22699386503067484,\n",
    "\"acc_stderr\": 0.032910995786157686,\n",
    "\"acc_norm\": 0.34355828220858897,\n",
    "\"acc_norm_stderr\": 0.037311335196738925\n",
    "},\n",
    "\"mmlu:machine_learning\": {\n",
    "\"acc\": 0.24107142857142858,\n",
    "\"acc_stderr\": 0.04059867246952686,\n",
    "\"acc_norm\": 0.24107142857142858,\n",
    "\"acc_norm_stderr\": 0.04059867246952687\n",
    "},\n",
    "\"mmlu:management\": {\n",
    "\"acc\": 0.22330097087378642,\n",
    "\"acc_stderr\": 0.04123553189891431,\n",
    "\"acc_norm\": 0.30097087378640774,\n",
    "\"acc_norm_stderr\": 0.045416094465039476\n",
    "},\n",
    "\"mmlu:marketing\": {\n",
    "\"acc\": 0.3504273504273504,\n",
    "\"acc_stderr\": 0.031256108244218796,\n",
    "\"acc_norm\": 0.34615384615384615,\n",
    "\"acc_norm_stderr\": 0.0311669573672359\n",
    "},\n",
    "\"mmlu:medical_genetics\": {\n",
    "\"acc\": 0.25,\n",
    "\"acc_stderr\": 0.04351941398892446,\n",
    "\"acc_norm\": 0.24,\n",
    "\"acc_norm_stderr\": 0.042923469599092816\n",
    "},\n",
    "\"mmlu:miscellaneous\": {\n",
    "\"acc\": 0.2950191570881226,\n",
    "\"acc_stderr\": 0.016308363772932724,\n",
    "\"acc_norm\": 0.28991060025542786,\n",
    "\"acc_norm_stderr\": 0.01622501794477095\n",
    "},\n",
    "\"mmlu:moral_disputes\": {\n",
    "\"acc\": 0.21965317919075145,\n",
    "\"acc_stderr\": 0.022289638852617904,\n",
    "\"acc_norm\": 0.18208092485549132,\n",
    "\"acc_norm_stderr\": 0.020776761102513\n",
    "},\n",
    "\"mmlu:moral_scenarios\": {\n",
    "\"acc\": 0.23798882681564246,\n",
    "\"acc_stderr\": 0.014242630070574915,\n",
    "\"acc_norm\": 0.27262569832402234,\n",
    "\"acc_norm_stderr\": 0.014893391735249588\n",
    "},\n",
    "\"mmlu:nutrition\": {\n",
    "\"acc\": 0.19934640522875818,\n",
    "\"acc_stderr\": 0.02287581699346406,\n",
    "\"acc_norm\": 0.2777777777777778,\n",
    "\"acc_norm_stderr\": 0.0256468630971379\n",
    "},\n",
    "\"mmlu:philosophy\": {\n",
    "\"acc\": 0.2282958199356913,\n",
    "\"acc_stderr\": 0.023839303311398212,\n",
    "\"acc_norm\": 0.2797427652733119,\n",
    "\"acc_norm_stderr\": 0.02549425935069489\n",
    "},\n",
    "\"mmlu:prehistory\": {\n",
    "\"acc\": 0.29012345679012347,\n",
    "\"acc_stderr\": 0.025251173936495022,\n",
    "\"acc_norm\": 0.20987654320987653,\n",
    "\"acc_norm_stderr\": 0.02265834408598138\n",
    "},\n",
    "\"mmlu:professional_law\": {\n",
    "\"acc\": 0.246,\n",
    "\"acc_stderr\": 0.013626065817750638,\n",
    "\"acc_norm\": 0.257,\n",
    "\"acc_norm_stderr\": 0.013825416526895019\n",
    "},\n",
    "\"mmlu:professional_medicine\": {\n",
    "\"acc\": 0.2610294117647059,\n",
    "\"acc_stderr\": 0.026679252270103117,\n",
    "\"acc_norm\": 0.2610294117647059,\n",
    "\"acc_norm_stderr\": 0.026679252270103117\n",
    "},\n",
    "\"mmlu:professional_psychology\": {\n",
    "\"acc\": 0.26143790849673204,\n",
    "\"acc_stderr\": 0.01777694715752804,\n",
    "\"acc_norm\": 0.24509803921568626,\n",
    "\"acc_norm_stderr\": 0.017401816711427653\n",
    "},\n",
    "\"mmlu:public_relations\": {\n",
    "\"acc\": 0.38181818181818183,\n",
    "\"acc_stderr\": 0.04653429807913509,\n",
    "\"acc_norm\": 0.2727272727272727,\n",
    "\"acc_norm_stderr\": 0.04265792110940588\n",
    "},\n",
    "\"mmlu:security_studies\": {\n",
    "\"acc\": 0.2938775510204082,\n",
    "\"acc_stderr\": 0.029162738410249765,\n",
    "\"acc_norm\": 0.22040816326530613,\n",
    "\"acc_norm_stderr\": 0.02653704531214529\n",
    "},\n",
    "\"mmlu:sociology\": {\n",
    "\"acc\": 0.208955223880597,\n",
    "\"acc_stderr\": 0.028748298931728655,\n",
    "\"acc_norm\": 0.22885572139303484,\n",
    "\"acc_norm_stderr\": 0.029705284056772426\n",
    "},\n",
    "\"mmlu:us_foreign_policy\": {\n",
    "\"acc\": 0.26,\n",
    "\"acc_stderr\": 0.04408440022768078,\n",
    "\"acc_norm\": 0.21,\n",
    "\"acc_norm_stderr\": 0.04093601807403326\n",
    "},\n",
    "\"mmlu:virology\": {\n",
    "\"acc\": 0.2469879518072289,\n",
    "\"acc_stderr\": 0.03357351982064536,\n",
    "\"acc_norm\": 0.3072289156626506,\n",
    "\"acc_norm_stderr\": 0.03591566797824665\n",
    "},\n",
    "\"mmlu:world_religions\": {\n",
    "\"acc\": 0.18128654970760233,\n",
    "\"acc_stderr\": 0.029547741687640027,\n",
    "\"acc_norm\": 0.23976608187134502,\n",
    "\"acc_norm_stderr\": 0.032744852119469564\n",
    "},\n",
    "\"mmlu:_average\": {\n",
    "\"acc\": 0.24539887197950047,\n",
    "\"acc_stderr\": 0.031920583010219564,\n",
    "\"acc_norm\": 0.2590726074431258,\n",
    "\"acc_norm_stderr\": 0.03270896508924344\n",
    "},\n",
    " \"mmlu:professional_accounting\": {'acc': 0.2624113475177305, 'acc_stderr': 0.026244920349843, 'acc_norm': 0.24822695035460993, 'acc_norm_stderr': 0.025770015644290382},\n",
    "\"arc:_average\": {'acc': 0.309, 'acc_stderr': 0.014092576519664016, 'acc_norm': 0.32299999999999995, 'acc_norm_stderr': 0.014511395857443949}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5e4bf9-3555-45e8-be41-6dbfa955f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/huggingface/DATA/notebooks/hf-notebooks/doremi/experiments/\")\n",
    "from utils import plot_domain_weights, print_name_weights, compute_eval_stats, plot_eval, compute_avg_eval\n",
    "from constants import REFERENCE_1B_110K_TOKEN_RATIO, REFERENCE_1B_200K_UNIFORM, REFERENCE_1B_200K_TOKEN_RATIO, REFERENCE_1B_200K_TOKEN_RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137b3d83-5ab3-4c73-b5d3-b550a4f46fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_DOREMI_1B_120K = compute_avg_eval(doremi_data_100k_proxy_120k_ckp)\n",
    "AVG_REFERENCE_1B_120K = compute_avg_eval(reference_data_120k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0301acb6-9d75-4037-9121-346ea4e1e12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mmlu:average', 'arc:average', 'commonsense_qa', 'hellaswag', 'openbookqa', 'piqa', 'siqa', 'winogrande'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_DOREMI_1B_120K.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5246a310-0fbb-44ea-873e-57a70d808b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tasks that DoReMi outperforms the reference model: 6 = 75.00%\n",
      "The number of tasks that DoReMi underperforms the reference model: 2 = 25.00%\n",
      "The number of tasks that DoReMi performs the same as the reference model: 0 = 0.00%\n",
      "On average, DoReMi outperforms the reference model per task by: 1.31%\n",
      "On average, DoReMi underperforms the reference model per task by: 1.58%\n",
      "The average accuracy of DoReMi per task: 34.63%\n",
      "The average accuracy of the reference model per task: 34.04%\n"
     ]
    }
   ],
   "source": [
    "compute_eval_stats(AVG_DOREMI_1B_120K, AVG_REFERENCE_1B_120K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26372fe-c9f9-4953-8c0c-192eff933b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0b44b_row0_col0, #T_0b44b_row0_col1, #T_0b44b_row0_col2, #T_0b44b_row0_col3, #T_0b44b_row0_col4, #T_0b44b_row3_col0, #T_0b44b_row3_col1, #T_0b44b_row3_col2, #T_0b44b_row3_col3, #T_0b44b_row3_col4, #T_0b44b_row4_col0, #T_0b44b_row4_col1, #T_0b44b_row4_col2, #T_0b44b_row4_col3, #T_0b44b_row4_col4, #T_0b44b_row5_col0, #T_0b44b_row5_col1, #T_0b44b_row5_col2, #T_0b44b_row5_col3, #T_0b44b_row5_col4, #T_0b44b_row6_col0, #T_0b44b_row6_col1, #T_0b44b_row6_col2, #T_0b44b_row6_col3, #T_0b44b_row6_col4, #T_0b44b_row7_col0, #T_0b44b_row7_col1, #T_0b44b_row7_col2, #T_0b44b_row7_col3, #T_0b44b_row7_col4 {\n",
       "  background-color: #59cc0c;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0b44b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0b44b_level0_col0\" class=\"col_heading level0 col0\" >Task</th>\n",
       "      <th id=\"T_0b44b_level0_col1\" class=\"col_heading level0 col1\" >DoReMi ACC</th>\n",
       "      <th id=\"T_0b44b_level0_col2\" class=\"col_heading level0 col2\" >Reference ACC</th>\n",
       "      <th id=\"T_0b44b_level0_col3\" class=\"col_heading level0 col3\" >DoReMi AccNorm</th>\n",
       "      <th id=\"T_0b44b_level0_col4\" class=\"col_heading level0 col4\" >Reference AccNorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0b44b_row0_col0\" class=\"data row0 col0\" >mmlu:average</td>\n",
       "      <td id=\"T_0b44b_row0_col1\" class=\"data row0 col1\" >0.253078</td>\n",
       "      <td id=\"T_0b44b_row0_col2\" class=\"data row0 col2\" >0.245399</td>\n",
       "      <td id=\"T_0b44b_row0_col3\" class=\"data row0 col3\" >0.268902</td>\n",
       "      <td id=\"T_0b44b_row0_col4\" class=\"data row0 col4\" >0.259073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0b44b_row1_col0\" class=\"data row1 col0\" >arc:average</td>\n",
       "      <td id=\"T_0b44b_row1_col1\" class=\"data row1 col1\" >0.300500</td>\n",
       "      <td id=\"T_0b44b_row1_col2\" class=\"data row1 col2\" >0.309000</td>\n",
       "      <td id=\"T_0b44b_row1_col3\" class=\"data row1 col3\" >0.327000</td>\n",
       "      <td id=\"T_0b44b_row1_col4\" class=\"data row1 col4\" >0.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0b44b_row2_col0\" class=\"data row2 col0\" >commonsense_qa</td>\n",
       "      <td id=\"T_0b44b_row2_col1\" class=\"data row2 col1\" >0.252000</td>\n",
       "      <td id=\"T_0b44b_row2_col2\" class=\"data row2 col2\" >0.275000</td>\n",
       "      <td id=\"T_0b44b_row2_col3\" class=\"data row2 col3\" >0.263000</td>\n",
       "      <td id=\"T_0b44b_row2_col4\" class=\"data row2 col4\" >0.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0b44b_row3_col0\" class=\"data row3 col0\" >hellaswag</td>\n",
       "      <td id=\"T_0b44b_row3_col1\" class=\"data row3 col1\" >0.301000</td>\n",
       "      <td id=\"T_0b44b_row3_col2\" class=\"data row3 col2\" >0.297000</td>\n",
       "      <td id=\"T_0b44b_row3_col3\" class=\"data row3 col3\" >0.330000</td>\n",
       "      <td id=\"T_0b44b_row3_col4\" class=\"data row3 col4\" >0.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0b44b_row4_col0\" class=\"data row4 col0\" >openbookqa</td>\n",
       "      <td id=\"T_0b44b_row4_col1\" class=\"data row4 col1\" >0.160000</td>\n",
       "      <td id=\"T_0b44b_row4_col2\" class=\"data row4 col2\" >0.128000</td>\n",
       "      <td id=\"T_0b44b_row4_col3\" class=\"data row4 col3\" >0.266000</td>\n",
       "      <td id=\"T_0b44b_row4_col4\" class=\"data row4 col4\" >0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0b44b_row5_col0\" class=\"data row5 col0\" >piqa</td>\n",
       "      <td id=\"T_0b44b_row5_col1\" class=\"data row5 col1\" >0.606000</td>\n",
       "      <td id=\"T_0b44b_row5_col2\" class=\"data row5 col2\" >0.594000</td>\n",
       "      <td id=\"T_0b44b_row5_col3\" class=\"data row5 col3\" >0.633000</td>\n",
       "      <td id=\"T_0b44b_row5_col4\" class=\"data row5 col4\" >0.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_0b44b_row6_col0\" class=\"data row6 col0\" >siqa</td>\n",
       "      <td id=\"T_0b44b_row6_col1\" class=\"data row6 col1\" >0.376000</td>\n",
       "      <td id=\"T_0b44b_row6_col2\" class=\"data row6 col2\" >0.365000</td>\n",
       "      <td id=\"T_0b44b_row6_col3\" class=\"data row6 col3\" >0.397000</td>\n",
       "      <td id=\"T_0b44b_row6_col4\" class=\"data row6 col4\" >0.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0b44b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_0b44b_row7_col0\" class=\"data row7 col0\" >winogrande</td>\n",
       "      <td id=\"T_0b44b_row7_col1\" class=\"data row7 col1\" >0.522000</td>\n",
       "      <td id=\"T_0b44b_row7_col2\" class=\"data row7 col2\" >0.510000</td>\n",
       "      <td id=\"T_0b44b_row7_col3\" class=\"data row7 col3\" >0.505000</td>\n",
       "      <td id=\"T_0b44b_row7_col4\" class=\"data row7 col4\" >0.497000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x106056f40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_eval(AVG_DOREMI_1B_120K, AVG_REFERENCE_1B_120K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7386d-df24-4eb0-84f0-b6414383cd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20663fa4-9730-4d82-a4d1-c47850c0be91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
