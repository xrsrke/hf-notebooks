{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e47cbb-4314-4afb-9630-30c1af8e9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    get_dataset_size_from_model_size, calculate_total_steps, calculate_total_flops, calculate_flops_per_step,\n",
    "    calculate_num_h100s_per_step, calculate_total_time_to_train_a_model,\n",
    "    compute_minimum_latency_between_clusters, calculate_total_minimum_comm_latency_to_train_a_model\n",
    ")\n",
    "from utils import (\n",
    "    convert_to_petaflops, convert_to_exaflops, convert_seconds_to_days,\n",
    "    convert_to_xt_format, convert_to_million_format, convert_to_billion_format, convert_seconds_to_years\n",
    ")\n",
    "from constants import UTILIZED_BFLOAT16_FLOPS, H100_COST_PER_HOUR, H100_COST_PER_GPU\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11fc98-3b28-48b1-a575-45a71cf58a02",
   "metadata": {},
   "source": [
    "#### Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd23e6e-342a-4bb9-9df5-8eae0a1925b7",
   "metadata": {},
   "source": [
    "Assumption: one fwd+bwd pass takes a second (if it take x more seconds, then you scale the numbers linearly), 20k per h100 (wholesale price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789c4b71-6311-421f-9da8-7c837b031e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100b to 100T\n",
    "target_model_sizes = [100*10**9, 500*10**9, 1000*10**9, 10000*10**9, 100000*10**9]\n",
    "global_batch_sizes = [x*10**6 for x in [2, 16, 40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f02f48e-3d76-4f34-9fd4-b06a038ddc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_step = 1 # the total time of a fwd, and bwd pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1553384-116a-4d25-b733-6462692bf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_compute = []\n",
    "\n",
    "for global_batch_size in global_batch_sizes:\n",
    "    data_compute = {\n",
    "        \"Model Size (Params)\": [],\n",
    "        \"Dataset Size (Tokens)\": [],\n",
    "        \"Total Steps\": [],\n",
    "        \"Total FLOPs\": [],\n",
    "        \"FLOPs per Step\": [],\n",
    "        \"H100 GPUs Needed\": [],\n",
    "        \"Total H100s cost\": [],\n",
    "        \"Total Training Time without grad accum\": [],\n",
    "        \"Total Training Time with 10 grad accum\": [],\n",
    "        \"Total Training Time with 100 grad accum\": [],\n",
    "        \"Total Training Time with 1000 grad accum\": []\n",
    "    }\n",
    "    \n",
    "    for model_size in target_model_sizes:\n",
    "        dataset_size = get_dataset_size_from_model_size(model_size)\n",
    "        total_steps = calculate_total_steps(model_size, global_batch_size)\n",
    "        total_flops = calculate_total_flops(model_size)\n",
    "        flops_per_step = calculate_flops_per_step(model_size, global_batch_size)\n",
    "        h100s_per_step = calculate_num_h100s_per_step(model_size, global_batch_size, UTILIZED_BFLOAT16_FLOPS)\n",
    "        total_time = calculate_total_time_to_train_a_model(model_size, global_batch_size, time_per_step)\n",
    "        \n",
    "        data_compute[\"Model Size (Params)\"].append(convert_to_xt_format(model_size))\n",
    "        data_compute[\"Dataset Size (Tokens)\"].append(convert_to_xt_format(dataset_size))\n",
    "        data_compute[\"Total Steps\"].append(\"{:,}\".format(total_steps))\n",
    "        data_compute[\"Total FLOPs\"].append(convert_to_exaflops(total_flops))\n",
    "        data_compute[\"FLOPs per Step\"].append(convert_to_petaflops(flops_per_step))\n",
    "        data_compute[\"H100 GPUs Needed\"].append(h100s_per_step)\n",
    "        data_compute[\"Total H100s cost\"].append(convert_to_billion_format(h100s_per_step * H100_COST_PER_GPU))\n",
    "        data_compute[\"Total Training Time without grad accum\"].append(convert_seconds_to_days(total_time))\n",
    "        data_compute[\"Total Training Time with 10 grad accum\"].append(f\"{convert_seconds_to_years(total_time*10)} - {h100s_per_step/10} gpus\")\n",
    "        data_compute[\"Total Training Time with 100 grad accum\"].append(f\"{convert_seconds_to_years(total_time*100)} - {h100s_per_step/100} gpus\")\n",
    "        data_compute[\"Total Training Time with 1000 grad accum\"].append(f\"{convert_seconds_to_years(total_time*1000)} - {h100s_per_step/1000} gpus\")\n",
    "    \n",
    "    df = pd.DataFrame(data_compute)\n",
    "    # Add batch size information\n",
    "    df['Global Batch Size'] = f'{global_batch_size/1e6}M'\n",
    "    dataframes_compute.append(df)\n",
    "\n",
    "final_df_compute = pd.DataFrame()\n",
    "for i, df in enumerate(dataframes_compute):\n",
    "    final_df_compute = pd.concat([final_df_compute, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6188ca7e-09c0-4dee-b71f-75c4d0f56f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Size (Params)</th>\n",
       "      <th>Dataset Size (Tokens)</th>\n",
       "      <th>Total Steps</th>\n",
       "      <th>Total FLOPs</th>\n",
       "      <th>FLOPs per Step</th>\n",
       "      <th>H100 GPUs Needed</th>\n",
       "      <th>Total H100s cost</th>\n",
       "      <th>Total Training Time without grad accum</th>\n",
       "      <th>Total Training Time with 10 grad accum</th>\n",
       "      <th>Total Training Time with 100 grad accum</th>\n",
       "      <th>Total Training Time with 1000 grad accum</th>\n",
       "      <th>Global Batch Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>1,000,000</td>\n",
       "      <td>1,200,000.0 EFLOPs</td>\n",
       "      <td>1,200.0 PFLOPs</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>0.1B</td>\n",
       "      <td>11.574074074074074 days</td>\n",
       "      <td>0.0 years - 220.6 gpus</td>\n",
       "      <td>3.0 years - 22.06 gpus</td>\n",
       "      <td>31.0 years - 2.206 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>5,000,000</td>\n",
       "      <td>30,000,000.0 EFLOPs</td>\n",
       "      <td>6,000.0 PFLOPs</td>\n",
       "      <td>11030.0</td>\n",
       "      <td>0.3B</td>\n",
       "      <td>57.870370370370374 days</td>\n",
       "      <td>1.0 years - 1103.0 gpus</td>\n",
       "      <td>15.0 years - 110.3 gpus</td>\n",
       "      <td>158.0 years - 11.03 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>10,000,000</td>\n",
       "      <td>120,000,000.0 EFLOPs</td>\n",
       "      <td>12,000.0 PFLOPs</td>\n",
       "      <td>22060.0</td>\n",
       "      <td>0.7B</td>\n",
       "      <td>115.74074074074075 days</td>\n",
       "      <td>3.0 years - 2206.0 gpus</td>\n",
       "      <td>31.0 years - 220.6 gpus</td>\n",
       "      <td>316.0 years - 22.06 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>12,000,000,000.0 EFLOPs</td>\n",
       "      <td>120,000.0 PFLOPs</td>\n",
       "      <td>220608.0</td>\n",
       "      <td>6.6B</td>\n",
       "      <td>1,157.4074074074074 days</td>\n",
       "      <td>31.0 years - 22060.8 gpus</td>\n",
       "      <td>316.0 years - 2206.08 gpus</td>\n",
       "      <td>3,168.0 years - 220.608 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>1,000,000,000</td>\n",
       "      <td>1,200,000,000,000.0 EFLOPs</td>\n",
       "      <td>1,200,000.0 PFLOPs</td>\n",
       "      <td>2206085.0</td>\n",
       "      <td>66.2B</td>\n",
       "      <td>11,574.074074074075 days</td>\n",
       "      <td>316.0 years - 220608.5 gpus</td>\n",
       "      <td>3,168.0 years - 22060.85 gpus</td>\n",
       "      <td>31,688.0 years - 2206.085 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>125,000</td>\n",
       "      <td>1,200,000.0 EFLOPs</td>\n",
       "      <td>9,600.0 PFLOPs</td>\n",
       "      <td>17648.0</td>\n",
       "      <td>0.5B</td>\n",
       "      <td>1.4467592592592593 days</td>\n",
       "      <td>0.0 years - 1764.8 gpus</td>\n",
       "      <td>0.0 years - 176.48 gpus</td>\n",
       "      <td>3.0 years - 17.648 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>625,000</td>\n",
       "      <td>30,000,000.0 EFLOPs</td>\n",
       "      <td>48,000.0 PFLOPs</td>\n",
       "      <td>88243.0</td>\n",
       "      <td>2.6B</td>\n",
       "      <td>7.233796296296297 days</td>\n",
       "      <td>0.0 years - 8824.3 gpus</td>\n",
       "      <td>1.0 years - 882.43 gpus</td>\n",
       "      <td>19.0 years - 88.243 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>1,250,000</td>\n",
       "      <td>120,000,000.0 EFLOPs</td>\n",
       "      <td>96,000.0 PFLOPs</td>\n",
       "      <td>176486.0</td>\n",
       "      <td>5.3B</td>\n",
       "      <td>14.467592592592593 days</td>\n",
       "      <td>0.0 years - 17648.6 gpus</td>\n",
       "      <td>3.0 years - 1764.86 gpus</td>\n",
       "      <td>39.0 years - 176.486 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>12,500,000</td>\n",
       "      <td>12,000,000,000.0 EFLOPs</td>\n",
       "      <td>960,000.0 PFLOPs</td>\n",
       "      <td>1764868.0</td>\n",
       "      <td>52.9B</td>\n",
       "      <td>144.67592592592592 days</td>\n",
       "      <td>3.0 years - 176486.8 gpus</td>\n",
       "      <td>39.0 years - 17648.68 gpus</td>\n",
       "      <td>396.0 years - 1764.868 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>125,000,000</td>\n",
       "      <td>1,200,000,000,000.0 EFLOPs</td>\n",
       "      <td>9,600,000.0 PFLOPs</td>\n",
       "      <td>17648680.0</td>\n",
       "      <td>529.5B</td>\n",
       "      <td>1,446.7592592592594 days</td>\n",
       "      <td>39.0 years - 1764868.0 gpus</td>\n",
       "      <td>396.0 years - 176486.8 gpus</td>\n",
       "      <td>3,961.0 years - 17648.68 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>50,000</td>\n",
       "      <td>1,200,000.0 EFLOPs</td>\n",
       "      <td>24,000.0 PFLOPs</td>\n",
       "      <td>44121.0</td>\n",
       "      <td>1.3B</td>\n",
       "      <td>0.5787037037037037 days</td>\n",
       "      <td>0.0 years - 4412.1 gpus</td>\n",
       "      <td>0.0 years - 441.21 gpus</td>\n",
       "      <td>1.0 years - 44.121 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>250,000</td>\n",
       "      <td>30,000,000.0 EFLOPs</td>\n",
       "      <td>120,000.0 PFLOPs</td>\n",
       "      <td>220608.0</td>\n",
       "      <td>6.6B</td>\n",
       "      <td>2.8935185185185186 days</td>\n",
       "      <td>0.0 years - 22060.8 gpus</td>\n",
       "      <td>0.0 years - 2206.08 gpus</td>\n",
       "      <td>7.0 years - 220.608 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>500,000</td>\n",
       "      <td>120,000,000.0 EFLOPs</td>\n",
       "      <td>240,000.0 PFLOPs</td>\n",
       "      <td>441217.0</td>\n",
       "      <td>13.2B</td>\n",
       "      <td>5.787037037037037 days</td>\n",
       "      <td>0.0 years - 44121.7 gpus</td>\n",
       "      <td>1.0 years - 4412.17 gpus</td>\n",
       "      <td>15.0 years - 441.217 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>5,000,000</td>\n",
       "      <td>12,000,000,000.0 EFLOPs</td>\n",
       "      <td>2,400,000.0 PFLOPs</td>\n",
       "      <td>4412170.0</td>\n",
       "      <td>132.4B</td>\n",
       "      <td>57.870370370370374 days</td>\n",
       "      <td>1.0 years - 441217.0 gpus</td>\n",
       "      <td>15.0 years - 44121.7 gpus</td>\n",
       "      <td>158.0 years - 4412.17 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>50,000,000</td>\n",
       "      <td>1,200,000,000,000.0 EFLOPs</td>\n",
       "      <td>24,000,000.0 PFLOPs</td>\n",
       "      <td>44121702.0</td>\n",
       "      <td>1323.7B</td>\n",
       "      <td>578.7037037037037 days</td>\n",
       "      <td>15.0 years - 4412170.2 gpus</td>\n",
       "      <td>158.0 years - 441217.02 gpus</td>\n",
       "      <td>1,584.0 years - 44121.702 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Size (Params) Dataset Size (Tokens)    Total Steps  \\\n",
       "0                0.1T                  2.0T      1,000,000   \n",
       "1                0.5T                 10.0T      5,000,000   \n",
       "2                1.0T                 20.0T     10,000,000   \n",
       "3               10.0T                200.0T    100,000,000   \n",
       "4              100.0T               2000.0T  1,000,000,000   \n",
       "0                0.1T                  2.0T        125,000   \n",
       "1                0.5T                 10.0T        625,000   \n",
       "2                1.0T                 20.0T      1,250,000   \n",
       "3               10.0T                200.0T     12,500,000   \n",
       "4              100.0T               2000.0T    125,000,000   \n",
       "0                0.1T                  2.0T         50,000   \n",
       "1                0.5T                 10.0T        250,000   \n",
       "2                1.0T                 20.0T        500,000   \n",
       "3               10.0T                200.0T      5,000,000   \n",
       "4              100.0T               2000.0T     50,000,000   \n",
       "\n",
       "                  Total FLOPs       FLOPs per Step  H100 GPUs Needed  \\\n",
       "0          1,200,000.0 EFLOPs       1,200.0 PFLOPs            2206.0   \n",
       "1         30,000,000.0 EFLOPs       6,000.0 PFLOPs           11030.0   \n",
       "2        120,000,000.0 EFLOPs      12,000.0 PFLOPs           22060.0   \n",
       "3     12,000,000,000.0 EFLOPs     120,000.0 PFLOPs          220608.0   \n",
       "4  1,200,000,000,000.0 EFLOPs   1,200,000.0 PFLOPs         2206085.0   \n",
       "0          1,200,000.0 EFLOPs       9,600.0 PFLOPs           17648.0   \n",
       "1         30,000,000.0 EFLOPs      48,000.0 PFLOPs           88243.0   \n",
       "2        120,000,000.0 EFLOPs      96,000.0 PFLOPs          176486.0   \n",
       "3     12,000,000,000.0 EFLOPs     960,000.0 PFLOPs         1764868.0   \n",
       "4  1,200,000,000,000.0 EFLOPs   9,600,000.0 PFLOPs        17648680.0   \n",
       "0          1,200,000.0 EFLOPs      24,000.0 PFLOPs           44121.0   \n",
       "1         30,000,000.0 EFLOPs     120,000.0 PFLOPs          220608.0   \n",
       "2        120,000,000.0 EFLOPs     240,000.0 PFLOPs          441217.0   \n",
       "3     12,000,000,000.0 EFLOPs   2,400,000.0 PFLOPs         4412170.0   \n",
       "4  1,200,000,000,000.0 EFLOPs  24,000,000.0 PFLOPs        44121702.0   \n",
       "\n",
       "  Total H100s cost Total Training Time without grad accum  \\\n",
       "0             0.1B                11.574074074074074 days   \n",
       "1             0.3B                57.870370370370374 days   \n",
       "2             0.7B                115.74074074074075 days   \n",
       "3             6.6B               1,157.4074074074074 days   \n",
       "4            66.2B               11,574.074074074075 days   \n",
       "0             0.5B                1.4467592592592593 days   \n",
       "1             2.6B                 7.233796296296297 days   \n",
       "2             5.3B                14.467592592592593 days   \n",
       "3            52.9B                144.67592592592592 days   \n",
       "4           529.5B               1,446.7592592592594 days   \n",
       "0             1.3B                0.5787037037037037 days   \n",
       "1             6.6B                2.8935185185185186 days   \n",
       "2            13.2B                 5.787037037037037 days   \n",
       "3           132.4B                57.870370370370374 days   \n",
       "4          1323.7B                 578.7037037037037 days   \n",
       "\n",
       "  Total Training Time with 10 grad accum  \\\n",
       "0                 0.0 years - 220.6 gpus   \n",
       "1                1.0 years - 1103.0 gpus   \n",
       "2                3.0 years - 2206.0 gpus   \n",
       "3              31.0 years - 22060.8 gpus   \n",
       "4            316.0 years - 220608.5 gpus   \n",
       "0                0.0 years - 1764.8 gpus   \n",
       "1                0.0 years - 8824.3 gpus   \n",
       "2               0.0 years - 17648.6 gpus   \n",
       "3              3.0 years - 176486.8 gpus   \n",
       "4            39.0 years - 1764868.0 gpus   \n",
       "0                0.0 years - 4412.1 gpus   \n",
       "1               0.0 years - 22060.8 gpus   \n",
       "2               0.0 years - 44121.7 gpus   \n",
       "3              1.0 years - 441217.0 gpus   \n",
       "4            15.0 years - 4412170.2 gpus   \n",
       "\n",
       "  Total Training Time with 100 grad accum  \\\n",
       "0                  3.0 years - 22.06 gpus   \n",
       "1                 15.0 years - 110.3 gpus   \n",
       "2                 31.0 years - 220.6 gpus   \n",
       "3              316.0 years - 2206.08 gpus   \n",
       "4           3,168.0 years - 22060.85 gpus   \n",
       "0                 0.0 years - 176.48 gpus   \n",
       "1                 1.0 years - 882.43 gpus   \n",
       "2                3.0 years - 1764.86 gpus   \n",
       "3              39.0 years - 17648.68 gpus   \n",
       "4             396.0 years - 176486.8 gpus   \n",
       "0                 0.0 years - 441.21 gpus   \n",
       "1                0.0 years - 2206.08 gpus   \n",
       "2                1.0 years - 4412.17 gpus   \n",
       "3               15.0 years - 44121.7 gpus   \n",
       "4            158.0 years - 441217.02 gpus   \n",
       "\n",
       "  Total Training Time with 1000 grad accum Global Batch Size  \n",
       "0                  31.0 years - 2.206 gpus              2.0M  \n",
       "1                 158.0 years - 11.03 gpus              2.0M  \n",
       "2                 316.0 years - 22.06 gpus              2.0M  \n",
       "3             3,168.0 years - 220.608 gpus              2.0M  \n",
       "4           31,688.0 years - 2206.085 gpus              2.0M  \n",
       "0                  3.0 years - 17.648 gpus             16.0M  \n",
       "1                 19.0 years - 88.243 gpus             16.0M  \n",
       "2                39.0 years - 176.486 gpus             16.0M  \n",
       "3              396.0 years - 1764.868 gpus             16.0M  \n",
       "4            3,961.0 years - 17648.68 gpus             16.0M  \n",
       "0                  1.0 years - 44.121 gpus             40.0M  \n",
       "1                 7.0 years - 220.608 gpus             40.0M  \n",
       "2                15.0 years - 441.217 gpus             40.0M  \n",
       "3               158.0 years - 4412.17 gpus             40.0M  \n",
       "4           1,584.0 years - 44121.702 gpus             40.0M  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4032de16-00f5-4881-8746-97ae7026ecda",
   "metadata": {},
   "source": [
    "##### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a54207cd-a0b5-4bed-aacd-ff3ee447f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import FP8_BYTES, BFLOAT16_BYTES\n",
    "from utils import convert_bytes_to_terabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b702221-3a61-4cf9-9470-9e74aed3f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mem = {\n",
    "    \"Model Size (Params)\": [],\n",
    "    \"Total bfloat16 gradient storage\": [],\n",
    "    \"Total fp8 gradient storage\": [],\n",
    "}\n",
    "\n",
    "for model_size in target_model_sizes:        \n",
    "    data_mem[\"Model Size (Params)\"].append(convert_to_xt_format(model_size))\n",
    "    data_mem[\"Total bfloat16 gradient storage\"].append(convert_bytes_to_terabytes(model_size * BFLOAT16_BYTES))\n",
    "    data_mem[\"Total fp8 gradient storage\"].append(convert_bytes_to_terabytes(model_size * FP8_BYTES))\n",
    "\n",
    "df_mem = pd.DataFrame(data_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b92fc56-67f2-4502-a4dd-36e6f4c612fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Size (Params)</th>\n",
       "      <th>Total bfloat16 gradient storage</th>\n",
       "      <th>Total fp8 gradient storage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>0.200 TB</td>\n",
       "      <td>0.100 TB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>1.000 TB</td>\n",
       "      <td>0.500 TB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>2.000 TB</td>\n",
       "      <td>1.000 TB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>20.000 TB</td>\n",
       "      <td>10.000 TB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>200.000 TB</td>\n",
       "      <td>100.000 TB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Size (Params) Total bfloat16 gradient storage  \\\n",
       "0                0.1T                        0.200 TB   \n",
       "1                0.5T                        1.000 TB   \n",
       "2                1.0T                        2.000 TB   \n",
       "3               10.0T                       20.000 TB   \n",
       "4              100.0T                      200.000 TB   \n",
       "\n",
       "  Total fp8 gradient storage  \n",
       "0                   0.100 TB  \n",
       "1                   0.500 TB  \n",
       "2                   1.000 TB  \n",
       "3                  10.000 TB  \n",
       "4                 100.000 TB  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97153b-7c80-45de-bffc-31dd0caa676d",
   "metadata": {},
   "source": [
    "#### Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ba983-2882-48d4-9541-1bd8faabfddb",
   "metadata": {},
   "source": [
    "Assumptions on communication\n",
    "- No limit on banwidth\n",
    "- Achieve speed of light\n",
    "- Clostest surface distance between two points on the earth surface (assume you don't dig a crazy hole to go a straight line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b40c02-2ac3-4dce-947e-a4915b7518f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_latency_between_jz_and_jc = compute_minimum_latency_between_clusters(\"JEAN_ZAY\", \"JOLIOT_CURIE\")\n",
    "minimum_latency_between_jz_and_ec = compute_minimum_latency_between_clusters(\"JEAN_ZAY\", \"EL_CAPITAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba98b7a-e713-446d-9dad-613b76d447e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_comm = []\n",
    "\n",
    "for global_batch_size in global_batch_sizes:\n",
    "    data_comm = {\n",
    "        \"Model Size (Params)\": [],\n",
    "        \"Dataset Size (Tokens)\": [],\n",
    "        \n",
    "        \"Total minimum communication latency between JZ and JC\": [],\n",
    "        \"Total GPU idle time for minimum comm between JZ and JC\": [],\n",
    "        \"GPU idle cost during JZ-JC minimum communication latency\": [],\n",
    "        \n",
    "        \"Total minimum communication latency between JZ and EC\": [],\n",
    "        \"Total GPU idle time for minimum comm between JZ and EC\": [],\n",
    "        \"GPU idle cost during JZ-EC minimum communication latency\": [],\n",
    "    }\n",
    "    \n",
    "    for model_size in target_model_sizes:\n",
    "        dataset_size = get_dataset_size_from_model_size(model_size)\n",
    "        # Append to dictionary\n",
    "        data_comm[\"Model Size (Params)\"].append(convert_to_xt_format(model_size))\n",
    "        data_comm[\"Dataset Size (Tokens)\"].append(convert_to_xt_format(dataset_size))\n",
    "        \n",
    "        data_comm[\"Total minimum communication latency between JZ and JC\"].append(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_jc))\n",
    "        data_comm[\"Total GPU idle time for minimum comm between JZ and JC\"].append(convert_seconds_to_days(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_jc) * h100s_per_step))\n",
    "        data_comm[\"GPU idle cost during JZ-JC minimum communication latency\"].append(convert_to_million_format((calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_jc) / (60 * 60)) * h100s_per_step * H100_COST_PER_HOUR))\n",
    "        \n",
    "        data_comm[\"Total minimum communication latency between JZ and EC\"].append(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_ec))\n",
    "        data_comm[\"Total GPU idle time for minimum comm between JZ and EC\"].append(convert_seconds_to_years(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_ec) * h100s_per_step))\n",
    "        data_comm[\"GPU idle cost during JZ-EC minimum communication latency\"].append(convert_to_million_format((calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_ec) / (60 * 60)) * h100s_per_step * H100_COST_PER_HOUR))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_comm = pd.DataFrame(data_comm)\n",
    "    df_comm['Global Batch Size'] = f'{global_batch_size/1e6}M'\n",
    "    dataframes_comm.append(df_comm)\n",
    "\n",
    "final_df_comm = pd.DataFrame()\n",
    "for i, df in enumerate(dataframes_comm):\n",
    "    final_df_comm = pd.concat([final_df_comm, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e897a27-98f8-43a8-aec6-55310d7da1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Size (Params)</th>\n",
       "      <th>Dataset Size (Tokens)</th>\n",
       "      <th>Total minimum communication latency between JZ and JC</th>\n",
       "      <th>Total GPU idle time for minimum comm between JZ and JC</th>\n",
       "      <th>GPU idle cost during JZ-JC minimum communication latency</th>\n",
       "      <th>Total minimum communication latency between JZ and EC</th>\n",
       "      <th>Total GPU idle time for minimum comm between JZ and EC</th>\n",
       "      <th>GPU idle cost during JZ-EC minimum communication latency</th>\n",
       "      <th>Global Batch Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>1.278270</td>\n",
       "      <td>652.7716235955164 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>29.790336</td>\n",
       "      <td>41.0 years</td>\n",
       "      <td>0.7m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>6.391352</td>\n",
       "      <td>3,263.858117977583 days</td>\n",
       "      <td>0.2m</td>\n",
       "      <td>148.951681</td>\n",
       "      <td>208.0 years</td>\n",
       "      <td>3.7m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>12.782705</td>\n",
       "      <td>6,527.716235955166 days</td>\n",
       "      <td>0.3m</td>\n",
       "      <td>297.903362</td>\n",
       "      <td>416.0 years</td>\n",
       "      <td>7.3m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>127.827046</td>\n",
       "      <td>65,277.16235955166 days</td>\n",
       "      <td>3.1m</td>\n",
       "      <td>2979.033618</td>\n",
       "      <td>4,165.0 years</td>\n",
       "      <td>73.0m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>1278.270459</td>\n",
       "      <td>652,771.6235955165 days</td>\n",
       "      <td>31.3m</td>\n",
       "      <td>29790.336181</td>\n",
       "      <td>41,650.0 years</td>\n",
       "      <td>730.2m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>0.159784</td>\n",
       "      <td>81.59645294943955 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>3.723792</td>\n",
       "      <td>5.0 years</td>\n",
       "      <td>0.1m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>0.798919</td>\n",
       "      <td>407.98226474719786 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>18.618960</td>\n",
       "      <td>26.0 years</td>\n",
       "      <td>0.5m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>1.597838</td>\n",
       "      <td>815.9645294943957 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>37.237920</td>\n",
       "      <td>52.0 years</td>\n",
       "      <td>0.9m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>15.978381</td>\n",
       "      <td>8,159.645294943957 days</td>\n",
       "      <td>0.4m</td>\n",
       "      <td>372.379202</td>\n",
       "      <td>520.0 years</td>\n",
       "      <td>9.1m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>159.783807</td>\n",
       "      <td>81,596.45294943957 days</td>\n",
       "      <td>3.9m</td>\n",
       "      <td>3723.792023</td>\n",
       "      <td>5,206.0 years</td>\n",
       "      <td>91.3m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>0.063914</td>\n",
       "      <td>32.638581179775834 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>1.489517</td>\n",
       "      <td>2.0 years</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>0.319568</td>\n",
       "      <td>163.1929058988791 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>7.447584</td>\n",
       "      <td>10.0 years</td>\n",
       "      <td>0.2m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>0.639135</td>\n",
       "      <td>326.3858117977582 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>14.895168</td>\n",
       "      <td>20.0 years</td>\n",
       "      <td>0.4m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>6.391352</td>\n",
       "      <td>3,263.858117977583 days</td>\n",
       "      <td>0.2m</td>\n",
       "      <td>148.951681</td>\n",
       "      <td>208.0 years</td>\n",
       "      <td>3.7m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>63.913523</td>\n",
       "      <td>32,638.58117977583 days</td>\n",
       "      <td>1.6m</td>\n",
       "      <td>1489.516809</td>\n",
       "      <td>2,082.0 years</td>\n",
       "      <td>36.5m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Size (Params) Dataset Size (Tokens)  \\\n",
       "0                0.1T                  2.0T   \n",
       "1                0.5T                 10.0T   \n",
       "2                1.0T                 20.0T   \n",
       "3               10.0T                200.0T   \n",
       "4              100.0T               2000.0T   \n",
       "0                0.1T                  2.0T   \n",
       "1                0.5T                 10.0T   \n",
       "2                1.0T                 20.0T   \n",
       "3               10.0T                200.0T   \n",
       "4              100.0T               2000.0T   \n",
       "0                0.1T                  2.0T   \n",
       "1                0.5T                 10.0T   \n",
       "2                1.0T                 20.0T   \n",
       "3               10.0T                200.0T   \n",
       "4              100.0T               2000.0T   \n",
       "\n",
       "   Total minimum communication latency between JZ and JC  \\\n",
       "0                                           1.278270       \n",
       "1                                           6.391352       \n",
       "2                                          12.782705       \n",
       "3                                         127.827046       \n",
       "4                                        1278.270459       \n",
       "0                                           0.159784       \n",
       "1                                           0.798919       \n",
       "2                                           1.597838       \n",
       "3                                          15.978381       \n",
       "4                                         159.783807       \n",
       "0                                           0.063914       \n",
       "1                                           0.319568       \n",
       "2                                           0.639135       \n",
       "3                                           6.391352       \n",
       "4                                          63.913523       \n",
       "\n",
       "  Total GPU idle time for minimum comm between JZ and JC  \\\n",
       "0                             652.7716235955164 days       \n",
       "1                            3,263.858117977583 days       \n",
       "2                            6,527.716235955166 days       \n",
       "3                            65,277.16235955166 days       \n",
       "4                            652,771.6235955165 days       \n",
       "0                             81.59645294943955 days       \n",
       "1                            407.98226474719786 days       \n",
       "2                             815.9645294943957 days       \n",
       "3                            8,159.645294943957 days       \n",
       "4                            81,596.45294943957 days       \n",
       "0                            32.638581179775834 days       \n",
       "1                             163.1929058988791 days       \n",
       "2                             326.3858117977582 days       \n",
       "3                            3,263.858117977583 days       \n",
       "4                            32,638.58117977583 days       \n",
       "\n",
       "  GPU idle cost during JZ-JC minimum communication latency  \\\n",
       "0                                               0.0m         \n",
       "1                                               0.2m         \n",
       "2                                               0.3m         \n",
       "3                                               3.1m         \n",
       "4                                              31.3m         \n",
       "0                                               0.0m         \n",
       "1                                               0.0m         \n",
       "2                                               0.0m         \n",
       "3                                               0.4m         \n",
       "4                                               3.9m         \n",
       "0                                               0.0m         \n",
       "1                                               0.0m         \n",
       "2                                               0.0m         \n",
       "3                                               0.2m         \n",
       "4                                               1.6m         \n",
       "\n",
       "   Total minimum communication latency between JZ and EC  \\\n",
       "0                                          29.790336       \n",
       "1                                         148.951681       \n",
       "2                                         297.903362       \n",
       "3                                        2979.033618       \n",
       "4                                       29790.336181       \n",
       "0                                           3.723792       \n",
       "1                                          18.618960       \n",
       "2                                          37.237920       \n",
       "3                                         372.379202       \n",
       "4                                        3723.792023       \n",
       "0                                           1.489517       \n",
       "1                                           7.447584       \n",
       "2                                          14.895168       \n",
       "3                                         148.951681       \n",
       "4                                        1489.516809       \n",
       "\n",
       "  Total GPU idle time for minimum comm between JZ and EC  \\\n",
       "0                                         41.0 years       \n",
       "1                                        208.0 years       \n",
       "2                                        416.0 years       \n",
       "3                                      4,165.0 years       \n",
       "4                                     41,650.0 years       \n",
       "0                                          5.0 years       \n",
       "1                                         26.0 years       \n",
       "2                                         52.0 years       \n",
       "3                                        520.0 years       \n",
       "4                                      5,206.0 years       \n",
       "0                                          2.0 years       \n",
       "1                                         10.0 years       \n",
       "2                                         20.0 years       \n",
       "3                                        208.0 years       \n",
       "4                                      2,082.0 years       \n",
       "\n",
       "  GPU idle cost during JZ-EC minimum communication latency Global Batch Size  \n",
       "0                                               0.7m                    2.0M  \n",
       "1                                               3.7m                    2.0M  \n",
       "2                                               7.3m                    2.0M  \n",
       "3                                              73.0m                    2.0M  \n",
       "4                                             730.2m                    2.0M  \n",
       "0                                               0.1m                   16.0M  \n",
       "1                                               0.5m                   16.0M  \n",
       "2                                               0.9m                   16.0M  \n",
       "3                                               9.1m                   16.0M  \n",
       "4                                              91.3m                   16.0M  \n",
       "0                                               0.0m                   40.0M  \n",
       "1                                               0.2m                   40.0M  \n",
       "2                                               0.4m                   40.0M  \n",
       "3                                               3.7m                   40.0M  \n",
       "4                                              36.5m                   40.0M  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_comm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a547c9e-def0-4c82-a541-517ec6d127c6",
   "metadata": {},
   "source": [
    "#### Electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2735f7c7-3210-414b-9590-b2c3a0620355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import TOTAL_H100_WATT\n",
    "from utils import convert_watts_to_megawatts, convert_watts_to_terawatts, calculate_electricity_consumption_of_an_h100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8857f303-4c68-4db4-9912-9f1fdd3afa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_elec = []\n",
    "\n",
    "for global_batch_size in global_batch_sizes:\n",
    "    data_elec = {\n",
    "        \"Model Size (Params)\": [],\n",
    "        \"Dataset Size (Tokens)\": [],\n",
    "        \"Number of GPUs\": [],\n",
    "        \"Total electricity per step (without grad accum)\": [],\n",
    "        \"Total electricity for the entire training (without grad accum)\": []\n",
    "    }\n",
    "    \n",
    "    for model_size in target_model_sizes:\n",
    "        dataset_size = get_dataset_size_from_model_size(model_size)\n",
    "        h100s_per_step = calculate_num_h100s_per_step(model_size, global_batch_size, UTILIZED_BFLOAT16_FLOPS)\n",
    "        total_time = calculate_total_time_to_train_a_model(model_size, global_batch_size, time_per_step)\n",
    "        total_electricity_consumption = calculate_electricity_consumption_of_an_h100(TOTAL_H100_WATT, total_time) * h100s_per_step\n",
    "        \n",
    "        data_elec[\"Model Size (Params)\"].append(convert_to_xt_format(model_size))\n",
    "        data_elec[\"Dataset Size (Tokens)\"].append(convert_to_xt_format(dataset_size))\n",
    "        data_elec[\"Number of GPUs\"].append(h100s_per_step)\n",
    "        data_elec[\"Total electricity per step (without grad accum)\"].append(convert_watts_to_megawatts(h100s_per_step * TOTAL_H100_WATT))\n",
    "        data_elec[\"Total electricity for the entire training (without grad accum)\"].append(f\"{convert_watts_to_terawatts(total_electricity_consumption)}\")\n",
    "    \n",
    "    df = pd.DataFrame(data_elec)\n",
    "    df['Global Batch Size'] = f'{global_batch_size/1e6}M'\n",
    "    dataframes_elec.append(df)\n",
    "\n",
    "final_df_elec = pd.DataFrame()\n",
    "for i, df in enumerate(dataframes_elec):\n",
    "    final_df_elec = pd.concat([final_df_elec, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96921a0d-6fc4-471b-a0d7-47e1c5ecd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my calculation closes to 100k gpu cluster's electricity: https://semianalysis.com/2024/06/17/100000-h100-clusters-power-network/#power-challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8152cae-4337-4743-a9ba-e9fe58fa946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Size (Params)</th>\n",
       "      <th>Dataset Size (Tokens)</th>\n",
       "      <th>Number of GPUs</th>\n",
       "      <th>Total electricity per step (without grad accum)</th>\n",
       "      <th>Total electricity for the entire training (without grad accum)</th>\n",
       "      <th>Global Batch Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>2.813 MW</td>\n",
       "      <td>2.812650000000 TW</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>11030.0</td>\n",
       "      <td>14.063 MW</td>\n",
       "      <td>70.316250000000 TW</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>22060.0</td>\n",
       "      <td>28.127 MW</td>\n",
       "      <td>281.265000000000 TW</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>220608.0</td>\n",
       "      <td>281.275 MW</td>\n",
       "      <td>28127.520000000000 TW</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>2206085.0</td>\n",
       "      <td>2812.758 MW</td>\n",
       "      <td>2812758.375000000000 TW</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>17648.0</td>\n",
       "      <td>22.501 MW</td>\n",
       "      <td>2.812650000000 TW</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>88243.0</td>\n",
       "      <td>112.510 MW</td>\n",
       "      <td>70.318640625000 TW</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>176486.0</td>\n",
       "      <td>225.020 MW</td>\n",
       "      <td>281.274562500000 TW</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>1764868.0</td>\n",
       "      <td>2250.207 MW</td>\n",
       "      <td>28127.583750000002 TW</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>17648680.0</td>\n",
       "      <td>22502.067 MW</td>\n",
       "      <td>2812758.375000000000 TW</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>44121.0</td>\n",
       "      <td>56.254 MW</td>\n",
       "      <td>2.812713750000 TW</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>220608.0</td>\n",
       "      <td>281.275 MW</td>\n",
       "      <td>70.318800000000 TW</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>441217.0</td>\n",
       "      <td>562.552 MW</td>\n",
       "      <td>281.275837500000 TW</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>4412170.0</td>\n",
       "      <td>5625.517 MW</td>\n",
       "      <td>28127.583750000002 TW</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>44121702.0</td>\n",
       "      <td>56255.170 MW</td>\n",
       "      <td>2812758.502499999944 TW</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Size (Params) Dataset Size (Tokens)  Number of GPUs  \\\n",
       "0                0.1T                  2.0T          2206.0   \n",
       "1                0.5T                 10.0T         11030.0   \n",
       "2                1.0T                 20.0T         22060.0   \n",
       "3               10.0T                200.0T        220608.0   \n",
       "4              100.0T               2000.0T       2206085.0   \n",
       "0                0.1T                  2.0T         17648.0   \n",
       "1                0.5T                 10.0T         88243.0   \n",
       "2                1.0T                 20.0T        176486.0   \n",
       "3               10.0T                200.0T       1764868.0   \n",
       "4              100.0T               2000.0T      17648680.0   \n",
       "0                0.1T                  2.0T         44121.0   \n",
       "1                0.5T                 10.0T        220608.0   \n",
       "2                1.0T                 20.0T        441217.0   \n",
       "3               10.0T                200.0T       4412170.0   \n",
       "4              100.0T               2000.0T      44121702.0   \n",
       "\n",
       "  Total electricity per step (without grad accum)  \\\n",
       "0                                        2.813 MW   \n",
       "1                                       14.063 MW   \n",
       "2                                       28.127 MW   \n",
       "3                                      281.275 MW   \n",
       "4                                     2812.758 MW   \n",
       "0                                       22.501 MW   \n",
       "1                                      112.510 MW   \n",
       "2                                      225.020 MW   \n",
       "3                                     2250.207 MW   \n",
       "4                                    22502.067 MW   \n",
       "0                                       56.254 MW   \n",
       "1                                      281.275 MW   \n",
       "2                                      562.552 MW   \n",
       "3                                     5625.517 MW   \n",
       "4                                    56255.170 MW   \n",
       "\n",
       "  Total electricity for the entire training (without grad accum)  \\\n",
       "0                                  2.812650000000 TW               \n",
       "1                                 70.316250000000 TW               \n",
       "2                                281.265000000000 TW               \n",
       "3                              28127.520000000000 TW               \n",
       "4                            2812758.375000000000 TW               \n",
       "0                                  2.812650000000 TW               \n",
       "1                                 70.318640625000 TW               \n",
       "2                                281.274562500000 TW               \n",
       "3                              28127.583750000002 TW               \n",
       "4                            2812758.375000000000 TW               \n",
       "0                                  2.812713750000 TW               \n",
       "1                                 70.318800000000 TW               \n",
       "2                                281.275837500000 TW               \n",
       "3                              28127.583750000002 TW               \n",
       "4                            2812758.502499999944 TW               \n",
       "\n",
       "  Global Batch Size  \n",
       "0              2.0M  \n",
       "1              2.0M  \n",
       "2              2.0M  \n",
       "3              2.0M  \n",
       "4              2.0M  \n",
       "0             16.0M  \n",
       "1             16.0M  \n",
       "2             16.0M  \n",
       "3             16.0M  \n",
       "4             16.0M  \n",
       "0             40.0M  \n",
       "1             40.0M  \n",
       "2             40.0M  \n",
       "3             40.0M  \n",
       "4             40.0M  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e422830-704f-4af3-9c81-3b6ee3a8eb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c797a-2914-4eb3-bdae-ce7f0026be1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e1305-4452-4fd0-8f4a-b8d8d860058e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
