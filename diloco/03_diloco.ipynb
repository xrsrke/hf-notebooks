{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e47cbb-4314-4afb-9630-30c1af8e9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    get_dataset_size_from_model_size, calculate_total_steps, calculate_total_flops, calculate_flops_per_step,\n",
    "    calculate_num_h100s_per_step, calculate_total_time_to_train_a_model,\n",
    "    compute_minimum_latency_between_clusters, calculate_total_minimum_comm_latency_to_train_a_model\n",
    ")\n",
    "from utils import (\n",
    "    convert_to_petaflops, convert_to_exaflops, convert_seconds_to_days,\n",
    "    convert_to_xt_format, convert_to_million_format, convert_seconds_to_years\n",
    ")\n",
    "from constants import UTILIZED_BFLOAT16_FLOPS, H100_COST_PER_HOUR\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11fc98-3b28-48b1-a575-45a71cf58a02",
   "metadata": {},
   "source": [
    "#### Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789c4b71-6311-421f-9da8-7c837b031e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100b to 100T\n",
    "target_model_sizes = [100*10**9, 500*10**9, 1000*10**9, 10000*10**9, 100000*10**9]\n",
    "global_batch_sizes = [x*10**6 for x in [2, 16, 40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f02f48e-3d76-4f34-9fd4-b06a038ddc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_step = 1 # the total time of a fwd, and bwd pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1553384-116a-4d25-b733-6462692bf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_compute = []\n",
    "\n",
    "for global_batch_size in global_batch_sizes:\n",
    "    data_compute = {\n",
    "        \"Model Size (Params)\": [],\n",
    "        \"Dataset Size (Tokens)\": [],\n",
    "        \"Total Steps\": [],\n",
    "        \"Total FLOPs\": [],\n",
    "        \"FLOPs per Step\": [],\n",
    "        \"H100 GPUs Needed\": [],\n",
    "        \"Total Training Time without grad accum\": [],\n",
    "        \"Total Training Time with 10 grad accum\": [],\n",
    "        \"Total Training Time with 100 grad accum\": [],\n",
    "        \"Total Training Time with 1000 grad accum\": []\n",
    "    }\n",
    "    \n",
    "    for model_size in target_model_sizes:\n",
    "        dataset_size = get_dataset_size_from_model_size(model_size)\n",
    "        total_steps = calculate_total_steps(model_size, global_batch_size)\n",
    "        total_flops = calculate_total_flops(model_size)\n",
    "        flops_per_step = calculate_flops_per_step(model_size, global_batch_size)\n",
    "        h100s_per_step = calculate_num_h100s_per_step(model_size, global_batch_size, UTILIZED_BFLOAT16_FLOPS)\n",
    "        total_time = calculate_total_time_to_train_a_model(model_size, global_batch_size, time_per_step)\n",
    "        \n",
    "        data_compute[\"Model Size (Params)\"].append(convert_to_xt_format(model_size))\n",
    "        data_compute[\"Dataset Size (Tokens)\"].append(convert_to_xt_format(dataset_size))\n",
    "        data_compute[\"Total Steps\"].append(total_steps)\n",
    "        data_compute[\"Total FLOPs\"].append(convert_to_exaflops(total_flops))\n",
    "        data_compute[\"FLOPs per Step\"].append(convert_to_petaflops(flops_per_step))\n",
    "        data_compute[\"H100 GPUs Needed\"].append(h100s_per_step)\n",
    "        data_compute[\"Total Training Time without grad accum\"].append(convert_seconds_to_days(total_time))\n",
    "        data_compute[\"Total Training Time with 10 grad accum\"].append(f\"{convert_seconds_to_years(total_time*10)} - {h100s_per_step/10} gpus\")\n",
    "        data_compute[\"Total Training Time with 100 grad accum\"].append(f\"{convert_seconds_to_years(total_time*100)} - {h100s_per_step/100} gpus\")\n",
    "        data_compute[\"Total Training Time with 1000 grad accum\"].append(f\"{convert_seconds_to_years(total_time*1000)} - {h100s_per_step/1000} gpus\")\n",
    "    \n",
    "    df = pd.DataFrame(data_compute)\n",
    "    # Add batch size information\n",
    "    df['Global Batch Size'] = f'{global_batch_size/1e6}M'\n",
    "    dataframes_compute.append(df)\n",
    "\n",
    "final_df_compute = pd.DataFrame()\n",
    "for i, df in enumerate(dataframes_compute):\n",
    "    final_df_compute = pd.concat([final_df_compute, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6188ca7e-09c0-4dee-b71f-75c4d0f56f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Size (Params)</th>\n",
       "      <th>Dataset Size (Tokens)</th>\n",
       "      <th>Total Steps</th>\n",
       "      <th>Total FLOPs</th>\n",
       "      <th>FLOPs per Step</th>\n",
       "      <th>H100 GPUs Needed</th>\n",
       "      <th>Total Training Time without grad accum</th>\n",
       "      <th>Total Training Time with 10 grad accum</th>\n",
       "      <th>Total Training Time with 100 grad accum</th>\n",
       "      <th>Total Training Time with 1000 grad accum</th>\n",
       "      <th>Global Batch Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1200000.000 EFLOPs</td>\n",
       "      <td>1200.000 PFLOPs</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>11.574 days</td>\n",
       "      <td>0.317 years - 220.6 gpus</td>\n",
       "      <td>3.169 years - 22.06 gpus</td>\n",
       "      <td>31.688 years - 2.206 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>5000000</td>\n",
       "      <td>30000000.000 EFLOPs</td>\n",
       "      <td>6000.000 PFLOPs</td>\n",
       "      <td>11030.0</td>\n",
       "      <td>57.870 days</td>\n",
       "      <td>1.584 years - 1103.0 gpus</td>\n",
       "      <td>15.844 years - 110.3 gpus</td>\n",
       "      <td>158.440 years - 11.03 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>10000000</td>\n",
       "      <td>120000000.000 EFLOPs</td>\n",
       "      <td>12000.000 PFLOPs</td>\n",
       "      <td>22060.0</td>\n",
       "      <td>115.741 days</td>\n",
       "      <td>3.169 years - 2206.0 gpus</td>\n",
       "      <td>31.688 years - 220.6 gpus</td>\n",
       "      <td>316.881 years - 22.06 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>100000000</td>\n",
       "      <td>12000000000.000 EFLOPs</td>\n",
       "      <td>120000.000 PFLOPs</td>\n",
       "      <td>220608.0</td>\n",
       "      <td>1157.407 days</td>\n",
       "      <td>31.688 years - 22060.8 gpus</td>\n",
       "      <td>316.881 years - 2206.08 gpus</td>\n",
       "      <td>3168.809 years - 220.608 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>1200000000000.000 EFLOPs</td>\n",
       "      <td>1200000.000 PFLOPs</td>\n",
       "      <td>2206085.0</td>\n",
       "      <td>11574.074 days</td>\n",
       "      <td>316.881 years - 220608.5 gpus</td>\n",
       "      <td>3168.809 years - 22060.85 gpus</td>\n",
       "      <td>31688.088 years - 2206.085 gpus</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>125000</td>\n",
       "      <td>1200000.000 EFLOPs</td>\n",
       "      <td>9600.000 PFLOPs</td>\n",
       "      <td>17648.0</td>\n",
       "      <td>1.447 days</td>\n",
       "      <td>0.040 years - 1764.8 gpus</td>\n",
       "      <td>0.396 years - 176.48 gpus</td>\n",
       "      <td>3.961 years - 17.648 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>625000</td>\n",
       "      <td>30000000.000 EFLOPs</td>\n",
       "      <td>48000.000 PFLOPs</td>\n",
       "      <td>88243.0</td>\n",
       "      <td>7.234 days</td>\n",
       "      <td>0.198 years - 8824.3 gpus</td>\n",
       "      <td>1.981 years - 882.43 gpus</td>\n",
       "      <td>19.805 years - 88.243 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>1250000</td>\n",
       "      <td>120000000.000 EFLOPs</td>\n",
       "      <td>96000.000 PFLOPs</td>\n",
       "      <td>176486.0</td>\n",
       "      <td>14.468 days</td>\n",
       "      <td>0.396 years - 17648.6 gpus</td>\n",
       "      <td>3.961 years - 1764.86 gpus</td>\n",
       "      <td>39.610 years - 176.486 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>12500000</td>\n",
       "      <td>12000000000.000 EFLOPs</td>\n",
       "      <td>960000.000 PFLOPs</td>\n",
       "      <td>1764868.0</td>\n",
       "      <td>144.676 days</td>\n",
       "      <td>3.961 years - 176486.8 gpus</td>\n",
       "      <td>39.610 years - 17648.68 gpus</td>\n",
       "      <td>396.101 years - 1764.868 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>125000000</td>\n",
       "      <td>1200000000000.000 EFLOPs</td>\n",
       "      <td>9600000.000 PFLOPs</td>\n",
       "      <td>17648680.0</td>\n",
       "      <td>1446.759 days</td>\n",
       "      <td>39.610 years - 1764868.0 gpus</td>\n",
       "      <td>396.101 years - 176486.8 gpus</td>\n",
       "      <td>3961.011 years - 17648.68 gpus</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>50000</td>\n",
       "      <td>1200000.000 EFLOPs</td>\n",
       "      <td>24000.000 PFLOPs</td>\n",
       "      <td>44121.0</td>\n",
       "      <td>0.579 days</td>\n",
       "      <td>0.016 years - 4412.1 gpus</td>\n",
       "      <td>0.158 years - 441.21 gpus</td>\n",
       "      <td>1.584 years - 44.121 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>250000</td>\n",
       "      <td>30000000.000 EFLOPs</td>\n",
       "      <td>120000.000 PFLOPs</td>\n",
       "      <td>220608.0</td>\n",
       "      <td>2.894 days</td>\n",
       "      <td>0.079 years - 22060.8 gpus</td>\n",
       "      <td>0.792 years - 2206.08 gpus</td>\n",
       "      <td>7.922 years - 220.608 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>500000</td>\n",
       "      <td>120000000.000 EFLOPs</td>\n",
       "      <td>240000.000 PFLOPs</td>\n",
       "      <td>441217.0</td>\n",
       "      <td>5.787 days</td>\n",
       "      <td>0.158 years - 44121.7 gpus</td>\n",
       "      <td>1.584 years - 4412.17 gpus</td>\n",
       "      <td>15.844 years - 441.217 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>5000000</td>\n",
       "      <td>12000000000.000 EFLOPs</td>\n",
       "      <td>2400000.000 PFLOPs</td>\n",
       "      <td>4412170.0</td>\n",
       "      <td>57.870 days</td>\n",
       "      <td>1.584 years - 441217.0 gpus</td>\n",
       "      <td>15.844 years - 44121.7 gpus</td>\n",
       "      <td>158.440 years - 4412.17 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>50000000</td>\n",
       "      <td>1200000000000.000 EFLOPs</td>\n",
       "      <td>24000000.000 PFLOPs</td>\n",
       "      <td>44121702.0</td>\n",
       "      <td>578.704 days</td>\n",
       "      <td>15.844 years - 4412170.2 gpus</td>\n",
       "      <td>158.440 years - 441217.02 gpus</td>\n",
       "      <td>1584.404 years - 44121.702 gpus</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Size (Params) Dataset Size (Tokens)  Total Steps  \\\n",
       "0                0.1T                  2.0T      1000000   \n",
       "1                0.5T                 10.0T      5000000   \n",
       "2                1.0T                 20.0T     10000000   \n",
       "3               10.0T                200.0T    100000000   \n",
       "4              100.0T               2000.0T   1000000000   \n",
       "0                0.1T                  2.0T       125000   \n",
       "1                0.5T                 10.0T       625000   \n",
       "2                1.0T                 20.0T      1250000   \n",
       "3               10.0T                200.0T     12500000   \n",
       "4              100.0T               2000.0T    125000000   \n",
       "0                0.1T                  2.0T        50000   \n",
       "1                0.5T                 10.0T       250000   \n",
       "2                1.0T                 20.0T       500000   \n",
       "3               10.0T                200.0T      5000000   \n",
       "4              100.0T               2000.0T     50000000   \n",
       "\n",
       "                Total FLOPs       FLOPs per Step  H100 GPUs Needed  \\\n",
       "0        1200000.000 EFLOPs      1200.000 PFLOPs            2206.0   \n",
       "1       30000000.000 EFLOPs      6000.000 PFLOPs           11030.0   \n",
       "2      120000000.000 EFLOPs     12000.000 PFLOPs           22060.0   \n",
       "3    12000000000.000 EFLOPs    120000.000 PFLOPs          220608.0   \n",
       "4  1200000000000.000 EFLOPs   1200000.000 PFLOPs         2206085.0   \n",
       "0        1200000.000 EFLOPs      9600.000 PFLOPs           17648.0   \n",
       "1       30000000.000 EFLOPs     48000.000 PFLOPs           88243.0   \n",
       "2      120000000.000 EFLOPs     96000.000 PFLOPs          176486.0   \n",
       "3    12000000000.000 EFLOPs    960000.000 PFLOPs         1764868.0   \n",
       "4  1200000000000.000 EFLOPs   9600000.000 PFLOPs        17648680.0   \n",
       "0        1200000.000 EFLOPs     24000.000 PFLOPs           44121.0   \n",
       "1       30000000.000 EFLOPs    120000.000 PFLOPs          220608.0   \n",
       "2      120000000.000 EFLOPs    240000.000 PFLOPs          441217.0   \n",
       "3    12000000000.000 EFLOPs   2400000.000 PFLOPs         4412170.0   \n",
       "4  1200000000000.000 EFLOPs  24000000.000 PFLOPs        44121702.0   \n",
       "\n",
       "  Total Training Time without grad accum  \\\n",
       "0                            11.574 days   \n",
       "1                            57.870 days   \n",
       "2                           115.741 days   \n",
       "3                          1157.407 days   \n",
       "4                         11574.074 days   \n",
       "0                             1.447 days   \n",
       "1                             7.234 days   \n",
       "2                            14.468 days   \n",
       "3                           144.676 days   \n",
       "4                          1446.759 days   \n",
       "0                             0.579 days   \n",
       "1                             2.894 days   \n",
       "2                             5.787 days   \n",
       "3                            57.870 days   \n",
       "4                           578.704 days   \n",
       "\n",
       "  Total Training Time with 10 grad accum  \\\n",
       "0               0.317 years - 220.6 gpus   \n",
       "1              1.584 years - 1103.0 gpus   \n",
       "2              3.169 years - 2206.0 gpus   \n",
       "3            31.688 years - 22060.8 gpus   \n",
       "4          316.881 years - 220608.5 gpus   \n",
       "0              0.040 years - 1764.8 gpus   \n",
       "1              0.198 years - 8824.3 gpus   \n",
       "2             0.396 years - 17648.6 gpus   \n",
       "3            3.961 years - 176486.8 gpus   \n",
       "4          39.610 years - 1764868.0 gpus   \n",
       "0              0.016 years - 4412.1 gpus   \n",
       "1             0.079 years - 22060.8 gpus   \n",
       "2             0.158 years - 44121.7 gpus   \n",
       "3            1.584 years - 441217.0 gpus   \n",
       "4          15.844 years - 4412170.2 gpus   \n",
       "\n",
       "  Total Training Time with 100 grad accum  \\\n",
       "0                3.169 years - 22.06 gpus   \n",
       "1               15.844 years - 110.3 gpus   \n",
       "2               31.688 years - 220.6 gpus   \n",
       "3            316.881 years - 2206.08 gpus   \n",
       "4          3168.809 years - 22060.85 gpus   \n",
       "0               0.396 years - 176.48 gpus   \n",
       "1               1.981 years - 882.43 gpus   \n",
       "2              3.961 years - 1764.86 gpus   \n",
       "3            39.610 years - 17648.68 gpus   \n",
       "4           396.101 years - 176486.8 gpus   \n",
       "0               0.158 years - 441.21 gpus   \n",
       "1              0.792 years - 2206.08 gpus   \n",
       "2              1.584 years - 4412.17 gpus   \n",
       "3             15.844 years - 44121.7 gpus   \n",
       "4          158.440 years - 441217.02 gpus   \n",
       "\n",
       "  Total Training Time with 1000 grad accum Global Batch Size  \n",
       "0                31.688 years - 2.206 gpus              2.0M  \n",
       "1               158.440 years - 11.03 gpus              2.0M  \n",
       "2               316.881 years - 22.06 gpus              2.0M  \n",
       "3            3168.809 years - 220.608 gpus              2.0M  \n",
       "4          31688.088 years - 2206.085 gpus              2.0M  \n",
       "0                3.961 years - 17.648 gpus             16.0M  \n",
       "1               19.805 years - 88.243 gpus             16.0M  \n",
       "2              39.610 years - 176.486 gpus             16.0M  \n",
       "3            396.101 years - 1764.868 gpus             16.0M  \n",
       "4           3961.011 years - 17648.68 gpus             16.0M  \n",
       "0                1.584 years - 44.121 gpus             40.0M  \n",
       "1               7.922 years - 220.608 gpus             40.0M  \n",
       "2              15.844 years - 441.217 gpus             40.0M  \n",
       "3             158.440 years - 4412.17 gpus             40.0M  \n",
       "4          1584.404 years - 44121.702 gpus             40.0M  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97153b-7c80-45de-bffc-31dd0caa676d",
   "metadata": {},
   "source": [
    "#### Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ba983-2882-48d4-9541-1bd8faabfddb",
   "metadata": {},
   "source": [
    "Assumptions on communication\n",
    "- No limit on banwidth\n",
    "- Achieve speed of light\n",
    "- Clostest surface distance between two points on the earth surface (assume you don't dig a crazy hole to go a straight line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b40c02-2ac3-4dce-947e-a4915b7518f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_latency_between_jz_and_jc = compute_minimum_latency_between_clusters(\"JEAN_ZAY\", \"JOLIOT_CURIE\")\n",
    "minimum_latency_between_jz_and_ec = compute_minimum_latency_between_clusters(\"JEAN_ZAY\", \"EL_CAPITAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba98b7a-e713-446d-9dad-613b76d447e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_comm = []\n",
    "\n",
    "for global_batch_size in global_batch_sizes:\n",
    "    data_comm = {\n",
    "        \"Model Size (Params)\": [],\n",
    "        \"Dataset Size (Tokens)\": [],\n",
    "        \n",
    "        \"Total minimum communication latency between JZ and JC\": [],\n",
    "        \"Total GPU idle time for minimum comm between JZ and JC\": [],\n",
    "        \"GPU idle cost during JZ-JC minimum communication latency\": [],\n",
    "        \n",
    "        \"Total minimum communication latency between JZ and EC\": [],\n",
    "        \"Total GPU idle time for minimum comm between JZ and EC\": [],\n",
    "        \"GPU idle cost during JZ-EC minimum communication latency\": [],\n",
    "    }\n",
    "    \n",
    "    for model_size in target_model_sizes:\n",
    "        dataset_size = get_dataset_size_from_model_size(model_size)\n",
    "        # Append to dictionary\n",
    "        data_comm[\"Model Size (Params)\"].append(convert_to_xt_format(model_size))\n",
    "        data_comm[\"Dataset Size (Tokens)\"].append(convert_to_xt_format(dataset_size))\n",
    "        \n",
    "        data_comm[\"Total minimum communication latency between JZ and JC\"].append(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_jc))\n",
    "        data_comm[\"Total GPU idle time for minimum comm between JZ and JC\"].append(convert_seconds_to_days(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_jc) * h100s_per_step))\n",
    "        data_comm[\"GPU idle cost during JZ-JC minimum communication latency\"].append(convert_to_million_format((calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_jc) / (60 * 60)) * h100s_per_step * H100_COST_PER_HOUR))\n",
    "        \n",
    "        data_comm[\"Total minimum communication latency between JZ and EC\"].append(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_ec))\n",
    "        data_comm[\"Total GPU idle time for minimum comm between JZ and EC\"].append(convert_seconds_to_years(calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_ec) * h100s_per_step))\n",
    "        data_comm[\"GPU idle cost during JZ-EC minimum communication latency\"].append(convert_to_million_format((calculate_total_minimum_comm_latency_to_train_a_model(model_size, global_batch_size, minimum_latency_between_jz_and_ec) / (60 * 60)) * h100s_per_step * H100_COST_PER_HOUR))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df_comm = pd.DataFrame(data_comm)\n",
    "    df_comm['Global Batch Size'] = f'{global_batch_size/1e6}M'\n",
    "    dataframes_comm.append(df_comm)\n",
    "\n",
    "final_df_comm = pd.DataFrame()\n",
    "for i, df in enumerate(dataframes_comm):\n",
    "    final_df_comm = pd.concat([final_df_comm, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e897a27-98f8-43a8-aec6-55310d7da1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Size (Params)</th>\n",
       "      <th>Dataset Size (Tokens)</th>\n",
       "      <th>Total minimum communication latency between JZ and JC</th>\n",
       "      <th>Total GPU idle time for minimum comm between JZ and JC</th>\n",
       "      <th>GPU idle cost during JZ-JC minimum communication latency</th>\n",
       "      <th>Total minimum communication latency between JZ and EC</th>\n",
       "      <th>Total GPU idle time for minimum comm between JZ and EC</th>\n",
       "      <th>GPU idle cost during JZ-EC minimum communication latency</th>\n",
       "      <th>Global Batch Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>1.278270</td>\n",
       "      <td>652.772 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>29.790336</td>\n",
       "      <td>41.651 years</td>\n",
       "      <td>0.7m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>6.391352</td>\n",
       "      <td>3263.858 days</td>\n",
       "      <td>0.2m</td>\n",
       "      <td>148.951681</td>\n",
       "      <td>208.254 years</td>\n",
       "      <td>3.7m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>12.782705</td>\n",
       "      <td>6527.716 days</td>\n",
       "      <td>0.3m</td>\n",
       "      <td>297.903362</td>\n",
       "      <td>416.508 years</td>\n",
       "      <td>7.3m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>127.827046</td>\n",
       "      <td>65277.162 days</td>\n",
       "      <td>3.1m</td>\n",
       "      <td>2979.033618</td>\n",
       "      <td>4165.083 years</td>\n",
       "      <td>73.0m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>1278.270459</td>\n",
       "      <td>652771.624 days</td>\n",
       "      <td>31.3m</td>\n",
       "      <td>29790.336181</td>\n",
       "      <td>41650.833 years</td>\n",
       "      <td>730.2m</td>\n",
       "      <td>2.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>0.159784</td>\n",
       "      <td>81.596 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>3.723792</td>\n",
       "      <td>5.206 years</td>\n",
       "      <td>0.1m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>0.798919</td>\n",
       "      <td>407.982 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>18.618960</td>\n",
       "      <td>26.032 years</td>\n",
       "      <td>0.5m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>1.597838</td>\n",
       "      <td>815.965 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>37.237920</td>\n",
       "      <td>52.064 years</td>\n",
       "      <td>0.9m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>15.978381</td>\n",
       "      <td>8159.645 days</td>\n",
       "      <td>0.4m</td>\n",
       "      <td>372.379202</td>\n",
       "      <td>520.635 years</td>\n",
       "      <td>9.1m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>159.783807</td>\n",
       "      <td>81596.453 days</td>\n",
       "      <td>3.9m</td>\n",
       "      <td>3723.792023</td>\n",
       "      <td>5206.354 years</td>\n",
       "      <td>91.3m</td>\n",
       "      <td>16.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1T</td>\n",
       "      <td>2.0T</td>\n",
       "      <td>0.063914</td>\n",
       "      <td>32.639 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>1.489517</td>\n",
       "      <td>2.083 years</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5T</td>\n",
       "      <td>10.0T</td>\n",
       "      <td>0.319568</td>\n",
       "      <td>163.193 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>7.447584</td>\n",
       "      <td>10.413 years</td>\n",
       "      <td>0.2m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0T</td>\n",
       "      <td>20.0T</td>\n",
       "      <td>0.639135</td>\n",
       "      <td>326.386 days</td>\n",
       "      <td>0.0m</td>\n",
       "      <td>14.895168</td>\n",
       "      <td>20.825 years</td>\n",
       "      <td>0.4m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0T</td>\n",
       "      <td>200.0T</td>\n",
       "      <td>6.391352</td>\n",
       "      <td>3263.858 days</td>\n",
       "      <td>0.2m</td>\n",
       "      <td>148.951681</td>\n",
       "      <td>208.254 years</td>\n",
       "      <td>3.7m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0T</td>\n",
       "      <td>2000.0T</td>\n",
       "      <td>63.913523</td>\n",
       "      <td>32638.581 days</td>\n",
       "      <td>1.6m</td>\n",
       "      <td>1489.516809</td>\n",
       "      <td>2082.542 years</td>\n",
       "      <td>36.5m</td>\n",
       "      <td>40.0M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Size (Params) Dataset Size (Tokens)  \\\n",
       "0                0.1T                  2.0T   \n",
       "1                0.5T                 10.0T   \n",
       "2                1.0T                 20.0T   \n",
       "3               10.0T                200.0T   \n",
       "4              100.0T               2000.0T   \n",
       "0                0.1T                  2.0T   \n",
       "1                0.5T                 10.0T   \n",
       "2                1.0T                 20.0T   \n",
       "3               10.0T                200.0T   \n",
       "4              100.0T               2000.0T   \n",
       "0                0.1T                  2.0T   \n",
       "1                0.5T                 10.0T   \n",
       "2                1.0T                 20.0T   \n",
       "3               10.0T                200.0T   \n",
       "4              100.0T               2000.0T   \n",
       "\n",
       "   Total minimum communication latency between JZ and JC  \\\n",
       "0                                           1.278270       \n",
       "1                                           6.391352       \n",
       "2                                          12.782705       \n",
       "3                                         127.827046       \n",
       "4                                        1278.270459       \n",
       "0                                           0.159784       \n",
       "1                                           0.798919       \n",
       "2                                           1.597838       \n",
       "3                                          15.978381       \n",
       "4                                         159.783807       \n",
       "0                                           0.063914       \n",
       "1                                           0.319568       \n",
       "2                                           0.639135       \n",
       "3                                           6.391352       \n",
       "4                                          63.913523       \n",
       "\n",
       "  Total GPU idle time for minimum comm between JZ and JC  \\\n",
       "0                                       652.772 days       \n",
       "1                                      3263.858 days       \n",
       "2                                      6527.716 days       \n",
       "3                                     65277.162 days       \n",
       "4                                    652771.624 days       \n",
       "0                                        81.596 days       \n",
       "1                                       407.982 days       \n",
       "2                                       815.965 days       \n",
       "3                                      8159.645 days       \n",
       "4                                     81596.453 days       \n",
       "0                                        32.639 days       \n",
       "1                                       163.193 days       \n",
       "2                                       326.386 days       \n",
       "3                                      3263.858 days       \n",
       "4                                     32638.581 days       \n",
       "\n",
       "  GPU idle cost during JZ-JC minimum communication latency  \\\n",
       "0                                               0.0m         \n",
       "1                                               0.2m         \n",
       "2                                               0.3m         \n",
       "3                                               3.1m         \n",
       "4                                              31.3m         \n",
       "0                                               0.0m         \n",
       "1                                               0.0m         \n",
       "2                                               0.0m         \n",
       "3                                               0.4m         \n",
       "4                                               3.9m         \n",
       "0                                               0.0m         \n",
       "1                                               0.0m         \n",
       "2                                               0.0m         \n",
       "3                                               0.2m         \n",
       "4                                               1.6m         \n",
       "\n",
       "   Total minimum communication latency between JZ and EC  \\\n",
       "0                                          29.790336       \n",
       "1                                         148.951681       \n",
       "2                                         297.903362       \n",
       "3                                        2979.033618       \n",
       "4                                       29790.336181       \n",
       "0                                           3.723792       \n",
       "1                                          18.618960       \n",
       "2                                          37.237920       \n",
       "3                                         372.379202       \n",
       "4                                        3723.792023       \n",
       "0                                           1.489517       \n",
       "1                                           7.447584       \n",
       "2                                          14.895168       \n",
       "3                                         148.951681       \n",
       "4                                        1489.516809       \n",
       "\n",
       "  Total GPU idle time for minimum comm between JZ and EC  \\\n",
       "0                                       41.651 years       \n",
       "1                                      208.254 years       \n",
       "2                                      416.508 years       \n",
       "3                                     4165.083 years       \n",
       "4                                    41650.833 years       \n",
       "0                                        5.206 years       \n",
       "1                                       26.032 years       \n",
       "2                                       52.064 years       \n",
       "3                                      520.635 years       \n",
       "4                                     5206.354 years       \n",
       "0                                        2.083 years       \n",
       "1                                       10.413 years       \n",
       "2                                       20.825 years       \n",
       "3                                      208.254 years       \n",
       "4                                     2082.542 years       \n",
       "\n",
       "  GPU idle cost during JZ-EC minimum communication latency Global Batch Size  \n",
       "0                                               0.7m                    2.0M  \n",
       "1                                               3.7m                    2.0M  \n",
       "2                                               7.3m                    2.0M  \n",
       "3                                              73.0m                    2.0M  \n",
       "4                                             730.2m                    2.0M  \n",
       "0                                               0.1m                   16.0M  \n",
       "1                                               0.5m                   16.0M  \n",
       "2                                               0.9m                   16.0M  \n",
       "3                                               9.1m                   16.0M  \n",
       "4                                              91.3m                   16.0M  \n",
       "0                                               0.0m                   40.0M  \n",
       "1                                               0.2m                   40.0M  \n",
       "2                                               0.4m                   40.0M  \n",
       "3                                               3.7m                   40.0M  \n",
       "4                                              36.5m                   40.0M  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cb2a5-93ee-4a40-bbd0-79f65f58a344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
