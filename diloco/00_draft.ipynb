{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93499f2d-a0c2-4c17-a256-3cee88151f7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_critical_batch_size, convert_to_million_format\n",
      "File \u001b[0;32m~/DATA/hf-notebooks/diloco/utils.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mname\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Datatype, Transformer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOTAL_H100_WATT\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# def chinchilla_flops(seq_len, vocab_size, d_model, num_heads, num_layers, ffw_size):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     \"\"\" \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     Calculate total number of FLOPs, see Chinchilla \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m### SCALING LAWS\u001b[39;00m\n",
      "File \u001b[0;32m~/DATA/hf-notebooks/diloco/name.py:30\u001b[0m\n\u001b[1;32m     26\u001b[0m     n_key_value_heads: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m     27\u001b[0m     ctx_length: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTrainingConfig\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     tp_size: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m     32\u001b[0m     pp_size: \u001b[38;5;28mint\u001b[39m\n",
      "File \u001b[0;32m~/DATA/hf-notebooks/diloco/name.py:43\u001b[0m, in \u001b[0;36mTrainingConfig\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m optim_first_state_dtype: Datatype\n\u001b[1;32m     42\u001b[0m optim_second_state_dtype: Datatype\n\u001b[0;32m---> 43\u001b[0m master_weight_dtype: \u001b[43mOptional\u001b[49m[Datatype] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_gpus \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtp_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpp_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Optional' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import get_critical_batch_size, convert_to_million_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf4a56-5cb2-4704-be0b-896b3cebf7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model_sizes = [100*10**9, 500*10**9, 1000*10**9, 10000*10**9, 100000*10**9]\n",
    "\n",
    "[get_critical_batch_size(x) * 4096 for x in target_model_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4489a4c-1d7b-4b51-ac1a-ea4af1fe8f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4740703.56033686,\n",
       " 8025570.014198784,\n",
       " 10067990.55408977,\n",
       " 21381727.945469383,\n",
       " 45409090.073922805]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_critical_batch_size(x) * 4096 for x in target_model_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8d0bf6-da09-49a5-bd91-e2ab263dd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_weight_memory, calculate_kv_cache\n",
    "from utils import convert_bytes_to_gigabytes, convert_bytes_to_megabytes\n",
    "from constants import LLAMA3_400B_CONFIG\n",
    "from name import TrainingConfig, Datatype, Transformer\n",
    "from transformer_mem_functional import calculate_memory_requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8937ba-e7b5-441a-b360-6b749a339a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model Memory': '39.865 GB',\n",
       " 'KV Cache Memory': '2.215 GB',\n",
       " 'Gradient Memory': '39.865 GB',\n",
       " 'Activation Memory': '18.824 GB',\n",
       " 'Optimizer Memory': '239.189 GB',\n",
       " 'Communication Memory': '3.000 GB',\n",
       " 'Miscellaneous Memory': '0.000 GB',\n",
       " 'Total Training Memory (GB)': '340.743 GB',\n",
       " 'Total Inference Memory (GB)': '42.079 GB'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: convert_bytes_to_gigabytes(v) for k, v in calculate_memory_requirements(\n",
    "    transformer=Transformer(\n",
    "        name=\"x\",\n",
    "        n_layers=44,\n",
    "        hidden_size=6144,\n",
    "        n_heads=64,\n",
    "        n_key_value_heads=64,\n",
    "        ctx_length=2048\n",
    "    ),\n",
    "    config=TrainingConfig(\n",
    "    tp_size=1, pp_size=1, num_gpus=1,\n",
    "    partition_activations=True, zero1=1,\n",
    "    checkpoint_activations=True,\n",
    "    batch_size_per_replicas=1,\n",
    "    weight_dtype=Datatype.BFLOAT16,\n",
    "    gradient_dtype=Datatype.BFLOAT16,\n",
    "    optim_first_state_dtype=Datatype.FLOAT32,\n",
    "    optim_second_state_dtype=Datatype.FLOAT32\n",
    ")).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808c6219-2a64-4ccd-acd6-e064d6da89e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model Memory': '39.865 GB',\n",
       " 'KV Cache Memory': '2.215 GB',\n",
       " 'Gradient Memory': '39.865 GB',\n",
       " 'Activation Memory': '18.824 GB',\n",
       " 'Optimizer Memory': '239.189 GB',\n",
       " 'Communication Memory': '3.000 GB',\n",
       " 'Miscellaneous Memory': '0.000 GB',\n",
       " 'Total Training Memory (GB)': '340.743 GB',\n",
       " 'Total Inference Memory (GB)': '42.079 GB'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: convert_bytes_to_gigabytes(v) for k, v in calculate_memory_requirements(\n",
    "    transformer=Transformer(\n",
    "        name=\"x\",\n",
    "        n_layers=44,\n",
    "        hidden_size=6144,\n",
    "        n_heads=64,\n",
    "        n_key_value_heads=64,\n",
    "        ctx_length=2048\n",
    "    ),\n",
    "    config=TrainingConfig(\n",
    "    tp_size=1, pp_size=1, num_gpus=1,\n",
    "    partition_activations=True,\n",
    "    zero1=1,\n",
    "    checkpoint_activations=True,\n",
    "    batch_size_per_replicas=1,\n",
    "    \n",
    "    weight_dtype=Datatype.BFLOAT16,\n",
    "    gradient_dtype=Datatype.BFLOAT16,\n",
    "    \n",
    "    optim_first_state_dtype=Datatype.FLOAT32,\n",
    "    optim_second_state_dtype=Datatype.FLOAT32,\n",
    "    master_weight_dtype=Datatype.FLOAT32,\n",
    ")).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f3978-ead4-404f-a003-c2dc7ca20032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
